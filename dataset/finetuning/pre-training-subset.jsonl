{"sample": "package rssplugin\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"net/url\"\n\t\"regexp\"\n\t\"time\"\n\n\t\"github.com/torlenor/redseligg/model\"\n\t\"github.com/torlenor/redseligg/storage\"\n\t\"github.com/torlenor/redseligg/storagemodels\"\n)\n\nvar now = time.Now\n\nvar errNotExist = errors.New(\"RSS subscription does not exist\")\n\nfunc (p *RssPlugin) getRssSubscriptions() (storagemodels.RssPluginSubscriptions, error) {\n\ts := p.getStorage()\n\tif s == nil {\n\t\treturn storagemodels.RssPluginSubscriptions{}, ErrNoValidStorage\n\t}\n\n\treturn s.GetRssPluginSubscriptions(p.BotID, p.PluginID)\n}\n\nfunc (p *RssPlugin) storeRssPluginSubscription(data storagemodels.RssPluginSubscription) error {\n\ts := p.getStorage()\n\tif s == nil {\n\t\tp.API.LogError(ErrNoValidStorage.Error())\n\t\treturn ErrNoValidStorage\n\t}\n\n\terr := s.StoreRssPluginSubscription(p.BotID, p.PluginID, generateIdentifier(), data)\n\tif err != nil {\n\t\tp.API.LogError(fmt.Sprintf(\"Error storing RSS subscription: %s\", err))\n\t\treturn fmt.Errorf(\"Error storing RSS subscription: %s\", err)\n\t}\n\n\treturn nil\n}\n\nfunc (p *RssPlugin) updateRssPluginSubscription(data storagemodels.RssPluginSubscription) error {\n\ts := p.getStorage()\n\tif s == nil {\n\t\tp.API.LogError(ErrNoValidStorage.Error())\n\t\treturn ErrNoValidStorage\n\t}\n\n\terr := s.UpdateRssPluginSubscription(p.BotID, p.PluginID, data.Identifier, data)\n\tif err != nil {\n\t\tp.API.LogError(fmt.Sprintf(\"Error updating RSS subscription: %s\", err))\n\t\treturn fmt.Errorf(\"Error updating RSS subscription: %s\", err)\n\t}\n\n\treturn nil\n}\n\nfunc (p *RssPlugin) addRssSubscription(channelID, link string) error {\n\terr := p.storeRssPluginSubscription(storagemodels.RssPluginSubscription{\n\t\tLink:              link,\n\t\tChannelID:         channelID,\n\t\tLastPostedPubDate: time.Now(),\n\t})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Could not add RSS subscription for link '%s' in channel '%s': %s\", link, channelID, err)\n\t}\n\n\tp.API.LogTrace(fmt.Sprintf(\"Added RSS subscription for link '%s' for channel %s\", link, channelID))\n\n\treturn nil\n}\n\nfunc (p *RssPlugin) removeRssSubscription(channelID, link string) error {\n\tsubscriptions, err := p.getRssSubscriptions()\n\tif err != nil && err != storage.ErrNotFound {\n\t\treturn fmt.Errorf(\"Could not remove RSS subscription: %s\", err)\n\t}\n\n\ts := p.getStorage()\n\tif s == nil {\n\t\tp.API.LogError(ErrNoValidStorage.Error())\n\t\treturn ErrNoValidStorage\n\t}\n\n\tvar wasRemoved bool\n\tfor _, x := range subscriptions.Subscriptions {\n\t\tif x.ChannelID == channelID && x.Link == link {\n\t\t\tp.API.LogTrace(fmt.Sprintf(\"Removed RSS subscription for link '%s' for channel %s\", link, channelID))\n\t\t\ts.DeleteRssPluginSubscription(p.BotID, p.PluginID, x.Identifier)\n\t\t\twasRemoved = true\n\t\t}\n\t}\n\n\tif !wasRemoved {\n\t\treturn errNotExist\n\t}\n\n\treturn nil\n}\n\nfunc splitRssCommand(text string) (c string, link string, err error) {\n\tvar re = regexp.MustCompile(`(?m)^+(add|remove) +(.*)$`)\n\n\tconst cgCommand = 1\n\tconst cgLink = 2\n\n\tmatches := re.FindAllStringSubmatch(text, -1)\n\n\tif matches == nil || len(matches) < 1 {\n\t\terr = errors.New(\"Not a valid command\")\n\t\treturn\n\t}\n\n\tif len(matches[0]) > cgLink {\n\t\tc = matches[0][cgCommand]\n\t\tlink = matches[0][cgLink]\n\t} else {\n\t\terr = errors.New(\"Not a valid command\")\n\t}\n\n\t_, err = url.ParseRequestURI(link)\n\tif err != nil {\n\t\terr = fmt.Errorf(\"Not a valid url: %s\", err)\n\t}\n\n\treturn\n}\n\nfunc (p *RssPlugin) returnSubscriptionsList(channelID string) {\n\tsubscriptions, err := p.getRssSubscriptions()\n\tif err != nil {\n\t\tp.API.LogError(fmt.Sprintf(\"Error getting RSS subscriptions list: %s\", err))\n\t\tp.returnMessage(channelID, fmt.Sprintf(\"Error getting RSS subscriptions list: %s\", err))\n\t}\n\n\tsubscriptionsText := \"RSS subscriptions for this channel:\\n\"\n\tcnt := 0\n\tlines := []string{}\n\tfor _, s := range subscriptions.Subscriptions {\n\t\tif s.ChannelID == channelID {\n\t\t\tcnt++\n\t\t\t// subscriptionsText += fmt.Sprintf(\"%d. %s\\n\", cnt, s.Link)\n\t\t\tlines = append(lines, fmt.Sprintf(\"%d. %s\", cnt, s.Link))\n\t\t}\n\t}\n\n\tfor i, line := range lines {\n\t\tsubscriptionsText += line\n\t\tif i < (len(lines) - 1) {\n\t\t\tsubscriptionsText += \"\\n\"\n\t\t}\n\t}\n\n\tp.returnMessage(channelID, subscriptionsText)\n}\n\n// onCommand handles a !rss command.\nfunc (p *RssPlugin) onCommand(content string, post model.Post) {\n\tif content == \"add\" {\n\t\tp.returnHelpAdd(post.ChannelID)\n\t\treturn\n\t} else if content == \"remove\" {\n\t\tp.returnHelpRemove(post.ChannelID)\n\t\treturn\n\t}\n\n\tif content == \"list\" {\n\t\tp.returnSubscriptionsList(post.ChannelID)\n\t\treturn\n\t}\n\n\tc, link, err := splitRssCommand(content)\n\tif err != nil {\n\t\tp.API.LogError(fmt.Sprintf(\"Error parsing command '%s': %s\", content, err))\n\t\tp.returnHelp(post.ChannelID)\n\t\treturn\n\t}\n\n\tswitch c {\n\tcase \"add\":\n\t\terr = p.addRssSubscription(post.ChannelID, link)\n\tcase \"remove\":\n\t\terr = p.removeRssSubscription(post.ChannelID, link)\n\t}\n\n\tif err == errNotExist {\n\t\tp.returnMessage(post.ChannelID, \"RSS subscription to remove does not exist.\")\n\t\treturn\n\t} else if err != nil {\n\t\tp.API.LogError(fmt.Sprintf(\"Could not %s RSS subscription: %s\", c, err))\n\t\tp.returnMessage(post.ChannelID, fmt.Sprintf(\"Could not %s RSS subscription. Please try again later.\", c))\n\t\treturn\n\t}\n\n\tswitch c {\n\tcase \"add\":\n\t\tp.returnMessage(post.ChannelID, fmt.Sprintf(\"RSS subscription for link '%s' added.\", link))\n\tcase \"remove\":\n\t\tp.returnMessage(post.ChannelID, fmt.Sprintf(\"RSS subscription for link '%s' removed.\", link))\n\t}\n}\n"}
{"sample": "package v1\n\nimport (\n\t\"net/http\"\n\t\"strconv\"\n\t\"testing\"\n\n\t\"github.com/labstack/echo/v4\"\n\n\t\"github.com/traPtitech/traQ/repository\"\n\t\"github.com/traPtitech/traQ/service/file\"\n\t\"github.com/traPtitech/traQ/service/rbac/role\"\n\t\"github.com/traPtitech/traQ/utils/random\"\n)\n\nfunc TestHandlers_GetPublicUserIcon(t *testing.T) {\n\tt.Parallel()\n\tenv, _, require, _, _ := setup(t, common2)\n\n\tfid, err := file.GenerateIconFile(env.FileManager, \"test\")\n\trequire.NoError(err)\n\n\ttestUser, err := env.Repository.CreateUser(repository.CreateUserArgs{\n\t\tName:       random.AlphaNumeric(32),\n\t\tRole:       role.User,\n\t\tIconFileID: fid,\n\t})\n\trequire.NoError(err)\n\n\tt.Run(\"No user\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\te := env.makeExp(t)\n\t\te.GET(\"/api/1.0/public/icon/no+user\").\n\t\t\tExpect().\n\t\t\tStatus(http.StatusNotFound)\n\t})\n\n\tt.Run(\"Success\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\t_, require := assertAndRequire(t)\n\n\t\tmeta, err := env.FileManager.Get(testUser.GetIconFileID())\n\t\trequire.NoError(err)\n\t\te := env.makeExp(t)\n\t\te.GET(\"/api/1.0/public/icon/{username}\", testUser.GetName()).\n\t\t\tExpect().\n\t\t\tStatus(http.StatusOK).\n\t\t\tHeader(echo.HeaderContentLength).\n\t\t\tEqual(strconv.FormatInt(meta.GetFileSize(), 10))\n\t})\n\n\tt.Run(\"Success With 304\", func(t *testing.T) {\n\t\tt.Parallel()\n\t\t_, require := assertAndRequire(t)\n\n\t\tmeta, err := env.FileManager.Get(testUser.GetIconFileID())\n\t\trequire.NoError(err)\n\n\t\te := env.makeExp(t)\n\t\te.GET(\"/api/1.0/public/icon/{username}\", testUser.GetName()).\n\t\t\tWithHeader(\"If-None-Match\", strconv.Quote(meta.GetMD5Hash())).\n\t\t\tExpect().\n\t\t\tStatus(http.StatusNotModified)\n\t})\n}\n"}
{"sample": "// Copyright \u00a9 2013-2016 Galvanized Logic Inc.\n// Use is governed by a BSD-style license found in the LICENSE file.\n\npackage main\n\nimport (\n\t\"strconv\"\n\n\t\"github.com/gazed/vu\"\n\t\"github.com/gazed/vu/math/lin\"\n)\n\n// hud is the 2D controller for all parts of the games heads-up-display (HUD).\ntype hud struct {\n\tui   *vu.Ent  // 2D scene.\n\tarea          // Hud fills up the full screen.\n\tpl   *player  // Player model.\n\txp   *xpbar   // Show cores collected and current energy.\n\tmm   *minimap // Show overhead map centered on player.\n\tce   *vu.Ent  // Cloaking effect.\n\tte   *vu.Ent  // Teleport effect.\n\tee   *vu.Ent  // Energy loss effect.\n}\n\n// newHud creates all the various parts of the heads up display.\nfunc newHud(eng vu.Eng, sentryCount, wx, wy, ww, wh int) *hud {\n\thd := &hud{}\n\thd.ui = eng.AddScene().SetUI()\n\thd.ui.Cam().SetClip(0, 10)\n\thd.setSize(wx, wy, ww, wh)\n\n\t// create the HUD parts.\n\thd.pl = newPlayer(hd.ui.AddPart(), hd.w, hd.h)\n\thd.xp = newXpbar(hd.ui, hd.w, hd.h)\n\thd.mm = newMinimap(eng, sentryCount)\n\thd.ce = hd.cloakingEffect(hd.ui.AddPart())\n\thd.te = hd.teleportEffect(hd.ui.AddPart())\n\thd.ee = hd.energyLossEffect(hd.ui.AddPart())\n\thd.resize(hd.w, hd.h)\n\treturn hd\n}\n\n// setSize adjusts the size of the hud to the current screen dimensions.\nfunc (hd *hud) setSize(screenX, screenY, screenWidth, screenHeight int) {\n\thd.x, hd.y, hd.w, hd.h = 0, 0, screenWidth, screenHeight\n\thd.cx, hd.cy = hd.center()\n}\n\n// resize adapts the overlay to a new window size.\nfunc (hd *hud) resize(screenWidth, screenHeight int) {\n\thd.setSize(0, 0, screenWidth, screenHeight)\n\thd.xp.resize(screenWidth, screenHeight)\n\thd.mm.resize(screenWidth, screenHeight)\n\n\t// resize the animation effects.\n\thd.ce.SetScale(float64(hd.w), float64(hd.h), 1)\n\thd.ce.SetAt(hd.cx, hd.cy, -1)\n\thd.te.SetScale(float64(hd.w), float64(hd.h), 1)\n\thd.te.SetAt(hd.cx, hd.cy, -1)\n\thd.ee.SetScale(float64(hd.w), float64(hd.h), 1)\n\thd.ee.SetAt(hd.cx, hd.cy, -1)\n}\n\n// setVisible turns the HUD on/off. This is used when transitioning\n// between levels.\nfunc (hd *hud) setVisible(isVisible bool) {\n\thd.ui.Cull(!isVisible)\n\thd.mm.setVisible(isVisible)\n}\n\n// setLevel is called when a level transition happens.\nfunc (hd *hud) setLevel(lvl *level) {\n\thd.pl.setLevel(lvl)\n\thd.xp.setLevel(lvl)\n\thd.mm.setLevel(lvl.cam, lvl)\n}\n\n// have the hud wrap the minimap specifics so as to provide a single\n// outside interface.\nfunc (hd *hud) addWall(gamex, gamez float64)              { hd.mm.addWall(gamex, gamez) }\nfunc (hd *hud) remCore(gamex, gamez float64)              { hd.mm.remCore(gamex, gamez) }\nfunc (hd *hud) addCore(gamex, gamez float64)              { hd.mm.addCore(gamex, gamez) }\nfunc (hd *hud) resetCores()                               { hd.mm.resetCores() }\nfunc (hd *hud) update(c *vu.Camera, sentries []*sentinel) { hd.mm.update(c, sentries) }\n\n// cloakingEffect creates the model shown when the user cloaks.\nfunc (hd *hud) cloakingEffect(ce *vu.Ent) *vu.Ent {\n\tce.Cull(true)\n\tce.MakeModel(\"textured\", \"msh:icon\", \"tex:cloakon\")\n\tce.SetAlpha(0.5)\n\treturn ce\n}\nfunc (hd *hud) cloakingActive(isActive bool) { hd.ce.Cull(!isActive) }\n\n// teleportEffect creates the model shown when the user teleports.\nfunc (hd *hud) teleportEffect(te *vu.Ent) *vu.Ent {\n\tte.Cull(true)\n\tm := te.MakeModel(\"uvra\", \"msh:icon\", \"tex:smoke\")\n\tm.SetAlpha(0.5).SetUniform(\"spin\", 10.0).SetUniform(\"fd\", 1000)\n\treturn te\n}\nfunc (hd *hud) teleportActive(isActive bool) { hd.te.Cull(!isActive) }\nfunc (hd *hud) teleportFade(alpha float64) {\n\thd.te.SetAlpha(lin.Clamp(alpha, 0, 1))\n}\n\n// energyLossEffect creates the model shown when the player gets hit\n// by a sentinel.\nfunc (hd *hud) energyLossEffect(ee *vu.Ent) *vu.Ent {\n\tee.Cull(true)\n\tm := ee.MakeModel(\"uvra\", \"msh:icon\", \"tex:loss\")\n\tm.SetAlpha(0.5).SetUniform(\"fd\", 1000).SetUniform(\"spin\", 2.0)\n\treturn ee\n}\nfunc (hd *hud) energyLossActive(isActive bool) { hd.ee.Cull(!isActive) }\nfunc (hd *hud) energyLossFade(alpha float64) {\n\thd.ee.SetAlpha(lin.Clamp(alpha, 0, 1))\n}\n\n// hud\n// ===========================================================================\n// player\n\n// player shows the trooper model that corresponds to the player. This allows\n// an alternative view, albeit less useful, of the current players health.\n//\n// Player can ignore resizes since it is in the lower left corner.\ntype player struct {\n\tcx, cy float64  // Center location.\n\tplayer *trooper // Composite model of the player.\n\tbg     *vu.Ent  // Health status background.\n}\n\n// newPlayer sets the player hud location and creates the white background.\nfunc newPlayer(pov *vu.Ent, screenWidth, screenHeight int) *player {\n\tpl := &player{}\n\tpl.cx, pl.cy = 100, 100\n\tpl.bg = pov.SetScale(110, 110, 1).SetAt(pl.cx, pl.cy, 0)\n\tpl.bg.MakeModel(\"textured\", \"msh:icon\", \"tex:hudbg\")\n\treturn pl\n}\n\n// setLevel gives the player its tilt. Note that nothing else\n// uses the player rotation/location fields.\nfunc (pl *player) setLevel(lvl *level) {\n\tpl.player = lvl.player\n\n\t// twist the player about 15 degrees around X and 15 degrees around Z.\n\tpl.player.part.SetView(&lin.Q{X: 0.24, Y: 0.16, Z: 0.16, W: 0.95})\n\tpl.player.part.SetAt(pl.cx, pl.cy, 0)\n}\n\n// player\n// ===========================================================================\n// xpbar\n\n// xpbar reflects the players health and energy statistics using different\n// progress bars.\ntype xpbar struct {\n\tarea\n\tborder int      // Offset from the edge of the screen.\n\tlinew  int      // Line width for the box.\n\tbh, bw int      // Bar height and width.\n\tbg     *vu.Ent  // Health background bar.\n\tfg     *vu.Ent  // Health foreground bar.\n\tcbg    *vu.Ent  // Cloak energy background bar.\n\tcfg    *vu.Ent  // Cloak energy foreground bar.\n\ttbg    *vu.Ent  // Teleport energy background bar.\n\ttfg    *vu.Ent  // Teleport energy foreground bar.\n\thb     *vu.Ent  // Display health amount.\n\thbw    int      // Display health width in pixels.\n\ttk     *vu.Ent  // Display teleport key.\n\ttkw    int      // Display key width in pixels.\n\tck     *vu.Ent  // Display cloak key.\n\tckw    int      // Display key width in pixels.\n\ttr     *trooper // Current player injected with SetStage.\n}\n\n// newXpbar creates all three status bars.\nfunc newXpbar(scene *vu.Ent, screenWidth, screenHeight int) *xpbar {\n\txp := &xpbar{}\n\txp.border = 5\n\txp.linew = 2\n\txp.setSize(screenWidth, screenHeight)\n\n\t// add the xp background and foreground bars.\n\txp.bg = scene.AddPart()\n\txp.bg.MakeModel(\"colored\", \"msh:square\", \"mat:tgray\")\n\txp.fg = scene.AddPart()\n\txp.fg.MakeModel(\"textured\", \"msh:icon\", \"tex:xpcyan\", \"tex:xpred\")\n\n\t// add the xp bar text.\n\txp.hb = scene.AddPart()\n\txp.hb.MakeLabel(\"labeled\", \"lucidiaSu22\")\n\n\t// teleport energy background and foreground bars.\n\txp.tbg = scene.AddPart()\n\txp.tbg.MakeModel(\"colored\", \"msh:square\", \"mat:tgray\")\n\txp.tfg = scene.AddPart()\n\txp.tfg.MakeModel(\"textured\", \"msh:icon\", \"tex:xpblue\", \"tex:xpred\")\n\n\t// the teleport bar text.\n\txp.tk = scene.AddPart().MakeLabel(\"labeled\", \"lucidiaSu18\")\n\n\t// cloak energy background and foreground bars.\n\txp.cbg = scene.AddPart()\n\txp.cbg.MakeModel(\"colored\", \"msh:square\", \"mat:tgray\")\n\txp.cfg = scene.AddPart()\n\txp.cfg.MakeModel(\"textured\", \"msh:icon\", \"tex:xpblue\")\n\n\t// the cloak bar text.\n\txp.ck = scene.AddPart().MakeLabel(\"labeled\", \"lucidiaSu18\")\n\txp.resize(screenWidth, screenHeight)\n\treturn xp\n}\n\n// resize adjusts the graphics to fit the new window dimensions.\nfunc (xp *xpbar) resize(screenWidth, screenHeight int) {\n\txp.setSize(screenWidth, screenHeight)\n\txp.bg.SetAt(xp.cx+5, xp.cy+5, 1)\n\txp.bg.SetScale(float64(xp.bw/2), float64(xp.bh-xp.y), 1)\n\n\t// adjust the teleport energy bar.\n\txp.tbg.SetAt(xp.cx-float64(xp.w)/10, xp.cy+35, 1)\n\txp.tbg.SetScale(float64(xp.bw/10), float64(xp.bh-xp.y)-5, 1)\n\tbw := xp.tkw\n\txp.tk.SetAt(xp.cx-float64(xp.bw)/10-float64(bw/2), xp.cy+26, 0)\n\n\t// adjust the cloaking energy bar.\n\txp.cbg.SetAt(xp.cx+float64(xp.bw)/10, xp.cy+35, 1)\n\txp.cbg.SetScale(float64(xp.bw/10), float64(xp.bh-xp.y)-5, 1)\n\tbw = xp.ckw\n\txp.ck.SetAt(xp.cx+float64(xp.bw)/10-float64(bw/2), xp.cy+26, 0)\n\n\t// adjust the energy amounts for the bars.\n\tif xp.tr != nil {\n\t\txp.healthUpdated(xp.tr.health())\n\t\txp.energyUpdated(xp.tr.energy())\n\t}\n}\n\n// setSize adjusts the xpbars area according to the given screen dimensions.\nfunc (xp *xpbar) setSize(screenWidth, screenHeight int) {\n\txp.x, xp.y = 5, 5 // bottom left corner.\n\txp.w, xp.h = screenWidth, screenHeight\n\txp.bw, xp.bh = screenWidth-2*xp.border, 20\n\txp.cx, xp.cy = float64(screenWidth)*0.5-float64(xp.border), float64(xp.bh)*0.5+float64(xp.border)\n}\n\n// healthMonitor:healthUpdated. Updates the health banner when it changes.\nfunc (xp *xpbar) healthUpdated(health, warn, high int) {\n\tmaxCores := high / gameCellGain[xp.tr.lvl-1]\n\tcoresNeeded := (high - health) / gameCellGain[xp.tr.lvl-1]\n\tcoreCount := strconv.Itoa(maxCores-coresNeeded) + \"/\" + strconv.Itoa(maxCores)\n\txp.hb.SetStr(coreCount)\n\txp.hbw, _ = xp.hb.Size()\n\txp.hb.SetAt(xp.cx-float64(xp.hbw/2), xp.cy*0.5, 0)\n\n\t// turn on the warning colour if player has less than the starting amount of cores.\n\tbarMax := float64(xp.bw/2 - xp.linew)\n\tif health >= warn {\n\t\txp.fg.SetFirst(\"xpcyan\")\n\t} else {\n\t\txp.fg.SetFirst(\"xpred\")\n\t}\n\thealthBar := float64(health) / float64(high) * barMax\n\tzeroSpot := float64(xp.border) + healthBar + float64(xp.linew-xp.border)\n\txp.fg.SetAt(zeroSpot+5, xp.cy+5, 0)\n\txp.fg.SetScale(healthBar, float64(xp.bh-xp.y-xp.linew)-1, 1)\n}\n\n// energyMonitor:energyUpdated. Update the energy banner when it changes.\nfunc (xp *xpbar) energyUpdated(teleportEnergy, tmax, cloakEnergy, cmax int) {\n\ttratio := float64(teleportEnergy) / float64(tmax)\n\tif tratio == 1.0 {\n\t\txp.tfg.SetFirst(\"xpblue\")\n\t} else {\n\t\txp.tfg.SetFirst(\"xpred\")\n\t}\n\txp.tfg.SetAt(xp.cx-float64(xp.w)/10, xp.cy+35, 0)\n\txp.tfg.SetScale((float64(xp.bw/10))*tratio, float64(xp.bh-xp.y)-7, 1)\n\tcratio := float64(cloakEnergy) / float64(cmax)\n\txp.cfg.SetAt(xp.cx+float64(xp.w)/10-1, xp.cy+35, 0)\n\txp.cfg.SetScale((float64(xp.bw/10))*cratio, float64(xp.bh-xp.y)-7, 1)\n}\n\n// setLevel sets the xpbars values and must be called at least once before rendering.\nfunc (xp *xpbar) setLevel(lvl *level) {\n\txp.tr = lvl.player\n\txp.tr.monitorHealth(\"xpbar\", xp)\n\txp.tr.monitorEnergy(\"xpbar\", xp)\n\txp.healthUpdated(xp.tr.health())\n\txp.energyUpdated(xp.tr.energy())\n}\n\n// updateKeys needs to be called on startup and whenever the displayed key\n// mappings are changed.\nfunc (xp *xpbar) updateKeys(teleportKey, cloakKey int) {\n\tif xp.tk != nil && xp.ck != nil {\n\t\tif tsym := vu.Symbol(teleportKey); tsym > 0 {\n\t\t\txp.tk.SetStr(string(tsym))\n\t\t}\n\t\tif csym := vu.Symbol(cloakKey); csym > 0 {\n\t\t\txp.ck.SetStr(string(csym))\n\t\t}\n\t}\n}\n\n// xpbar\n// ===========================================================================\n// minimap\n\n// minimap displays a limited portion of the current level from the overhead\n// 2D perspective.\ntype minimap struct {\n\tui     *vu.Ent   // 2D overlay scene.\n\tarea             // Rectangular area.\n\tcores  []*vu.Ent // Keep track of the cores for removal.\n\ttop    *vu.Ent   // Map scale and position on screen.\n\troot   *vu.Ent   // Reposition map as player move.s\n\tbg     *vu.Ent   // The white background.\n\tscale  float64   // Minimap sizing.\n\tppm    *vu.Ent   // Player position marker.\n\tcpm    *vu.Ent   // Center of map position marker.\n\tspms   []*vu.Ent // Sentry position markers.\n\tradius int       // Limits map visibility. Distance squared in pixels.\n}\n\n// newMinimap initializes the minimap. It still needs to be populated.\nfunc newMinimap(eng vu.Eng, numTroops int) *minimap {\n\tmm := &minimap{}\n\tmm.radius = 120\n\tmm.scale = 5.0\n\tmm.cores = []*vu.Ent{}\n\tmm.ui = eng.AddScene().SetUI()\n\tmm.ui.Cam().SetClip(0, 10)\n\tmm.ui.SetCuller(mm) // mm implements Culler\n\n\t// parent for all the visible minimap pieces.\n\tmm.top = mm.ui.AddPart().SetScale(mm.scale, mm.scale, 1)\n\tmm.root = mm.top.AddPart()\n\n\t// add the white background to highlight player marker.\n\tmm.bg = mm.root.AddPart().SetScale(110, 110, 1)\n\tmm.bg = mm.root.AddPart().SetScale(110, 110, 1)\n\tmm.bg.MakeModel(\"textured\", \"msh:icon\", \"tex:hudbg\")\n\n\t// create the sentinel position markers\n\tmm.spms = []*vu.Ent{}\n\tfor cnt := 0; cnt < numTroops; cnt++ {\n\t\ttpm := mm.root.AddPart()\n\t\ttpm.MakeModel(\"colored\", \"msh:square\", \"mat:tred\")\n\t\tmm.spms = append(mm.spms, tpm)\n\t}\n\n\t// create the player marker and center map marker.\n\tmm.cpm = mm.root.AddPart()\n\tmm.cpm.MakeModel(\"colored\", \"msh:square\", \"mat:blue\")\n\tmm.ppm = mm.root.AddPart()\n\tmm.ppm.MakeModel(\"colored\", \"msh:tri\", \"mat:tblack\")\n\treturn mm\n}\n\n// setVisible (un)hides all the minimap objects.\nfunc (mm *minimap) setVisible(isVisible bool) {\n\tmm.ui.Cull(!isVisible)\n}\n\n// Culled returns true if the given Pov is to far away from the player.\n// Used to limit the minimap view to map elements close to the player.\nfunc (mm *minimap) Culled(cam *vu.Camera, wx, wy, wz float64) bool {\n\tpx, py, _ := mm.ppm.World()\n\tdx := px - wx\n\tdy := py - wy\n\treturn (dx*dx + dy*dy) > float64(mm.radius*mm.radius)\n}\n\n// resize is responsible for keeping the minimap at the bottom\n// right corner of the application window.\nfunc (mm *minimap) resize(width, height int) {\n\tmm.x, mm.y, mm.w, mm.h = width-mm.radius-10, 125, width, height\n\tmm.top.SetAt(float64(mm.x), float64(mm.y), 0)\n}\n\n// setLevel is called when a level transition happens.\nfunc (mm *minimap) setLevel(cam *vu.Camera, lvl *level) {\n\tx, _, z := cam.At()\n\n\t// adjust the center location based on the game maze center.\n\tmm.cx, mm.cy = float64(lvl.gcx*lvl.units), float64(lvl.gcy*lvl.units)\n\tmm.ppm.SetAt(x, -z, 0)\n\tmm.bg.SetAt(x, -z, 0)\n\tmm.ppm.SetAa(0, 0, 1, lin.Rad(cam.Yaw))\n\tmm.setSentryAt(lvl.sentries)\n\tlvl.player.monitorHealth(\"mmap\", mm)\n}\n\n// addWall adds a block representing a wall to the minimap.\nfunc (mm *minimap) addWall(x, y float64) {\n\twall := mm.root.AddPart().SetAt(x, -y, 0)\n\twall.MakeModel(\"colored\", \"msh:square\", \"mat:gray\")\n}\n\n// addCore adds a small block representing an energy core to the minimap.\nfunc (mm *minimap) addCore(gamex, gamez float64) {\n\tcm := mm.root.AddPart().SetAt(gamex, -gamez, 0).SetScale(0.5, 0.5, 1)\n\tcm.MakeModel(\"colored\", \"msh:square\", \"mat:green\")\n\tmm.cores = append(mm.cores, cm)\n}\n\n// remCore removes a collected energy core from the minimap.\nfunc (mm *minimap) remCore(gamex, gamez float64) {\n\tgx, gy := lin.Round(gamex, 0), lin.Round(-gamez, 0)\n\tfor index, core := range mm.cores {\n\t\tcx, cy, _ := core.At()\n\t\tcx, cy = lin.Round(cx, 0), lin.Round(cy, 0)\n\t\tif cx == gx && cy == gy {\n\t\t\tcore.Dispose()\n\t\t\tmm.cores = append(mm.cores[:index], mm.cores[index+1:]...)\n\t\t\treturn\n\t\t}\n\t}\n\tlogf(\"hud.mapOverlay.remCore: failed to remove a core.\")\n}\n\n// resetCores is expected to be called when switching levels so that\n// this level is clear of cores the next time it is activated.\nfunc (mm *minimap) resetCores() {\n\tfor _, core := range mm.cores {\n\t\tcore.Dispose()\n\t}\n\tmm.cores = []*vu.Ent{}\n}\n\n// healthMonitor:healthUpdated. Update the center colour of the maze\n// based on the player health.\nfunc (mm *minimap) healthUpdated(health, warn, high int) {\n\tif health == high {\n\t\tmm.cpm.SetColor(0, 0.62, 0.6)\n\t} else {\n\t\tmm.cpm.SetColor(0.4, 0.5, 0.8)\n\t}\n}\n\n// update adjusts the minimap according to the players new position.\nfunc (mm *minimap) update(cam *vu.Camera, sentries []*sentinel) {\n\tx, _, z := cam.At()\n\tmm.root.SetAt(-x, z, 0)\n\tmm.setCenterAt(x, -z)\n\tmm.bg.SetAt(x, -z, 0)\n\tmm.ppm.SetAt(x, -z, 0)\n\tmm.ppm.SetAa(0, 0, 1, lin.Rad(cam.Yaw))\n\tmm.setSentryAt(sentries)\n}\n\n// set the position of the maze center marker. Ensure the center marker\n// is always visible to the player knows where the maze is if they wander\n// to far away.\nfunc (mm *minimap) setCenterAt(x, y float64) {\n\tradius := float64(mm.radius) / 5.1\n\ttoc := &lin.V3{X: x - mm.cx, Y: y - mm.cy, Z: 0} // vector from player to center\n\tdtoc := toc.Len()                                // distance to center\n\tmm.cpm.SetAt(mm.cx, mm.cy, 0)                    // set marker at center...\n\tif dtoc > radius {                               // ... unless the distance is to great\n\t\ttoc.Unit().Scale(toc, radius)\n\t\tmm.cpm.SetAt(x-toc.X, y-toc.Y, 0)\n\t}\n}\n\n// set the position for all the sentry markers.\nfunc (mm *minimap) setSentryAt(sentinels []*sentinel) {\n\tif len(mm.spms) != len(sentinels) {\n\t\tlogf(\"hud.minimap.setSentryAt: sentry length mismatch\")\n\t\treturn\n\t}\n\tfor cnt, sentry := range sentinels {\n\t\ttpm := mm.spms[cnt]\n\t\tx, _, z := sentry.location()\n\t\ttpm.SetAt(x, -z, 0)\n\t}\n}\n"}
{"sample": "package applog\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"os\"\n\t\"sync\"\n\t\"sysvipc\"\n\t\"time\"\n)\n\ntype LOG_LEVEL uint8\n\nconst (\n\tDEBUG     = LOG_LEVEL(0)\n\tINFO      = LOG_LEVEL(1)\n\tCLEAN     = LOG_LEVEL(2)\n\tEVENT     = LOG_LEVEL(3)\n\tWARN      = LOG_LEVEL(4)\n\tERROR     = LOG_LEVEL(5)\n\tFATAL     = LOG_LEVEL(6)\n\tMAX_LEVEL = LOG_LEVEL(7)\n)\n\nfunc Level2Str(l LOG_LEVEL) string {\n\tswitch l {\n\tcase DEBUG:\n\t\treturn \"DEBUG\"\n\tcase INFO:\n\t\treturn \"INFO\"\n\tcase CLEAN:\n\t\treturn \"CLEAN\"\n\tcase EVENT:\n\t\treturn \"EVENT\"\n\tcase WARN:\n\t\treturn \"WARN\"\n\tcase ERROR:\n\t\treturn \"ERROR\"\n\tcase FATAL:\n\t\treturn \"FATAL\"\n\tdefault:\n\t\treturn \"UNDEFINE\"\n\t}\n}\n\ntype Logger struct {\n\tLogPath     string\n\tLogFilename string\n\tLogFullpath string\n\tAppName     string\n\tmutex       sync.Mutex\n}\n\nvar g_logger Logger\nvar g_debug_flag = false\nvar g_stdout_flag = false\nvar g_log_cfg *LogCfg\nvar g_mq sysvipc.MessageQueue\nvar g_log_available = false\n\nfunc Config() *LogCfg {\n\treturn g_log_cfg\n}\n\nfunc Log() *Logger {\n\treturn &g_logger\n}\n\nfunc DumpLog() string {\n\treturn fmt.Sprintf(\"LogPath: %s\\nLogFilename: %s\\nLogFullpath: %s\\nAppName: %s\\n\", g_logger.LogPath, g_logger.LogFilename, g_logger.LogFullpath, g_logger.AppName)\n}\n\nfunc InitLog(filename string, app_name string) error {\n\tg_logger.mutex.Lock()\n\tdefer g_logger.mutex.Unlock()\n\n\tif len(g_log_cfg.LogPath) < 1 || len(filename) < 1 || len(app_name) < 1 {\n\t\treturn errors.New(fmt.Sprintf(\"InitLog: invalid arguments path[%s] filename[%s] app_name[%s]\", g_log_cfg.LogPath, filename, app_name))\n\t}\n\t/* if filename == \"mq\"||\"MQ\u201c do not write to file */\n\tif filename != \"mq\" || filename != \"MQ\" {\n\t\terr := ValidateFile(g_log_cfg.LogPath + \"/\" + filename)\n\t\tif err != nil {\n\t\t\treturn errors.New(fmt.Sprintf(\"InitLog [%s/%s] failed, %v\", g_log_cfg.LogPath, filename, err))\n\t\t}\n\t\tg_logger.LogPath = g_log_cfg.LogPath\n\t} else {\n\t\tg_logger.LogPath = \"mq\"\n\t}\n\tg_logger.LogFilename = filename\n\tg_logger.LogFullpath = g_log_cfg.LogPath + \"/\" + filename\n\tg_logger.AppName = app_name\n\tg_log_available = true\n\treturn nil\n}\n\nfunc LoadLogCfg(config_file string) error {\n\tvar cfg LogCfg\n\terr := cfg.Load(config_file)\n\tif err != nil {\n\t\treturn err\n\t}\n\tmq, err := sysvipc.GetMsgQueue(cfg.MQID, &sysvipc.MQFlags{true, false, 0660})\n\tif err != nil {\n\t\treturn err\n\t}\n\tg_log_cfg = &cfg\n\tg_mq = mq\n\n\treturn nil\n}\n\nfunc DebugLog(d bool) {\n\tg_debug_flag = d\n}\n\nfunc StdoutLog(s bool) {\n\tg_stdout_flag = s\n}\n\nfunc IncreaseKpi(kpi_name string) error {\n\treturn WriteKpi(kpi_name, 1)\n}\n\nfunc DecreaseKpi(kpi_name string) error {\n\treturn WriteKpi(kpi_name, 1)\n}\n\nfunc WriteKpi(kpi_name string, delta int64) error {\n\tg_logger.mutex.Lock()\n\tdefer g_logger.mutex.Unlock()\n\tif g_log_cfg == nil {\n\t\treturn errors.New(\"WriteKpi failed, mq not initialized\")\n\t}\n\toid, err := g_log_cfg.GetKpiOid(kpi_name)\n\tif err != nil {\n\t\treturn errors.New(\"WriteKpi failed, invalid kpi_name \" + kpi_name)\n\t}\n\tkpi_line := fmt.Sprintf(\"%s|%d\", oid, delta)\n\t//fmt.Printf(\"WriteKpi [%s][%v]\\n\", kpi_line, []byte(kpi_line))\n\tg_mq.Send(KPI_MSG_TYPE, []byte(kpi_line), &sysvipc.MQSendFlags{true})\n\treturn nil\n}\n\nfunc Db(format string, v ...interface{}) {\n\tWriteLog(DEBUG, \"\", format, v...)\n}\n\nfunc Info(format string, v ...interface{}) {\n\tWriteLog(INFO, \"\", format, v...)\n}\n\nfunc WriteLog(level LOG_LEVEL, alarm_name string, format string, v ...interface{}) {\n\tg_logger.mutex.Lock()\n\tdefer g_logger.mutex.Unlock()\n\n\tts := time.Now().Format(\"20060102-150405.000\")\n\tif !g_debug_flag && level == DEBUG {\n\t\treturn\n\t}\n\tline := ts + \"|\" + g_logger.AppName + \"|\" + Level2Str(level) + \"|\" + fmt.Sprintf(format, v...)\n\tif g_stdout_flag || !g_log_available { //if no log file available print to stdout\n\t\tfmt.Println(line)\n\t}\n\tif !g_log_available { //simple mode, only write to stdout\n\t\treturn\n\t}\n\n\tif g_logger.LogFilename == \"mq\" {\n\t\terr := g_mq.Send(LOG_MSG_TYPE, []byte(line+\"\\n\"), &sysvipc.MQSendFlags{true})\n\t\tif err != nil {\n\t\t\tfmt.Printf(\"log failed to write to mq: %s\\n\", line)\n\t\t\treturn\n\t\t}\n\t} else {\n\t\tf, err := os.OpenFile(g_logger.LogFullpath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0644)\n\t\tif err != nil {\n\t\t\t//fmt.Printf(\"WriteLog [%s] failed\\n\", g_logger.LogFullpath)\n\t\t\tfmt.Println(err)\n\t\t\treturn\n\t\t}\n\t\tdefer f.Close()\n\t\tf.Write([]byte(line + \"\\n\"))\n\t}\n\n\t////////////// write alarm string to mq ///////////////\n\t/*20160514030208|DC:AOC_001:C001|ERROR|.1.3.6.1.4.1.193.176.3.4.2|Cannot connect to backup DCC server. ip address: , port: 0. Invalid ip address or port. The current instance of dcc_client is DC:AOC_001:C001*/\n\tif g_log_cfg != nil && level > INFO && level < MAX_LEVEL {\n\t\toid, err := g_log_cfg.GetAlarmOid(alarm_name)\n\t\tif err != nil || oid == NO_ALARM {\n\t\t\treturn\n\t\t}\n\t\talarm_line := fmt.Sprintf(\"%s|%s|%s|.%s|%s\", time.Now().Format(\"20060102150405\"), g_logger.AppName, Level2Str(level), oid, fmt.Sprintf(format, v...))\n\t\t//fmt.Printf(\"WriteAlarm [%s][%v]\\n\", alarm_line, []byte(alarm_line))\n\t\tg_mq.Send(ALARM_MSG_TYPE, []byte(alarm_line), &sysvipc.MQSendFlags{true})\n\t}\n}\n"}
{"sample": "/*\nLandscape omnikeeper REST API\n\nNo description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)\n\nAPI version: v1\n*/\n\n// Code generated by OpenAPI Generator (https://openapi-generator.tech); DO NOT EDIT.\n\npackage okclient\n\nimport (\n\t\"encoding/json\"\n)\n\n// ChangeDataRequest struct for ChangeDataRequest\ntype ChangeDataRequest struct {\n\tSparseRows []SparseRow `json:\"sparseRows,omitempty\"`\n}\n\n// NewChangeDataRequest instantiates a new ChangeDataRequest object\n// This constructor will assign default values to properties that have it defined,\n// and makes sure properties required by API are set, but the set of arguments\n// will change when the set of required properties is changed\nfunc NewChangeDataRequest() *ChangeDataRequest {\n\tthis := ChangeDataRequest{}\n\treturn &this\n}\n\n// NewChangeDataRequestWithDefaults instantiates a new ChangeDataRequest object\n// This constructor will only assign default values to properties that have it defined,\n// but it doesn't guarantee that properties required by API are set\nfunc NewChangeDataRequestWithDefaults() *ChangeDataRequest {\n\tthis := ChangeDataRequest{}\n\treturn &this\n}\n\n// GetSparseRows returns the SparseRows field value if set, zero value otherwise (both if not set or set to explicit null).\nfunc (o *ChangeDataRequest) GetSparseRows() []SparseRow {\n\tif o == nil  {\n\t\tvar ret []SparseRow\n\t\treturn ret\n\t}\n\treturn o.SparseRows\n}\n\n// GetSparseRowsOk returns a tuple with the SparseRows field value if set, nil otherwise\n// and a boolean to check if the value has been set.\n// NOTE: If the value is an explicit nil, `nil, true` will be returned\nfunc (o *ChangeDataRequest) GetSparseRowsOk() (*[]SparseRow, bool) {\n\tif o == nil || o.SparseRows == nil {\n\t\treturn nil, false\n\t}\n\treturn &o.SparseRows, true\n}\n\n// HasSparseRows returns a boolean if a field has been set.\nfunc (o *ChangeDataRequest) HasSparseRows() bool {\n\tif o != nil && o.SparseRows != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// SetSparseRows gets a reference to the given []SparseRow and assigns it to the SparseRows field.\nfunc (o *ChangeDataRequest) SetSparseRows(v []SparseRow) {\n\to.SparseRows = v\n}\n\nfunc (o ChangeDataRequest) MarshalJSON() ([]byte, error) {\n\ttoSerialize := map[string]interface{}{}\n\tif o.SparseRows != nil {\n\t\ttoSerialize[\"sparseRows\"] = o.SparseRows\n\t}\n\treturn json.Marshal(toSerialize)\n}\n\ntype NullableChangeDataRequest struct {\n\tvalue *ChangeDataRequest\n\tisSet bool\n}\n\nfunc (v NullableChangeDataRequest) Get() *ChangeDataRequest {\n\treturn v.value\n}\n\nfunc (v *NullableChangeDataRequest) Set(val *ChangeDataRequest) {\n\tv.value = val\n\tv.isSet = true\n}\n\nfunc (v NullableChangeDataRequest) IsSet() bool {\n\treturn v.isSet\n}\n\nfunc (v *NullableChangeDataRequest) Unset() {\n\tv.value = nil\n\tv.isSet = false\n}\n\nfunc NewNullableChangeDataRequest(val *ChangeDataRequest) *NullableChangeDataRequest {\n\treturn &NullableChangeDataRequest{value: val, isSet: true}\n}\n\nfunc (v NullableChangeDataRequest) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(v.value)\n}\n\nfunc (v *NullableChangeDataRequest) UnmarshalJSON(src []byte) error {\n\tv.isSet = true\n\treturn json.Unmarshal(src, &v.value)\n}\n\n\n"}
{"sample": "package resource\n\nimport (\n\t\"net/http\"\n\t\"strings\"\n\n\t\"github.com/bmc-toolbox/dora/filter\"\n\t\"github.com/bmc-toolbox/dora/model\"\n\t\"github.com/bmc-toolbox/dora/storage\"\n\t\"github.com/jinzhu/gorm\"\n\t\"github.com/manyminds/api2go\"\n)\n\n// ScannedPortResource for api2go routes\ntype ScannedPortResource struct {\n\tScannedPortStorage *storage.ScannedPortStorage\n}\n\n// FindAll Scans\nfunc (s ScannedPortResource) FindAll(r api2go.Request) (api2go.Responder, error) {\n\t_, scans, err := s.queryAndCountAllWrapper(r)\n\treturn &Response{Res: scans}, err\n}\n\n// FindOne Scanner\nfunc (s ScannedPortResource) FindOne(ID string, r api2go.Request) (api2go.Responder, error) {\n\tres, err := s.ScannedPortStorage.GetOne(strings.Replace(ID, \"-\", \"/\", -1))\n\tif err == gorm.ErrRecordNotFound {\n\t\treturn &Response{}, api2go.NewHTTPError(err, err.Error(), http.StatusNotFound)\n\t}\n\treturn &Response{Res: res}, err\n}\n\n// PaginatedFindAll can be used to load Scans in chunks\nfunc (s ScannedPortResource) PaginatedFindAll(r api2go.Request) (uint, api2go.Responder, error) {\n\tcount, scans, err := s.queryAndCountAllWrapper(r)\n\treturn uint(count), &Response{Res: scans}, err\n}\n\n// queryAndCountAllWrapper retrieve the data to be used for FindAll and PaginatedFindAll in a standard way\nfunc (s ScannedPortResource) queryAndCountAllWrapper(r api2go.Request) (count int, scans []model.ScannedPort, err error) {\n\tfor _, invalidQuery := range []string{\"page[number]\", \"page[size]\"} {\n\t\t_, invalid := r.QueryParams[invalidQuery]\n\t\tif invalid {\n\t\t\treturn count, scans, ErrPageSizeAndNumber\n\t\t}\n\t}\n\n\tfilters, hasFilters := filter.NewFilterSet(&r)\n\toffset, limit := filter.OffSetAndLimitParse(&r)\n\n\tif hasFilters {\n\t\tcount, scans, err = s.ScannedPortStorage.GetAllByFilters(offset, limit, filters)\n\t\tfilters.Clean()\n\t\tif err != nil {\n\t\t\treturn count, scans, err\n\t\t}\n\t}\n\n\tif !hasFilters {\n\t\tcount, scans, err = s.ScannedPortStorage.GetAll(offset, limit)\n\t\tif err != nil {\n\t\t\treturn count, scans, err\n\t\t}\n\t}\n\n\treturn count, scans, err\n}\n"}
{"sample": "//   Copyright 2016 DigitalOcean\n//\n//   Licensed under the Apache License, Version 2.0 (the \"License\");\n//   you may not use this file except in compliance with the License.\n//   You may obtain a copy of the License at\n//\n//       http://www.apache.org/licenses/LICENSE-2.0\n//\n//   Unless required by applicable law or agreed to in writing, software\n//   distributed under the License is distributed on an \"AS IS\" BASIS,\n//   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//   See the License for the specific language governing permissions and\n//   limitations under the License.\n\n// Command ceph_exporter provides a Prometheus exporter for a Ceph cluster.\npackage main\n\nimport (\n\t\"flag\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"sync\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/ceph/go-ceph/rados\"\n\t\"github.com/phpor/ceph_exporter/collectors\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n)\n\n// This horrible thing is a copy of tcpKeepAliveListener, tweaked to\n// specifically check if it hits EMFILE when doing an accept, and if so,\n// terminate the process.\n\ntype emfileAwareTcpListener struct {\n\t*net.TCPListener\n}\n\nfunc (ln emfileAwareTcpListener) Accept() (c net.Conn, err error) {\n\ttc, err := ln.AcceptTCP()\n\tif err != nil {\n\t\tif oerr, ok := err.(*net.OpError); ok {\n\t\t\tif serr, ok := oerr.Err.(*os.SyscallError); ok && serr.Err == syscall.EMFILE {\n\t\t\t\t// This calls os.Exit(1) and terminates the process\n\t\t\t\tlog.Fatalf(\"%v\", err)\n\t\t\t}\n\t\t}\n\t\t// Default return\n\t\treturn\n\t}\n\ttc.SetKeepAlive(true)\n\ttc.SetKeepAlivePeriod(3 * time.Minute)\n\treturn tc, nil\n}\n\n// CephExporter wraps all the ceph collectors and provides a single global\n// exporter to extracts metrics out of. It also ensures that the collection\n// is done in a thread-safe manner, the necessary requirement stated by\n// prometheus. It also implements a prometheus.Collector interface in order\n// to register it correctly.\ntype CephExporter struct {\n\tmu         sync.Mutex\n\tcollectors []prometheus.Collector\n}\n\n// Verify that the exporter implements the interface correctly.\nvar _ prometheus.Collector = &CephExporter{}\n\n// NewCephExporter creates an instance to CephExporter and returns a reference\n// to it. We can choose to enable a collector to extract stats out of by adding\n// it to the list of collectors.\nfunc NewCephExporter(conn *rados.Conn, cluster string) *CephExporter {\n\treturn &CephExporter{\n\t\tcollectors: []prometheus.Collector{\n\t\t\tcollectors.NewClusterUsageCollector(conn, cluster),\n\t\t\tcollectors.NewPoolUsageCollector(conn, cluster),\n\t\t\tcollectors.NewClusterHealthCollector(conn, cluster),\n\t\t\tcollectors.NewMonitorCollector(conn, cluster),\n\t\t\tcollectors.NewOSDCollector(conn, cluster),\n\t\t},\n\t}\n}\n\n// Describe sends all the descriptors of the collectors included to\n// the provided channel.\nfunc (c *CephExporter) Describe(ch chan<- *prometheus.Desc) {\n\tfor _, cc := range c.collectors {\n\t\tcc.Describe(ch)\n\t}\n}\n\n// Collect sends the collected metrics from each of the collectors to\n// prometheus. Collect could be called several times concurrently\n// and thus its run is protected by a single mutex.\nfunc (c *CephExporter) Collect(ch chan<- prometheus.Metric) {\n\tc.mu.Lock()\n\tdefer c.mu.Unlock()\n\n\tfor _, cc := range c.collectors {\n\t\tcc.Collect(ch)\n\t}\n}\n\nfunc main() {\n\tvar (\n\t\taddr        = flag.String(\"telemetry.addr\", \":9128\", \"host:port for ceph exporter\")\n\t\tmetricsPath = flag.String(\"telemetry.path\", \"/metrics\", \"URL path for surfacing collected metrics\")\n\t\tcephConfig  = flag.String(\"ceph.config\", \"\", \"path to ceph config file\")\n\t\tcephUser    = flag.String(\"ceph.user\", \"admin\", \"Ceph user to connect to cluster.\")\n\n\t\texporterConfig = flag.String(\"exporter.config\", \"/etc/ceph/exporter.yml\", \"Path to ceph exporter config.\")\n\t)\n\tflag.Parse()\n\n\tif fileExists(*exporterConfig) {\n\n\t\tcfg, err := ParseConfig(*exporterConfig)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Error: %v\", err)\n\t\t}\n\n\t\tfor _, cluster := range cfg.Cluster {\n\n\t\t\tconn, err := rados.NewConnWithUser(cluster.User)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatalf(\"cannot create new ceph connection: %s\", err)\n\t\t\t}\n\n\t\t\terr = conn.ReadConfigFile(cluster.ConfigFile)\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatalf(\"cannot read ceph config file: %s\", err)\n\t\t\t}\n\n\t\t\tif err := conn.Connect(); err != nil {\n\t\t\t\tlog.Fatalf(\"cannot connect to ceph cluster: %s\", err)\n\t\t\t}\n\t\t\t// defer Shutdown to program exit\n\t\t\tdefer conn.Shutdown()\n\n\t\t\tlog.Printf(\"Starting ceph exporter for cluster: %s\", cluster.ClusterLabel)\n\t\t\terr = prometheus.Register(NewCephExporter(conn, cluster.ClusterLabel))\n\t\t\tif err != nil {\n\t\t\t\tlog.Fatalf(\"cannot export cluster: %s error: %v\", cluster.ClusterLabel, err)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tconn, err := rados.NewConnWithUser(*cephUser)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"cannot create new ceph connection: %s\", err)\n\t\t}\n\n\t\tif *cephConfig != \"\" {\n\t\t\terr = conn.ReadConfigFile(*cephConfig)\n\t\t} else {\n\t\t\terr = conn.ReadDefaultConfigFile()\n\t\t}\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"cannot read ceph config file: %s\", err)\n\t\t}\n\n\t\tif err := conn.Connect(); err != nil {\n\t\t\tlog.Fatalf(\"cannot connect to ceph cluster: %s\", err)\n\t\t}\n\t\tdefer conn.Shutdown()\n\n\t\tprometheus.MustRegister(NewCephExporter(conn, \"ceph\"))\n\t}\n\n\thttp.Handle(*metricsPath, promhttp.Handler())\n\thttp.HandleFunc(\"/\", func(w http.ResponseWriter, r *http.Request) {\n\t\tw.Write([]byte(`<html>\n\t\t\t<head><title>Ceph Exporter</title></head>\n\t\t\t<body>\n\t\t\t<h1>Ceph Exporter</h1>\n\t\t\t<p><a href='` + *metricsPath + `'>Metrics</a></p>\n\t\t\t</body>\n\t\t\t</html>`))\n\t})\n\n\tlog.Printf(\"Starting ceph exporter on %q\", *addr)\n\t// Below is essentially http.ListenAndServe(), but using our custom\n\t// emfileAwareTcpListener that will die if we run out of file descriptors\n\tln, err := net.Listen(\"tcp\", *addr)\n\tif err == nil {\n\t\terr := http.Serve(emfileAwareTcpListener{ln.(*net.TCPListener)}, nil)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"unable to serve requests: %s\", err)\n\t\t}\n\t}\n\tif err != nil {\n\t\tlog.Fatalf(\"unable to create listener: %s\", err)\n\t}\n}\n"}
{"sample": "/**\n * @Author         : s1m0n21\n * @Description    : Answer of https://leetcode-cn.com/problems/reshape-the-matrix/\n * @Project        : leetcode-go\n * @File           : answer.go\n * @Date           : 2022/1/13 12:39 PM\n */\n\npackage _reshape_the_matrix\n\nfunc matrixReshape(mat [][]int, r int, c int) [][]int {\n\tm, n := len(mat), len(mat[0])\n\tif m*n != r*c {\n\t\treturn mat\n\t}\n\n\tans := make([][]int, r)\n\tfor i := range ans {\n\t\tans[i] = make([]int, c)\n\t}\n\n\tx, y := 0, 0\n\tfor i := 0; i < m; i++ {\n\t\tfor j := 0; j < n; j++ {\n\t\t\tans[x][y] = mat[i][j]\n\t\t\tif y+1 < c {\n\t\t\t\ty++\n\t\t\t} else {\n\t\t\t\tx++\n\t\t\t\ty = 0\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ans\n}\n"}
{"sample": "// Package pipeline contains objects for processing by a conveyor\npackage pipeline\n\nimport (\n\t\"fmt\"\n\t\"strings\"\n\t\"yabs/common/format\"\n\t\"yabs/common/format/minidump\"\n\t\"regexp\"\n)\n\n// Pipeline stage\ntype Stage interface {\n\t//Process the report\n\t//If return true then pipeline stop\n\tProcess(report *minidump.Report, info *format.Info) bool\n}\n\ntype SignatureAndSource struct {\n\tStage\n}\n\ntype MinidumpStackUnfolding struct {\n\tStage\n}\n\nfunc (m *SignatureAndSource) Process(report *minidump.Report, info *format.Info) bool {\n\tif len(report.CrashingThread.Frames) > 0 {\n\t\tframe := &report.CrashingThread.Frames[0]\n\t\tsignature := frame.Function\n\t\tsource := fmt.Sprintf(\"%s:%d\", frame.File,\n\t\t\tframe.Line)\n\t\treport.Signature = signature\n\t\treport.Source = source\n\t}\n\n\treturn false\n}\n\nfunc (m *MinidumpStackUnfolding) Process(report *minidump.Report, info *format.Info) bool {\n\tframes := report.CrashingThread.Frames\n\tif len(report.CrashingThread.Frames) == 0 {\n\t\t// go to next stage\n\t\treturn false\n\t}\n\n\tiqoption := regexp.MustCompile(\"iq\\\\s*option\")\n\tfor _, frame := range frames {\n\t\tmodule := strings.ToLower(frame.Module)\n\t\tif iqoption.MatchString(module) {\n\t\t\treport.Signature = frame.Function\n\t\t\treport.Source = fmt.Sprintf(\"%s:%d\", frame.File,\n\t\t\t\tframe.Line)\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn true\n}\n"}
{"sample": "/* Copyright 2020 The Bazel Authors. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n   http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\n// This test file was first seen on:\n// https://github.com/bazelbuild/bazel-skylib/blob/f80bc733d4b9f83d427ce3442be2e07427b2cc8d/gazelle/bzl/BUILD.\n// It was modified for the needs of this extension.\n\npackage js\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/bazelbuild/bazel-gazelle/testtools\"\n\t\"github.com/bazelbuild/rules_go/go/tools/bazel\"\n\t\"github.com/emirpasic/gods/lists/singlylinkedlist\"\n\t\"github.com/ghodss/yaml\"\n)\n\nconst (\n\textensionDir      = \"gazelle/\"\n\ttestDataPath      = extensionDir + \"testdata/\"\n\tgazelleBinaryName = \"gazelle_bin\"\n)\n\nvar gazellePath = mustFindGazelle()\n\nfunc TestGazelleBinary(t *testing.T) {\n\ttests := map[string][]bazel.RunfileEntry{}\n\n\trunfiles, err := bazel.ListRunfiles()\n\tif err != nil {\n\t\tt.Fatalf(\"bazel.ListRunfiles() error: %v\", err)\n\t}\n\tfor _, f := range runfiles {\n\t\tif strings.HasPrefix(f.ShortPath, testDataPath) {\n\t\t\trelativePath := strings.TrimPrefix(f.ShortPath, testDataPath)\n\t\t\tparts := strings.SplitN(relativePath, \"/\", 2)\n\t\t\tif len(parts) < 2 {\n\t\t\t\t// This file is not a part of a testcase since it must be in a dir that\n\t\t\t\t// is the test case and then have a path inside of that.\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\ttests[parts[0]] = append(tests[parts[0]], f)\n\t\t}\n\t}\n\tif len(tests) == 0 {\n\t\tt.Fatal(\"no tests found\")\n\t}\n\n\tfor testName, files := range tests {\n\t\tfmt.Println(t)\n\t\ttestPath(t, testName, files)\n\t}\n}\n\nfunc testPath(t *testing.T, name string, files []bazel.RunfileEntry) {\n\tt.Run(name, func(t *testing.T) {\n\t\tvar inputs []testtools.FileSpec\n\t\tvar goldens []testtools.FileSpec\n\n\t\tvar config *testYAML\n\t\tfor _, f := range files {\n\t\t\tpath := f.Path\n\t\t\ttrim := testDataPath + name + \"/\"\n\t\t\tshortPath := strings.TrimPrefix(f.ShortPath, trim)\n\t\t\tinfo, err := os.Stat(path)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"os.Stat(%q) error: %v\", path, err)\n\t\t\t}\n\n\t\t\tif info.IsDir() {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tcontent, err := ioutil.ReadFile(path)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"ioutil.ReadFile(%q) error: %v\", path, err)\n\t\t\t}\n\n\t\t\tif filepath.Base(shortPath) == \"test.yaml\" {\n\t\t\t\tif config != nil {\n\t\t\t\t\tt.Fatal(\"only 1 test.yaml is supported\")\n\t\t\t\t}\n\t\t\t\tconfig = new(testYAML)\n\t\t\t\tif err := yaml.Unmarshal(content, config); err != nil {\n\t\t\t\t\tt.Fatal(err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif strings.HasSuffix(shortPath, \".in\") {\n\t\t\t\tinputs = append(inputs, testtools.FileSpec{\n\t\t\t\t\tPath:    filepath.Join(name, strings.TrimSuffix(shortPath, \".in\")),\n\t\t\t\t\tContent: string(content),\n\t\t\t\t})\n\t\t\t} else if strings.HasSuffix(shortPath, \".out\") {\n\t\t\t\tgoldens = append(goldens, testtools.FileSpec{\n\t\t\t\t\tPath:    filepath.Join(name, strings.TrimSuffix(shortPath, \".out\")),\n\t\t\t\t\tContent: string(content),\n\t\t\t\t})\n\t\t\t} else {\n\t\t\t\tinputs = append(inputs, testtools.FileSpec{\n\t\t\t\t\tPath:    filepath.Join(name, shortPath),\n\t\t\t\t\tContent: string(content),\n\t\t\t\t})\n\t\t\t\tgoldens = append(goldens, testtools.FileSpec{\n\t\t\t\t\tPath:    filepath.Join(name, shortPath),\n\t\t\t\t\tContent: string(content),\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\ttestdataDir, cleanup := testtools.CreateFiles(t, inputs)\n\t\tdefer cleanup()\n\t\tdefer func() {\n\t\t\tif t.Failed() {\n\t\t\t\tfilepath.Walk(testdataDir, func(path string, info os.FileInfo, err error) error {\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tt.Logf(\"%q exists\", strings.TrimPrefix(path, testdataDir))\n\t\t\t\t\treturn nil\n\t\t\t\t})\n\t\t\t}\n\t\t}()\n\n\t\tworkspaceRoot := filepath.Join(testdataDir, name)\n\n\t\targs := []string{\"-build_file_name=BUILD,BUILD.bazel\"}\n\n\t\tctx, cancel := context.WithTimeout(context.Background(), 2*time.Second)\n\t\tdefer cancel()\n\t\tcmd := exec.CommandContext(ctx, gazellePath, args...)\n\t\tvar stdout, stderr bytes.Buffer\n\t\tcmd.Stdout = &stdout\n\t\tcmd.Stderr = &stderr\n\t\tcmd.Dir = workspaceRoot\n\t\tif err := cmd.Run(); err != nil {\n\t\t\tvar e *exec.ExitError\n\t\t\tif !errors.As(err, &e) {\n\t\t\t\tt.Fatal(err)\n\t\t\t}\n\t\t}\n\t\terrs := singlylinkedlist.New()\n\t\tactualExitCode := cmd.ProcessState.ExitCode()\n\t\tif config.Expect.ExitCode != actualExitCode {\n\t\t\terrs.Add(fmt.Errorf(\"expected gazelle exit code: %d\\ngot: %d\",\n\t\t\t\tconfig.Expect.ExitCode, actualExitCode,\n\t\t\t))\n\t\t}\n\t\tactualStdout := stdout.String()\n\t\tif strings.TrimSpace(config.Expect.Stdout) != strings.TrimSpace(actualStdout) {\n\t\t\terrs.Add(fmt.Errorf(\"expected gazelle stdout: %s\\ngot: %s\",\n\t\t\t\tconfig.Expect.Stdout, actualStdout,\n\t\t\t))\n\t\t}\n\t\tactualStderr := stderr.String()\n\t\tif strings.TrimSpace(config.Expect.Stderr) != strings.TrimSpace(actualStderr) {\n\t\t\terrs.Add(fmt.Errorf(\"expected gazelle stderr: %s\\ngot: %s\",\n\t\t\t\tconfig.Expect.Stderr, actualStderr,\n\t\t\t))\n\t\t}\n\t\tif !errs.Empty() {\n\t\t\terrsIt := errs.Iterator()\n\t\t\tfor errsIt.Next() {\n\t\t\t\terr := errsIt.Value().(error)\n\t\t\t\tt.Log(err)\n\t\t\t}\n\t\t\tt.FailNow()\n\t\t}\n\n\t\ttesttools.CheckFiles(t, testdataDir, goldens)\n\t})\n}\n\nfunc mustFindGazelle() string {\n\tgazellePath, ok := bazel.FindBinary(\"\", gazelleBinaryName)\n\tif !ok {\n\t\tpanic(\"could not find gazelle binary\")\n\t}\n\treturn gazellePath\n}\n\ntype testYAML struct {\n\tExpect struct {\n\t\tExitCode int    `json:\"exit_code\"`\n\t\tStdout   string `json:\"stdout\"`\n\t\tStderr   string `json:\"stderr\"`\n\t} `json:\"expect\"`\n}\n"}
{"sample": "package validate\n\nimport \"fmt\"\n\nfunc StreamAnalyticsJobStreamingUnits(i interface{}, k string) (w []string, es []error) {\n\tv, ok := i.(int)\n\tif !ok {\n\t\tes = append(es, fmt.Errorf(\"expected type of %s to be int\", k))\n\t\treturn\n\t}\n\n\t//  Property 'streamingUnits' value '5' is not in the acceptable set: '1','3','6','12', and multiples of 6 up to your quota\"\n\tif v == 1 || v == 3 {\n\t\treturn\n\t}\n\n\tif v < 1 || v > 120 {\n\t\tes = append(es, fmt.Errorf(\"expected %s to be in the range (1 - 120), got %d\", k, v))\n\t\treturn\n\t}\n\n\tif v%6 != 0 {\n\t\tes = append(es, fmt.Errorf(\"expected %s to be divisible by 6, got %d\", k, v))\n\t\treturn\n\t}\n\n\treturn\n}\n"}
{"sample": "package colorjson\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/fatih/color\"\n)\n\nconst initialDepth = 0\nconst valueSep = \",\"\nconst null = \"null\"\nconst startMap = \"{\"\nconst endMap = \"}\"\nconst startArray = \"[\"\nconst endArray = \"]\"\n\nconst emptyMap = startMap + endMap\nconst emptyArray = startArray + endArray\n\nvar stripColorsRegEx = regexp.MustCompile(`\\x1b\\[[0-9;]*m`)\n\ntype Object map[string]interface{}\n\ntype Formatter struct {\n\tKeyColor        *color.Color\n\tStringColor     *color.Color\n\tBoolColor       *color.Color\n\tNumberColor     *color.Color\n\tNullColor       *color.Color\n\tStringMaxLength int\n\tIndent          int\n\tDisabledColor   bool\n\tHTMLEscape      bool\n\tRawStrings      bool\n\tKeyMapColors    map[string]*color.Color\n}\n\nfunc NewFormatter() *Formatter {\n\treturn &Formatter{\n\t\tKeyColor:        color.New(color.FgWhite),\n\t\tStringColor:     color.New(color.FgGreen),\n\t\tBoolColor:       color.New(color.FgYellow),\n\t\tNumberColor:     color.New(color.FgCyan),\n\t\tNullColor:       color.New(color.FgMagenta),\n\t\tStringMaxLength: 0,\n\t\tDisabledColor:   false,\n\t\tIndent:          0,\n\t\tRawStrings:      false,\n\t\tKeyMapColors:    map[string]*color.Color{},\n\t}\n}\n\n//nolint unused\nfunc (f *Formatter) sprintfColor(key string, c *color.Color, format string, args ...interface{}) string {\n\tif f.KeyMapColors[key] != nil {\n\t\tc = f.KeyMapColors[key]\n\t}\n\tif f.DisabledColor || c == nil {\n\t\treturn fmt.Sprintf(format, args...)\n\t}\n\treturn c.SprintfFunc()(format, args...)\n}\n\nfunc (f *Formatter) sprintColor(key string, c *color.Color, s string) string {\n\tif f.KeyMapColors[key] != nil {\n\t\tc = f.KeyMapColors[key]\n\t}\n\tif f.DisabledColor || c == nil {\n\t\treturn fmt.Sprint(s)\n\t}\n\treturn c.SprintFunc()(s)\n}\n\nfunc (f *Formatter) writeIndent(buf *bytes.Buffer, depth int) {\n\tbuf.WriteString(strings.Repeat(\" \", f.Indent*depth))\n}\n\nfunc (f *Formatter) writeObjSep(buf *bytes.Buffer) {\n\tif f.Indent != 0 {\n\t\tbuf.WriteByte('\\n')\n\t} else {\n\t\tbuf.WriteByte(' ')\n\t}\n}\n\nfunc (f *Formatter) Marshal(jsonObj interface{}) ([]byte, error) {\n\tbuffer := bytes.Buffer{}\n\tf.marshalValue(\"\", jsonObj, &buffer, initialDepth)\n\tif f.DisabledColor {\n\t\treturn stripColorsRegEx.ReplaceAll(buffer.Bytes(), []byte(\"\")), nil\n\t}\n\treturn buffer.Bytes(), nil\n}\n\nfunc (f *Formatter) MarshalString(jsonObj interface{}) (string, error) {\n\tb, err := f.Marshal(jsonObj)\n\treturn string(b), err\n}\n\nfunc (f *Formatter) marshalMap(m map[string]interface{}, buf *bytes.Buffer, depth int) {\n\tremaining := len(m)\n\n\tif remaining == 0 {\n\t\tbuf.WriteString(emptyMap)\n\t\treturn\n\t}\n\n\tkeys := make([]string, 0)\n\tfor key := range m {\n\t\tkeys = append(keys, key)\n\t}\n\n\tsort.Strings(keys)\n\n\tbuf.WriteString(startMap)\n\tf.writeObjSep(buf)\n\n\tfor _, key := range keys {\n\t\tf.writeIndent(buf, depth+1)\n\t\tbuf.WriteString(f.KeyColor.Sprintf(\"\\\"%s\\\": \", key))\n\t\tf.marshalValue(key, m[key], buf, depth+1)\n\t\tremaining--\n\t\tif remaining != 0 {\n\t\t\tbuf.WriteString(valueSep)\n\t\t}\n\t\tf.writeObjSep(buf)\n\t}\n\tf.writeIndent(buf, depth)\n\tbuf.WriteString(endMap)\n}\n\nfunc (f *Formatter) marshalArray(key string, a []interface{}, buf *bytes.Buffer, depth int) {\n\tif len(a) == 0 {\n\t\tbuf.WriteString(emptyArray)\n\t\treturn\n\t}\n\n\tbuf.WriteString(startArray)\n\tf.writeObjSep(buf)\n\n\tfor i, v := range a {\n\t\tf.writeIndent(buf, depth+1)\n\t\tf.marshalValue(key, v, buf, depth+1)\n\t\tif i < len(a)-1 {\n\t\t\tbuf.WriteString(valueSep)\n\t\t}\n\t\tf.writeObjSep(buf)\n\t}\n\tf.writeIndent(buf, depth)\n\tbuf.WriteString(endArray)\n}\n\nfunc (f *Formatter) marshalIntArray(key string, a []int, buf *bytes.Buffer, depth int) {\n\tif len(a) == 0 {\n\t\tbuf.WriteString(emptyArray)\n\t\treturn\n\t}\n\n\tbuf.WriteString(startArray)\n\tf.writeObjSep(buf)\n\n\tfor i, v := range a {\n\t\tf.writeIndent(buf, depth+1)\n\t\tf.marshalValue(key, v, buf, depth+1)\n\t\tif i < len(a)-1 {\n\t\t\tbuf.WriteString(valueSep)\n\t\t}\n\t\tf.writeObjSep(buf)\n\t}\n\tf.writeIndent(buf, depth)\n\tbuf.WriteString(endArray)\n}\n\nfunc (f *Formatter) marshalFloatArray(key string, a []float64, buf *bytes.Buffer, depth int) {\n\tif len(a) == 0 {\n\t\tbuf.WriteString(emptyArray)\n\t\treturn\n\t}\n\n\tbuf.WriteString(startArray)\n\tf.writeObjSep(buf)\n\n\tfor i, v := range a {\n\t\tf.writeIndent(buf, depth+1)\n\t\tf.marshalValue(key, v, buf, depth+1)\n\t\tif i < len(a)-1 {\n\t\t\tbuf.WriteString(valueSep)\n\t\t}\n\t\tf.writeObjSep(buf)\n\t}\n\tf.writeIndent(buf, depth)\n\tbuf.WriteString(endArray)\n}\n\nfunc (f *Formatter) marshalBoolArray(key string, a []bool, buf *bytes.Buffer, depth int) {\n\tif len(a) == 0 {\n\t\tbuf.WriteString(emptyArray)\n\t\treturn\n\t}\n\n\tbuf.WriteString(startArray)\n\tf.writeObjSep(buf)\n\n\tfor i, v := range a {\n\t\tf.writeIndent(buf, depth+1)\n\t\tf.marshalValue(key, v, buf, depth+1)\n\t\tif i < len(a)-1 {\n\t\t\tbuf.WriteString(valueSep)\n\t\t}\n\t\tf.writeObjSep(buf)\n\t}\n\tf.writeIndent(buf, depth)\n\tbuf.WriteString(endArray)\n}\n\nfunc (f *Formatter) marshalStringArray(key string, a []string, buf *bytes.Buffer, depth int) {\n\tif len(a) == 0 {\n\t\tbuf.WriteString(emptyArray)\n\t\treturn\n\t}\n\n\tbuf.WriteString(startArray)\n\tf.writeObjSep(buf)\n\n\tfor i, v := range a {\n\t\tf.writeIndent(buf, depth+1)\n\t\tf.marshalValue(key, v, buf, depth+1)\n\t\tif i < len(a)-1 {\n\t\t\tbuf.WriteString(valueSep)\n\t\t}\n\t\tf.writeObjSep(buf)\n\t}\n\tf.writeIndent(buf, depth)\n\tbuf.WriteString(endArray)\n}\n\nfunc (f *Formatter) marshalValue(key string, val interface{}, buf *bytes.Buffer, depth int) {\n\tswitch v := val.(type) {\n\tcase Object:\n\t\tf.marshalMap(v, buf, depth)\n\tcase map[string]interface{}:\n\t\tf.marshalMap(v, buf, depth)\n\tcase []interface{}:\n\t\tf.marshalArray(key, v, buf, depth)\n\tcase []int:\n\t\tf.marshalIntArray(key, v, buf, depth)\n\tcase []float64:\n\t\tf.marshalFloatArray(key, v, buf, depth)\n\tcase []string:\n\t\tf.marshalStringArray(key, v, buf, depth)\n\tcase []bool:\n\t\tf.marshalBoolArray(key, v, buf, depth)\n\tcase string:\n\t\tf.marshalString(key, v, buf)\n\tcase error:\n\t\tf.marshalString(key, v.Error(), buf)\n\tcase float64:\n\t\tbuf.WriteString(f.sprintColor(key, f.NumberColor, strconv.FormatFloat(v, 'f', -1, 64)))\n\tcase bool:\n\t\tbuf.WriteString(f.sprintColor(key, f.BoolColor, (strconv.FormatBool(v))))\n\tcase nil:\n\t\tbuf.WriteString(f.sprintColor(key, f.NullColor, null))\n\tcase json.Number:\n\t\tbuf.WriteString(f.sprintColor(key, f.NumberColor, v.String()))\n\tcase int:\n\t\tbuf.WriteString(f.sprintColor(key, f.NumberColor, strconv.Itoa(v)))\n\tdefault:\n\t\t//nolint lll\n\t\tpanic(errors.New(fmt.Sprintf(\"colorjson error: unknown type of \" + reflect.TypeOf(v).String() + \". If this an object cast as Object or []interface{}\\n\")))\n\t}\n}\n\nfunc (f *Formatter) marshalString(key string, str string, buf *bytes.Buffer) {\n\tif !f.RawStrings {\n\t\tb := &bytes.Buffer{}\n\n\t\tencoder := json.NewEncoder(b)\n\t\tencoder.SetEscapeHTML(f.HTMLEscape)\n\t\terr := encoder.Encode(interface{}(str))\n\t\tif err != nil {\n\t\t\tstr = \"colorjson: error encoding string\"\n\t\t} else {\n\t\t\tstr = strings.Replace(b.String(), \"\\n\", \"\", 1)\n\t\t}\n\t}\n\n\tif f.StringMaxLength != 0 && len(str) >= f.StringMaxLength {\n\t\tstr = fmt.Sprintf(\"%s...\", str[0:f.StringMaxLength])\n\t}\n\n\t// buf.WriteString(str)\n\tbuf.WriteString(f.sprintColor(key, f.StringColor, str))\n}\n\n// Marshal JSON data with default options\nfunc Marshal(jsonObj interface{}) ([]byte, error) {\n\treturn NewFormatter().Marshal(jsonObj)\n}\n"}
{"sample": "package calc\n\n// Sum returns the sum of elements of ints\nfunc Sum(vals []int) int {\n\tvar sum int\n\tfor _, val := range vals {\n\t\tsum += val\n\t}\n\treturn sum\n}\n\n// SumAll find sums of slices\nfunc SumAll(valSlices ...[]int) []int {\n\tresult := make([]int, len(valSlices))\n\tfor _, vals := range valSlices {\n\t\tsum := Sum(vals)\n\t\tresult = append(result, sum)\n\t}\n\treturn result\n}\n\n// SumTails find sums of slice tails\nfunc SumTails(valSlices ...[]int) []int {\n\tresult := make([]int, len(valSlices))\n\tfor _, vals := range valSlices {\n\t\tvar sum int\n\t\tif len(vals) != 0 {\n\t\t\ttail := vals[1:]\n\t\t\tsum = Sum(tail)\n\t\t}\n\t\tresult = append(result, sum)\n\t}\n\treturn result\n\n}\n"}
{"sample": "package properties\n\n// Code generated by go generate; DO NOT EDIT.\n// It's generated by \"github.com/KablamoOSS/kombustion/generate\"\n\n// ClusterScalingTrigger Documentation: http://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-elasticmapreduce-cluster-scalingtrigger.html\ntype ClusterScalingTrigger struct {\n\tCloudWatchAlarmDefinition interface{} `yaml:\"CloudWatchAlarmDefinition\"`\n}\n\n// ClusterScalingTrigger validation\nfunc (resource ClusterScalingTrigger) Validate() []error {\n\terrors := []error{}\n\n\treturn errors\n}\n"}
{"sample": "package internal\n\nimport (\n\t\"fmt\"\n\tG \"github.com/ionous/sashimi/game\"\n\t\"github.com/ionous/sashimi/meta\"\n\t\"github.com/ionous/sashimi/util/ident\"\n)\n\n// FIX? because we store property path, we cant test for equality directly.\n// ( therefore changed to pointer value for gopherjs optimization )\ntype gameValue struct {\n\tgame  *GameEventAdapter\n\tpath  PropertyPath\n\tptype meta.PropertyType\n\tvalue meta.Value\n}\n\nfunc (n *gameValue) Num() (ret float64) {\n\tif n.ptype != meta.NumProperty {\n\t\tn.log(\"Num(): property is not a number.\")\n\t} else {\n\t\tret = n.value.GetNum()\n\t}\n\treturn\n}\n\nfunc (n *gameValue) SetNum(value float64) {\n\tif n.ptype != meta.NumProperty {\n\t\tn.log(\"SetNum(): property is not a number.\")\n\t} else if e := n.value.SetNum(value); e != nil {\n\t\tn.log(\"SetNum(): error setting value: %v.\", e)\n\t}\n}\n\nfunc (n *gameValue) Text() (ret string) {\n\tif n.ptype != meta.TextProperty {\n\t\tn.log(\"Text(): property is not text.\")\n\t} else {\n\t\tret = n.value.GetText()\n\t}\n\treturn\n}\n\nfunc (n *gameValue) SetText(text string) {\n\tif n.ptype != meta.TextProperty {\n\t\tn.log(\"SetText(): property is not text.\")\n\t} else if e := n.value.SetText(text); e != nil {\n\t\tn.log(\"SetText(): error setting value: %v.\", e)\n\t}\n}\n\n// TBD: should these be logged? its sure nice to have be able to test objects generically for properties\nfunc (n *gameValue) Object() G.IObject {\n\tvar res ident.Id\n\tif n.ptype != meta.ObjectProperty {\n\t\tn.log(\"Object(): property is not an object.\")\n\t} else {\n\t\tres = n.value.GetObject()\n\t}\n\treturn n.game.NewGameObjectFromId(res)\n}\n\nfunc (n *gameValue) SetObject(obj G.IObject) {\n\tif n.ptype != meta.ObjectProperty {\n\t\tn.log(\"SetObject(): property is not an object.\")\n\t} else {\n\t\tvar id ident.Id\n\t\tif obj != nil {\n\t\t\tid = obj.Id()\n\t\t}\n\t\tif e := n.value.SetObject(id); e != nil {\n\t\t\tn.log(\"SetObject(): error setting value: %v.\", e)\n\t\t}\n\t}\n}\n\nfunc (n *gameValue) State() (ret ident.Id) {\n\tif n.ptype != meta.StateProperty {\n\t\tn.log(\"State(): property is not a state.\")\n\t} else {\n\t\tret = n.value.GetState()\n\t}\n\treturn\n}\n\nfunc (n *gameValue) SetState(val ident.Id) {\n\tif n.ptype != meta.StateProperty {\n\t\tn.log(\"SetState(): property is not a state.\")\n\t} else if e := n.value.SetState(val); e != nil {\n\t\tn.log(\"SetState(): error setting value: %v.\", e)\n\t}\n}\n\nfunc (n *gameValue) log(format string, v ...interface{}) {\n\tsuffix := fmt.Sprintf(format, v...)\n\tn.game.Println(n.path, suffix)\n}\n"}
{"sample": "package clearbit\n\nimport (\n\t\"net/http\"\n\t\"reflect\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/jarcoal/httpmock\"\n)\n\nfunc requestRecorder(out **http.Request, next httpmock.Responder) httpmock.Responder {\n\treturn func(req *http.Request) (*http.Response, error) {\n\t\t*out = req\n\t\treturn next(req)\n\t}\n}\n\nfunc TestClientEnrichPerson(t *testing.T) {\n\tvar (\n\t\temail  = \"user@example.com\"\n\t\tapiKey = \"clearbit-key\"\n\n\t\trequest *http.Request\n\t)\n\n\ttransport := httpmock.NewMockTransport()\n\ttransport.RegisterResponder(\n\t\t\"GET\",\n\t\tEnrichPersonStreamingURL,\n\t\trequestRecorder(\n\t\t\t&request,\n\t\t\thttpmock.NewBytesResponder(\n\t\t\t\t200,\n\t\t\t\treadFixture(t, \"enrichment_person_response\"),\n\t\t\t),\n\t\t),\n\t)\n\n\tclient := NewClient(apiKey, &http.Client{Transport: transport})\n\n\tperson, err := client.EnrichPerson(email)\n\tif err != nil {\n\t\tt.Fatal(\"EnrichPerson failed:\", err)\n\t}\n\n\tif person.ID == \"\" {\n\t\tt.Fatal(\"Expected person to be present\")\n\t}\n\n\texpectRequestWithAPIKey(t, request, apiKey)\n\n\trequestedEmail := request.URL.Query().Get(\"email\")\n\tif requestedEmail != email {\n\t\tt.Errorf(\"email param = %q, want %q\", requestedEmail, email)\n\t}\n}\n\nfunc TestClientEnrichPersonTransportError(t *testing.T) {\n\tvar (\n\t\tclient = NewClient(\"key\", &http.Client{\n\t\t\tTransport: httpmock.NewMockTransport(),\n\t\t})\n\t)\n\n\t_, err := client.EnrichPerson(\"email\")\n\tif err == nil {\n\t\tt.Fatal(\"EnrichPerson succeeded, should have failed\")\n\t}\n}\n\nfunc TestClientEnrichPersonClearbitError(t *testing.T) {\n\ttransport := httpmock.NewMockTransport()\n\ttransport.RegisterResponder(\n\t\t\"GET\",\n\t\tEnrichPersonStreamingURL,\n\t\thttpmock.NewStringResponder(\n\t\t\t404,\n\t\t\t`{\"error\": {\"type\": \"unknown_record\", \"message\": \"Unknown email address\"}}`,\n\t\t),\n\t)\n\n\tclient := NewClient(\"key\", &http.Client{\n\t\tTransport: transport,\n\t})\n\n\t_, err := client.EnrichPerson(\"email\")\n\tif err == nil {\n\t\tt.Fatal(\"Expected 404 to be an error\")\n\t}\n\n\terrorMessage := err.Error()\n\n\tif !strings.Contains(errorMessage, \"404\") {\n\t\tt.Errorf(\n\t\t\t\"Error message = %q, doesn't contain %q\",\n\t\t\terrorMessage,\n\t\t\t\"404\",\n\t\t)\n\t}\n\n\tif !strings.Contains(errorMessage, \"unknown_record\") {\n\t\tt.Errorf(\n\t\t\t\"Error message = %q, doesn't contain %q\",\n\t\t\terrorMessage,\n\t\t\t\"unknown_record\",\n\t\t)\n\t}\n\n\tif !strings.Contains(errorMessage, \"Unknown email address\") {\n\t\tt.Errorf(\n\t\t\t\"Error message = %q, doesn't contain %q\",\n\t\t\terrorMessage,\n\t\t\t\"Unknown email address\",\n\t\t)\n\t}\n}\n\nfunc TestClientEnrichCompany(t *testing.T) {\n\tvar (\n\t\tdomain = \"example.com\"\n\t\tapiKey = \"clearbit-key\"\n\n\t\trequest *http.Request\n\n\t\ttransport = httpmock.NewMockTransport()\n\t\tclient    = NewClient(apiKey, &http.Client{Transport: transport})\n\t)\n\n\ttransport.RegisterResponder(\n\t\t\"GET\",\n\t\tEnrichCompanyStreamingURL,\n\t\trequestRecorder(\n\t\t\t&request,\n\t\t\thttpmock.NewBytesResponder(\n\t\t\t\t200,\n\t\t\t\treadFixture(t, \"enrichment_company_response\"),\n\t\t\t),\n\t\t),\n\t)\n\n\tcompany, err := client.EnrichCompany(domain)\n\tif err != nil {\n\t\tt.Fatal(\"EnrichCompany failed:\", err)\n\t}\n\n\tif company.ID == \"\" {\n\t\tt.Fatal(\"Expected company to be present\")\n\t}\n\n\texpectRequestWithAPIKey(t, request, apiKey)\n\n\trequestedDomain := request.URL.Query().Get(\"domain\")\n\tif requestedDomain != domain {\n\t\tt.Errorf(\"domain param = %q, want %q\", requestedDomain, domain)\n\t}\n}\n\nfunc TestClientCombinedEnrich(t *testing.T) {\n\tvar (\n\t\temail  = \"user@example.com\"\n\t\tapiKey = \"clearbit-key\"\n\n\t\trequest *http.Request\n\n\t\ttransport = httpmock.NewMockTransport()\n\t\tclient    = NewClient(apiKey, &http.Client{Transport: transport})\n\t)\n\n\ttransport.RegisterResponder(\n\t\t\"GET\",\n\t\tEnrichCombinedStreamingURL,\n\t\trequestRecorder(\n\t\t\t&request,\n\t\t\thttpmock.NewBytesResponder(\n\t\t\t\t200,\n\t\t\t\treadFixture(t, \"enrichment_combined_response\"),\n\t\t\t),\n\t\t),\n\t)\n\n\tcombined, err := client.Enrich(email)\n\tif err != nil {\n\t\tt.Fatal(\"EnrichCombined failed:\", err)\n\t}\n\n\tif combined.Company.ID == \"\" {\n\t\tt.Fatal(\"Expected company to be present in combined response\")\n\t}\n\n\texpectRequestWithAPIKey(t, request, apiKey)\n\n\trequestedEmail := request.URL.Query().Get(\"email\")\n\tif requestedEmail != email {\n\t\tt.Errorf(\"email param = %q, want %q\", requestedEmail, email)\n\t}\n}\n\nfunc TestClientProspect(t *testing.T) {\n\tvar (\n\t\tdomain    = \"example.com\"\n\t\tname      = \"Jane\"\n\t\trole      = \"marketing\"\n\t\tseniority = \"executive\"\n\t\ttitles    = []string{\"VP\", \"CEO\"}\n\t\tapiKey    = \"clearbit-key\"\n\n\t\trequest *http.Request\n\n\t\ttransport = httpmock.NewMockTransport()\n\t\tclient    = NewClient(apiKey, &http.Client{Transport: transport})\n\t)\n\n\ttransport.RegisterResponder(\n\t\t\"GET\",\n\t\tProspectURL,\n\t\trequestRecorder(\n\t\t\t&request,\n\t\t\thttpmock.NewBytesResponder(\n\t\t\t\t200,\n\t\t\t\treadFixture(t, \"prospect_response\"),\n\t\t\t),\n\t\t),\n\t)\n\n\tprospects, err := client.Prospect(ProspectQuery{\n\t\tDomain:    domain,\n\t\tName:      name,\n\t\tRole:      role,\n\t\tSeniority: seniority,\n\t\tTitles:    titles,\n\t})\n\tif err != nil {\n\t\tt.Fatal(\"Prospect failed:\", err)\n\t}\n\n\tif len(prospects) == 0 {\n\t\tt.Fatal(\"Expected prospects to be present\")\n\t}\n\n\texpectRequestWithAPIKey(t, request, apiKey)\n\n\trequestedDomain := request.URL.Query().Get(\"domain\")\n\tif requestedDomain != domain {\n\t\tt.Errorf(\"domain param = %q, want %q\", requestedDomain, domain)\n\t}\n\n\trequestedName := request.URL.Query().Get(\"name\")\n\tif requestedName != name {\n\t\tt.Errorf(\"name param = %q, want %q\", requestedName, name)\n\t}\n\n\trequestedRole := request.URL.Query().Get(\"role\")\n\tif requestedRole != role {\n\t\tt.Errorf(\"role param = %q, want %q\", requestedRole, role)\n\t}\n\n\trequestedSeniority := request.URL.Query().Get(\"seniority\")\n\tif requestedSeniority != seniority {\n\t\tt.Errorf(\"seniority param = %q, want %q\", requestedSeniority, seniority)\n\t}\n\n\trequestedTitles := request.URL.Query()[\"titles[]\"]\n\tif !reflect.DeepEqual(requestedTitles, titles) {\n\t\tt.Errorf(\"titles param = %v, want %v\", requestedTitles, titles)\n\t}\n}\n\nfunc expectRequestWithAPIKey(t *testing.T, r *http.Request, apiKey string) {\n\tif r == nil {\n\t\tt.Fatal(\"Request not sent\")\n\t}\n\n\tusername, _, _ := r.BasicAuth()\n\tif username != apiKey {\n\t\tt.Errorf(\"basic auth username = %q, want %q\", username, apiKey)\n\t}\n}\n"}
{"sample": "// Copyright (c) 2020-2021 The Decred developers\n// Use of this source code is governed by an ISC\n// license that can be found in the LICENSE file.\n\npackage main\n\nimport (\n\tcmv1 \"github.com/decred/politeia/politeiawww/api/comments/v1\"\n\tpclient \"github.com/decred/politeia/politeiawww/client\"\n)\n\n// cmdComments retreives the comments for the specified proposal.\ntype cmdComments struct {\n\tArgs struct {\n\t\tToken string `positional-arg-name:\"token\"` // Censorship token\n\t} `positional-args:\"true\" required:\"true\"`\n}\n\n// Execute executes the cmdComments command.\n//\n// This function satisfies the go-flags Commander interface.\nfunc (c *cmdComments) Execute(args []string) error {\n\t// Setup client\n\topts := pclient.Opts{\n\t\tHTTPSCert:  cfg.HTTPSCert,\n\t\tCookies:    cfg.Cookies,\n\t\tHeaderCSRF: cfg.CSRF,\n\t\tVerbose:    cfg.Verbose,\n\t\tRawJSON:    cfg.RawJSON,\n\t}\n\tpc, err := pclient.New(cfg.Host, opts)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Get comments\n\tcm := cmv1.Comments{\n\t\tToken: c.Args.Token,\n\t}\n\tcr, err := pc.Comments(cm)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// Print comments\n\tfor _, v := range cr.Comments {\n\t\tprintComment(v)\n\t\tprintf(\"\\n\")\n\t}\n\n\treturn nil\n}\n\n// commentsHelpMsg is printed to stdout by the help command.\nconst commentsHelpMsg = `comments \"token\" \n\nGet the comments for a record.\n\nIf the record is unvetted, the --unvetted flag must be used. Retrieving the\ncomments on an unvetted record requires the user be either an admin or the\nrecord author.\n\nArguments:\n1. token  (string, required)  Proposal censorship token\n`\n"}
{"sample": "package luar\n\nimport (\n\t\"fmt\"\n\t\"reflect\"\n\t\"unicode\"\n\t\"unicode/utf8\"\n\n\t\"github.com/yuin/gopher-lua\"\n)\n\nfunc check(L *lua.LState, idx int) (ref reflect.Value, mt *Metatable) {\n\tud := L.CheckUserData(idx)\n\tref = reflect.ValueOf(ud.Value)\n\tmt = &Metatable{LTable: ud.Metatable.(*lua.LTable)}\n\treturn\n}\n\nfunc tostring(L *lua.LState) int {\n\tud := L.CheckUserData(1)\n\tif stringer, ok := ud.Value.(fmt.Stringer); ok {\n\t\tL.Push(lua.LString(stringer.String()))\n\t} else {\n\t\tL.Push(lua.LString(ud.String()))\n\t}\n\treturn 1\n}\n\nfunc getUnexportedName(name string) string {\n\tfirst, n := utf8.DecodeRuneInString(name)\n\tif n == 0 {\n\t\treturn name\n\t}\n\treturn string(unicode.ToLower(first)) + name[n:]\n}\n"}
{"sample": "// Code generated by the Pulumi SDK Generator DO NOT EDIT.\n// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***\n\npackage events\n\nimport (\n\t\"context\"\n\t\"reflect\"\n\n\t\"github.com/pulumi/pulumi/sdk/v3/go/pulumi\"\n)\n\n// Resource Type definition for AWS::Events::Connection.\nfunc LookupConnection(ctx *pulumi.Context, args *LookupConnectionArgs, opts ...pulumi.InvokeOption) (*LookupConnectionResult, error) {\n\tvar rv LookupConnectionResult\n\terr := ctx.Invoke(\"aws-native:events:getConnection\", args, &rv, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &rv, nil\n}\n\ntype LookupConnectionArgs struct {\n\t// Name of the connection.\n\tName string `pulumi:\"name\"`\n}\n\ntype LookupConnectionResult struct {\n\t// The arn of the connection resource.\n\tArn               *string                      `pulumi:\"arn\"`\n\tAuthorizationType *ConnectionAuthorizationType `pulumi:\"authorizationType\"`\n\t// Description of the connection.\n\tDescription *string `pulumi:\"description\"`\n\t// The arn of the secrets manager secret created in the customer account.\n\tSecretArn *string `pulumi:\"secretArn\"`\n}\n\nfunc LookupConnectionOutput(ctx *pulumi.Context, args LookupConnectionOutputArgs, opts ...pulumi.InvokeOption) LookupConnectionResultOutput {\n\treturn pulumi.ToOutputWithContext(context.Background(), args).\n\t\tApplyT(func(v interface{}) (LookupConnectionResult, error) {\n\t\t\targs := v.(LookupConnectionArgs)\n\t\t\tr, err := LookupConnection(ctx, &args, opts...)\n\t\t\tvar s LookupConnectionResult\n\t\t\tif r != nil {\n\t\t\t\ts = *r\n\t\t\t}\n\t\t\treturn s, err\n\t\t}).(LookupConnectionResultOutput)\n}\n\ntype LookupConnectionOutputArgs struct {\n\t// Name of the connection.\n\tName pulumi.StringInput `pulumi:\"name\"`\n}\n\nfunc (LookupConnectionOutputArgs) ElementType() reflect.Type {\n\treturn reflect.TypeOf((*LookupConnectionArgs)(nil)).Elem()\n}\n\ntype LookupConnectionResultOutput struct{ *pulumi.OutputState }\n\nfunc (LookupConnectionResultOutput) ElementType() reflect.Type {\n\treturn reflect.TypeOf((*LookupConnectionResult)(nil)).Elem()\n}\n\nfunc (o LookupConnectionResultOutput) ToLookupConnectionResultOutput() LookupConnectionResultOutput {\n\treturn o\n}\n\nfunc (o LookupConnectionResultOutput) ToLookupConnectionResultOutputWithContext(ctx context.Context) LookupConnectionResultOutput {\n\treturn o\n}\n\n// The arn of the connection resource.\nfunc (o LookupConnectionResultOutput) Arn() pulumi.StringPtrOutput {\n\treturn o.ApplyT(func(v LookupConnectionResult) *string { return v.Arn }).(pulumi.StringPtrOutput)\n}\n\nfunc (o LookupConnectionResultOutput) AuthorizationType() ConnectionAuthorizationTypePtrOutput {\n\treturn o.ApplyT(func(v LookupConnectionResult) *ConnectionAuthorizationType { return v.AuthorizationType }).(ConnectionAuthorizationTypePtrOutput)\n}\n\n// Description of the connection.\nfunc (o LookupConnectionResultOutput) Description() pulumi.StringPtrOutput {\n\treturn o.ApplyT(func(v LookupConnectionResult) *string { return v.Description }).(pulumi.StringPtrOutput)\n}\n\n// The arn of the secrets manager secret created in the customer account.\nfunc (o LookupConnectionResultOutput) SecretArn() pulumi.StringPtrOutput {\n\treturn o.ApplyT(func(v LookupConnectionResult) *string { return v.SecretArn }).(pulumi.StringPtrOutput)\n}\n\nfunc init() {\n\tpulumi.RegisterOutputType(LookupConnectionResultOutput{})\n}\n"}
{"sample": "package main\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"os/signal\"\n\t\"strings\"\n\t\"syscall\"\n\t\"time\"\n\n\t\"github.com/Azure/open-service-broker-azure/pkg/api\"\n\tapiFilters \"github.com/Azure/open-service-broker-azure/pkg/api/filters\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/azure\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/boot\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/broker\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/crypto\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/crypto/aes256\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/crypto/noop\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/http/filter\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/http/filters\"\n\tbrokerLog \"github.com/Azure/open-service-broker-azure/pkg/log\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/service\"\n\tstorage \"github.com/Azure/open-service-broker-azure/pkg/storage/redis\"\n\t\"github.com/Azure/open-service-broker-azure/pkg/version\"\n\tlog \"github.com/Sirupsen/logrus\"\n\tasync \"github.com/deis/async/redis\"\n)\n\nfunc main() {\n\t// Initialize logging\n\t// Split log output across stdout and stderr, depending on severity\n\t// krancour: This functionality is currently dependent on a fork of\n\t// the github.com/Sirupsen/logrus package that lives in the split-streams\n\t// branch at github.com/krancour/logrus. (See Gopkg.toml)\n\t// We can resume using the upstream logrus if/when this PR is merged:\n\t// https://github.com/sirupsen/logrus/pull/671\n\tlog.SetOutput(os.Stdout)\n\tlog.SetErrOutput(os.Stderr)\n\tformatter := &log.TextFormatter{\n\t\tFullTimestamp: true,\n\t}\n\tlog.SetFormatter(formatter)\n\tlog.SetLevel(log.InfoLevel)\n\n\tlog.WithFields(\n\t\tlog.Fields{\n\t\t\t\"version\": version.GetVersion(),\n\t\t\t\"commit\":  version.GetCommit(),\n\t\t},\n\t).Info(\"Open Service Broker for Azure starting\")\n\n\tlogConfig, err := brokerLog.GetConfig()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tlogLevel := logConfig.GetLevel()\n\tlog.WithField(\n\t\t\"logLevel\",\n\t\tstrings.ToUpper(logLevel.String()),\n\t).Info(\"Setting log level\")\n\tlog.SetLevel(logLevel)\n\n\t// Initialize catalog\n\tcatalogConfig, err := service.GetCatalogConfigFromEnvironment()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tazureConfig, err := azure.GetConfigFromEnvironment()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tcatalog, err := boot.GetCatalog(catalogConfig, azureConfig)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Initialize encryption\n\tcryptoConfig, err := crypto.GetConfigFromEnvironment()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tvar codec crypto.Codec\n\tswitch cryptoConfig.EncryptionScheme {\n\tcase crypto.AES256:\n\t\tvar aes256Config aes256.Config\n\t\taes256Config, err = aes256.GetConfigFromEnvironment()\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tcodec, err = aes256.NewCodec(aes256Config)\n\t\tif err != nil {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t\tlog.WithField(\n\t\t\t\"encryptionScheme\",\n\t\t\tcryptoConfig.EncryptionScheme,\n\t\t).Info(\"Sensitive instance and binding details will be encrypted\")\n\tcase crypto.NOOP:\n\t\tcodec = noop.NewCodec()\n\t\tlog.Warn(\n\t\t\t\"ENCRYPTION IS DISABLED -- THIS IS NOT A SUITABLE OPTION FOR PRODUCTION\",\n\t\t)\n\tdefault:\n\t\tlog.Fatalf(\n\t\t\t`unrecognized encryption scheme \"%s\"`,\n\t\t\tcryptoConfig.EncryptionScheme,\n\t\t)\n\t}\n\tif err = crypto.InitializeGlobalCodec(codec); err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Storage\n\tstorageConfig, err := storage.GetConfigFromEnvironment()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tstore, err := storage.NewStore(catalog, storageConfig)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Async\n\tasyncConfig, err := async.GetConfigFromEnvironment()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tasyncEngine := async.NewEngine(asyncConfig)\n\n\t// Assemble the filter chain\n\tbasicAuthConfig, err := api.GetBasicAuthConfig()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\tfilterChain := filter.NewChain(\n\t\tfilters.NewBasicAuthFilter(\n\t\t\tbasicAuthConfig.GetUsername(),\n\t\t\tbasicAuthConfig.GetPassword(),\n\t\t),\n\t\tapiFilters.NewAPIVersionFilter(),\n\t)\n\n\tapiServerConfig, err := api.GetConfigFromEnvironment()\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\t// Create API server\n\tapiServer, err := api.NewServer(\n\t\tapiServerConfig,\n\t\tstore,\n\t\tasyncEngine,\n\t\tfilterChain,\n\t\tcatalog,\n\t)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\t// Create broker\n\tbroker, err := broker.NewBroker(\n\t\tapiServer,\n\t\tasyncEngine,\n\t\tstore,\n\t\tcatalog,\n\t)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, syscall.SIGINT, syscall.SIGTERM)\n\tgo func() {\n\t\tsignal := <-sigChan\n\t\tlog.WithField(\n\t\t\t\"signal\",\n\t\t\tsignal,\n\t\t).Debug(\"signal received; shutting down\")\n\t\tcancel()\n\t}()\n\n\t// Run broker\n\tif err := broker.Run(ctx); err != nil {\n\t\tif err == ctx.Err() {\n\t\t\t// Allow some time for goroutines to shut down\n\t\t\ttime.Sleep(time.Second * 3)\n\t\t} else {\n\t\t\tlog.Fatal(err)\n\t\t}\n\t}\n}\n"}
{"sample": "package kms\n\nimport (\n\t\"encoding/base64\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/aws/aws-sdk-go/aws/awserr\"\n\tSDK \"github.com/aws/aws-sdk-go/service/kms\"\n\n\t\"github.com/evalphobia/aws-sdk-go-wrapper/config\"\n\t\"github.com/evalphobia/aws-sdk-go-wrapper/log\"\n\t\"github.com/evalphobia/aws-sdk-go-wrapper/private/pointers\"\n)\n\nconst (\n\tserviceName = \"KMS\"\n\taliasPrefix = \"alias/\"\n)\n\n// KMS has KMS client.\ntype KMS struct {\n\tclient *SDK.KMS\n\n\tlogger log.Logger\n}\n\n// New returns initialized *Rekognition.\nfunc New(conf config.Config) (*KMS, error) {\n\tsess, err := conf.Session()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsvc := &KMS{\n\t\tclient: SDK.New(sess),\n\t\tlogger: log.DefaultLogger,\n\t}\n\treturn svc, nil\n}\n\n// SetLogger sets logger.\nfunc (svc *KMS) SetLogger(logger log.Logger) {\n\tsvc.logger = logger\n}\n\n// CreateAlias executes CreateAlias operation.\nfunc (svc *KMS) CreateAlias(keyID, aliasName string) error {\n\tif !strings.HasPrefix(aliasName, aliasPrefix) {\n\t\taliasName = aliasPrefix + aliasName\n\t}\n\n\t_, err := svc.client.CreateAlias(&SDK.CreateAliasInput{\n\t\tTargetKeyId: pointers.String(keyID),\n\t\tAliasName:   pointers.String(aliasName),\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `CreateAlias` operation; keyID=%s; aliasName=%s; error=%s;\", keyID, aliasName, err.Error())\n\t\treturn err\n\t}\n\n\tsvc.Infof(\"success on `CreateAlias` operation; keyID=%s; aliasName=%s;\", keyID, aliasName)\n\treturn nil\n}\n\n// CreateKey executes CreateKey operation.\nfunc (svc *KMS) CreateKey(tags ...Tag) (*SDK.KeyMetadata, error) {\n\tvar kmsTags []*SDK.Tag\n\tfor _, tag := range tags {\n\t\tkmsTags = append(kmsTags, tag.Tag())\n\t}\n\n\toutput, err := svc.client.CreateKey(&SDK.CreateKeyInput{\n\t\tTags: kmsTags,\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `CreateKey` operation; error=%s;\", err.Error())\n\t\treturn nil, err\n\t}\n\n\tmetaData := output.KeyMetadata\n\tsvc.Infof(\"success on `CreateKey` operation; keyID=%s; arn=%s;\", *metaData.KeyId, *metaData.Arn)\n\treturn metaData, nil\n}\n\n// CreateKeyWithAlias creates a key and sets alias name.\nfunc (svc *KMS) CreateKeyWithAlias(aliasName string, tags ...Tag) (*SDK.KeyMetadata, error) {\n\tif !strings.HasPrefix(aliasName, aliasPrefix) {\n\t\taliasName = aliasPrefix + aliasName\n\t}\n\n\t_, err := svc.DescribeKey(aliasName)\n\tif err == nil {\n\t\treturn nil, fmt.Errorf(\"error: aliasName=[%s] is already exists\", aliasName)\n\t}\n\taerr, ok := err.(awserr.Error)\n\tif !ok {\n\t\treturn nil, err\n\t}\n\tswitch aerr.Code() {\n\tcase SDK.ErrCodeNotFoundException:\n\t\t// error must be NotFoundException.\n\tdefault:\n\t\treturn nil, err\n\t}\n\n\tmetaData, err := svc.CreateKey(tags...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\terr = svc.CreateAlias(*metaData.KeyId, aliasName)\n\treturn metaData, err\n}\n\n// DescribeKey executes DescribeKey operation.\nfunc (svc *KMS) DescribeKey(keyName string) (metaData *SDK.KeyMetadata, err error) {\n\toutput, err := svc.client.DescribeKey(&SDK.DescribeKeyInput{\n\t\tKeyId: pointers.String(keyName),\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `DescribeKey` operation; keyName=%s; error=%s;\", keyName, err.Error())\n\t\treturn nil, err\n\t}\n\n\treturn output.KeyMetadata, nil\n}\n\n// DeleteKey executes ScheduleKeyDeletion operation from Key name(key id, arn or alias).\nfunc (svc *KMS) DeleteKey(keyName string, day int) error {\n\tmetaData, err := svc.DescribeKey(keyName)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn svc.ScheduleKeyDeletion(*metaData.KeyId, day)\n}\n\n// ScheduleKeyDeletion executes ScheduleKeyDeletion operation.\nfunc (svc *KMS) ScheduleKeyDeletion(keyID string, day int) error {\n\t_, err := svc.client.ScheduleKeyDeletion(&SDK.ScheduleKeyDeletionInput{\n\t\tKeyId:               pointers.String(keyID),\n\t\tPendingWindowInDays: pointers.Long(day),\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `ScheduleKeyDeletion` operation; keyID=%s; error=%s;\", keyID, err.Error())\n\t}\n\treturn err\n}\n\n// Encrypt executes Encrypt operation.\nfunc (svc *KMS) Encrypt(keyName string, plainData []byte) (encryptedData []byte, err error) {\n\toutput, err := svc.client.Encrypt(&SDK.EncryptInput{\n\t\tKeyId:     pointers.String(keyName),\n\t\tPlaintext: plainData,\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `Encrypt` operation; keyName=%s; error=%s;\", keyName, err.Error())\n\t\treturn nil, err\n\t}\n\n\treturn output.CiphertextBlob, nil\n}\n\n// EncryptString executes Encrypt operation with base64 string.\nfunc (svc *KMS) EncryptString(keyName, plainText string) (base64Text string, err error) {\n\tencryptedData, err := svc.Encrypt(keyName, []byte(plainText))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn base64.StdEncoding.EncodeToString(encryptedData), nil\n}\n\n// Decrypt executes Decrypt operation.\nfunc (svc *KMS) Decrypt(encryptedData []byte) (plainData []byte, err error) {\n\toutput, err := svc.client.Decrypt(&SDK.DecryptInput{\n\t\tCiphertextBlob: encryptedData,\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `Decrypt` operation; error=%s;\", err.Error())\n\t\treturn nil, err\n\t}\n\n\treturn output.Plaintext, nil\n}\n\n// DecryptString executes Decrypt operation with base64 string.\nfunc (svc *KMS) DecryptString(base64Text string) (plainText string, err error) {\n\tbyt, err := base64.StdEncoding.DecodeString(base64Text)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tplainData, err := svc.Decrypt(byt)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn string(plainData), nil\n}\n\n// ReEncrypt executes ReEncrypt operation.\nfunc (svc *KMS) ReEncrypt(destinationKey string, encryptedData []byte) (resultEncryptedData []byte, err error) {\n\toutput, err := svc.client.ReEncrypt(&SDK.ReEncryptInput{\n\t\tDestinationKeyId: pointers.String(destinationKey),\n\t\tCiphertextBlob:   encryptedData,\n\t})\n\tif err != nil {\n\t\tsvc.Errorf(\"error on `ReEncrypt` operation; destinationKey=%s; error=%s;\", destinationKey, err.Error())\n\t\treturn nil, err\n\t}\n\n\treturn output.CiphertextBlob, nil\n}\n\n// ReEncryptString executes ReEncrypt operation with base64 string.\nfunc (svc *KMS) ReEncryptString(destinationKey, base64Text string) (resultBase64Text string, err error) {\n\tbyt, err := base64.StdEncoding.DecodeString(base64Text)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n\tencryptedData, err := svc.ReEncrypt(destinationKey, byt)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn base64.StdEncoding.EncodeToString(encryptedData), nil\n}\n\n// Infof logging information.\nfunc (svc *KMS) Infof(format string, v ...interface{}) {\n\tsvc.logger.Infof(serviceName, format, v...)\n}\n\n// Errorf logging error information.\nfunc (svc *KMS) Errorf(format string, v ...interface{}) {\n\tsvc.logger.Errorf(serviceName, format, v...)\n}\n"}
{"sample": "package main\n\nimport (\n\t\"flag\"\n\t\"strconv\"\n\n\t\"TraefikAccessControl/manager\"\n\t\"TraefikAccessControl/repository\"\n\t\"TraefikAccessControl/server\"\n\n\tlog \"github.com/sirupsen/logrus\"\n)\n\nfunc main() {\n\tdbNamePtr := flag.String(\"db_name\", \"tac.db\", \"Path of the database file\")\n\timportNamePtr := flag.String(\"import_name\", \"\", \"Path of an file to import\")\n\tforceImportPtr := flag.Bool(\"force_import\", false, \"Force the import of the given file, deletes all existing data\")\n\tcookieNamePtr := flag.String(\"cookie_name\", \"tac_token\", \"Cookie name used\")\n\tuserHeaderNamePtr := flag.String(\"user_header_name\", \"X-TAC-User\", \"Header name that contains the username after successful auth\")\n\tportPtr := flag.Int(\"port\", 4181, \"Port on which the application will run\")\n\tflag.Parse()\n\n\terr := repository.InitDatabaseConnection(*dbNamePtr)\n\tif err != nil {\n\t\tlog.Fatal(\"Abort: Failed to initialize database\")\n\t}\n\n\tuserRep, err := repository.CreateUserRepository()\n\tif err != nil {\n\t\tlog.Fatal(\"Abort: Failed to create user repository\")\n\t}\n\ttokenRep, err := repository.CreateTokenRepository()\n\tif err != nil {\n\t\tlog.Fatal(\"Abort: Failed to create token repository\")\n\t}\n\tsiteRep, err := repository.CreateSiteRepository()\n\tif err != nil {\n\t\tlog.Fatal(\"Abort: Failed to create site repository\")\n\t}\n\tsiteMappingRep, err := repository.CreateSiteMappingRepository()\n\tif err != nil {\n\t\tlog.Fatal(\"Abort: Failed to create site mapping repository\")\n\t}\n\n\tauthMgr := manager.CreateAuthManager(userRep, tokenRep)\n\tsiteMgr := manager.CreateSiteManager(siteRep, siteMappingRep)\n\taccessMgr := manager.CreateAccessManager()\n\timportExportManager := manager.CreateImportExportManager()\n\n\tif importNamePtr != nil && *importNamePtr != \"\" {\n\t\terr = importExportManager.ImportFile(*importNamePtr, *forceImportPtr)\n\t\tif err != nil {\n\t\t\tlog.Warn(\"Abort: Failed to import data\")\n\t\t}\n\t}\n\n\tif cnt, err := authMgr.GetUserCount(); err == nil && cnt == 0 {\n\t\tauthMgr.CreateFirstUser()\n\t}\n\n\tsrv := server.NewServer(*cookieNamePtr, *userHeaderNamePtr)\n\n\t// Start\n\tlog.WithField(\"port\", *portPtr).Info(\"Listening on specified port\")\n\tlog.Info(srv.Router.Run(\":\" + strconv.Itoa(*portPtr)))\n\n\tauthMgr.Close()\n\tsiteMgr.Close()\n\taccessMgr.Close()\n}\n"}
{"sample": "package validation\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/giantswarm/apiextensions-application/api/v1alpha1\"\n\t\"github.com/giantswarm/k8smetadata/pkg/label\"\n\t\"github.com/giantswarm/microerror\"\n\tapierrors \"k8s.io/apimachinery/pkg/api/errors\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\t\"k8s.io/apimachinery/pkg/fields\"\n\t\"sigs.k8s.io/controller-runtime/pkg/client\"\n\n\t\"github.com/giantswarm/app/v6/pkg/key\"\n)\n\nconst (\n\tcatalogNotFoundTemplate         = \"catalog %#q not found\"\n\tnameTooLongTemplate             = \"name %#q is %d chars and exceeds max length of %d chars\"\n\tnameNotFoundReasonTemplate      = \"name is not specified for %s\"\n\tnamespaceNotFoundReasonTemplate = \"namespace is not specified for %s %#q\"\n\tlabelInvalidValueTemplate       = \"label %#q has invalid value %#q\"\n\tlabelNotFoundTemplate           = \"label %#q not found\"\n\tresourceNotFoundTemplate        = \"%s %#q in namespace %#q not found\"\n\n\tdefaultCatalogName            = \"default\"\n\tnginxIngressControllerAppName = \"nginx-ingress-controller-app\"\n\n\t// nameMaxLength is 53 characters as this is the maximum allowed for Helm\n\t// release names.\n\tnameMaxLength = 53\n)\n\nfunc (v *Validator) ValidateApp(ctx context.Context, app v1alpha1.App) (bool, error) {\n\tvar err error\n\n\terr = v.validateCatalog(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateConfig(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateKubeConfig(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateLabels(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateMetadataConstraints(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateName(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateNamespaceConfig(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\terr = v.validateUserConfig(ctx, app)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\treturn true, nil\n}\n\nfunc (v *Validator) ValidateAppUpdate(ctx context.Context, app, currentApp v1alpha1.App) (bool, error) {\n\terr := v.validateNamespaceUpdate(ctx, app, currentApp)\n\tif err != nil {\n\t\treturn false, microerror.Mask(err)\n\t}\n\n\treturn true, nil\n}\n\nfunc (v *Validator) validateCatalog(ctx context.Context, cr v1alpha1.App) error {\n\tvar err error\n\n\tif key.CatalogName(cr) == \"\" {\n\t\treturn nil\n\t}\n\n\tvar namespaces []string\n\t{\n\t\tif key.CatalogNamespace(cr) != \"\" {\n\t\t\tnamespaces = []string{key.CatalogNamespace(cr)}\n\t\t} else {\n\t\t\tnamespaces = []string{metav1.NamespaceDefault, \"giantswarm\"}\n\t\t}\n\t}\n\n\tvar matchedCatalog *v1alpha1.Catalog\n\n\tfor _, ns := range namespaces {\n\t\tvar catalog v1alpha1.Catalog\n\t\terr = v.g8sClient.Get(ctx, client.ObjectKey{\n\t\t\tNamespace: ns,\n\t\t\tName:      key.CatalogName(cr),\n\t\t}, &catalog)\n\t\tif apierrors.IsNotFound(err) {\n\t\t\t// no-op\n\t\t\tcontinue\n\t\t} else if err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\t\tmatchedCatalog = &catalog\n\t\tbreak\n\t}\n\n\tif matchedCatalog == nil || matchedCatalog.Name == \"\" {\n\t\treturn microerror.Maskf(validationError, catalogNotFoundTemplate, key.CatalogName(cr))\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateConfig(ctx context.Context, cr v1alpha1.App) error {\n\tif key.IsManagedByFlux(cr, v.projectName) {\n\t\treturn nil\n\t}\n\n\tif key.AppConfigMapName(cr) != \"\" {\n\t\tns := key.AppConfigMapNamespace(cr)\n\t\tif ns == \"\" {\n\t\t\treturn microerror.Maskf(validationError, namespaceNotFoundReasonTemplate, \"configmap\", key.AppConfigMapName(cr))\n\t\t}\n\n\t\t_, err := v.k8sClient.CoreV1().ConfigMaps(ns).Get(ctx, key.AppConfigMapName(cr), metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\t// appConfigMapNotFoundError is used rather than a validation error because\n\t\t\t// during cluster creation there is a short delay while it is generated.\n\t\t\treturn microerror.Maskf(appConfigMapNotFoundError, resourceNotFoundTemplate, \"configmap\", key.AppConfigMapName(cr), ns)\n\t\t} else if err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\t}\n\n\tif key.AppSecretName(cr) != \"\" {\n\t\tns := key.AppSecretNamespace(cr)\n\t\tif ns == \"\" {\n\t\t\treturn microerror.Maskf(validationError, namespaceNotFoundReasonTemplate, \"secret\", key.AppSecretName(cr))\n\t\t}\n\n\t\t_, err := v.k8sClient.CoreV1().Secrets(ns).Get(ctx, key.AppSecretName(cr), metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\treturn microerror.Maskf(validationError, resourceNotFoundTemplate, \"secret\", key.AppSecretName(cr), ns)\n\t\t} else if err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateName(ctx context.Context, cr v1alpha1.App) error {\n\tif len(cr.Name) > nameMaxLength {\n\t\treturn microerror.Maskf(validationError, nameTooLongTemplate, cr.Name, len(cr.Name), nameMaxLength)\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateNamespaceConfig(ctx context.Context, cr v1alpha1.App) error {\n\tannotations := key.AppNamespaceAnnotations(cr)\n\tlabels := key.AppNamespaceLabels(cr)\n\n\tif annotations == nil && labels == nil {\n\t\t// no-op\n\t\treturn nil\n\t}\n\n\tvar apps []v1alpha1.App\n\t{\n\t\tfieldSelector, err := fields.ParseSelector(fmt.Sprintf(\"metadata.name!=%s\", cr.Name))\n\t\tif err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\n\t\tlo := client.ListOptions{\n\t\t\tNamespace:     cr.Namespace,\n\t\t\tFieldSelector: fieldSelector,\n\t\t}\n\t\tvar appList v1alpha1.AppList\n\t\terr = v.g8sClient.List(ctx, &appList, &lo)\n\t\tif err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\n\t\tapps = appList.Items\n\t}\n\n\tfor _, app := range apps {\n\t\tif key.AppNamespace(cr) != key.AppNamespace(app) {\n\t\t\tcontinue\n\t\t}\n\n\t\ttargetAnnotations := key.AppNamespaceAnnotations(app)\n\t\tif targetAnnotations != nil && annotations != nil {\n\t\t\tfor k, v := range targetAnnotations {\n\t\t\t\toriginalValue, ok := annotations[k]\n\t\t\t\tif ok && originalValue != v {\n\t\t\t\t\treturn microerror.Maskf(validationError, \"app %#q annotation %#q for target namespace %#q collides with value %#q for app %#q\",\n\t\t\t\t\t\tkey.AppName(cr), k, key.AppNamespace(cr), v, app.Name)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\ttargetLabels := key.AppNamespaceLabels(app)\n\t\tif targetLabels != nil && labels != nil {\n\t\t\tfor k, v := range targetLabels {\n\t\t\t\toriginalValue, ok := labels[k]\n\t\t\t\tif ok && originalValue != v {\n\t\t\t\t\treturn microerror.Maskf(validationError, \"app %#q label %#q for target namespace %#q collides with value %#q for app %#q\",\n\t\t\t\t\t\tkey.AppName(cr), k, key.AppNamespace(cr), v, app.Name)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateKubeConfig(ctx context.Context, cr v1alpha1.App) error {\n\tif key.IsManagedByFlux(cr, v.projectName) {\n\t\treturn nil\n\t}\n\n\tif !key.InCluster(cr) {\n\t\tns := key.KubeConfigSecretNamespace(cr)\n\t\tif ns == \"\" {\n\t\t\treturn microerror.Maskf(validationError, namespaceNotFoundReasonTemplate, \"kubeconfig secret\", key.KubeConfigSecretName(cr))\n\t\t}\n\n\t\tsecretName := key.KubeConfigSecretName(cr)\n\t\tif secretName == \"\" {\n\t\t\treturn microerror.Maskf(validationError, nameNotFoundReasonTemplate, \"kubeconfig secret\")\n\t\t}\n\n\t\t_, err := v.k8sClient.CoreV1().Secrets(key.KubeConfigSecretNamespace(cr)).Get(ctx, secretName, metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\t// kubeConfigNotFoundError is used rather than a validation error because\n\t\t\t// during cluster creation there is a short delay while it is generated.\n\t\t\treturn microerror.Maskf(kubeConfigNotFoundError, resourceNotFoundTemplate, \"kubeconfig secret\", secretName, ns)\n\t\t} else if err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateLabels(ctx context.Context, cr v1alpha1.App) error {\n\tif key.VersionLabel(cr) == \"\" {\n\t\treturn microerror.Maskf(validationError, labelNotFoundTemplate, label.AppOperatorVersion)\n\t}\n\tif key.VersionLabel(cr) == key.LegacyAppVersionLabel {\n\t\treturn microerror.Maskf(validationError, labelInvalidValueTemplate, label.AppOperatorVersion, key.VersionLabel(cr))\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateMetadataConstraints(ctx context.Context, cr v1alpha1.App) error {\n\tname := key.AppCatalogEntryName(key.CatalogName(cr), key.AppName(cr), key.Version(cr))\n\n\tvar entry v1alpha1.AppCatalogEntry\n\terr := v.g8sClient.Get(ctx, client.ObjectKey{\n\t\tNamespace: metav1.NamespaceDefault,\n\t\tName:      name,\n\t}, &entry)\n\tif apierrors.IsNotFound(err) {\n\t\tv.logger.Debugf(ctx, \"appcatalogentry %#q not found, skipping metadata validation\", name)\n\t\treturn nil\n\t} else if err != nil {\n\t\treturn microerror.Mask(err)\n\t}\n\n\tif entry.Spec.Restrictions == nil {\n\t\t// no-op\n\t\treturn nil\n\t}\n\n\tif len(entry.Spec.Restrictions.CompatibleProviders) > 0 {\n\t\tif !contains(entry.Spec.Restrictions.CompatibleProviders, v1alpha1.Provider(v.provider)) {\n\t\t\treturn microerror.Maskf(validationError, \"app %#q can only be installed for providers %#q not %#q\",\n\t\t\t\tcr.Spec.Name, entry.Spec.Restrictions.CompatibleProviders, v.provider)\n\t\t}\n\t}\n\n\tif entry.Spec.Restrictions.FixedNamespace != \"\" {\n\t\tif entry.Spec.Restrictions.FixedNamespace != cr.Spec.Namespace {\n\t\t\treturn microerror.Maskf(validationError, \"app %#q can only be installed in namespace %#q only, not %#q\",\n\t\t\t\tcr.Spec.Name, entry.Spec.Restrictions.FixedNamespace, cr.Spec.Namespace)\n\t\t}\n\t}\n\n\tvar apps []v1alpha1.App\n\tif entry.Spec.Restrictions.ClusterSingleton || entry.Spec.Restrictions.NamespaceSingleton {\n\t\tfieldSelector, err := fields.ParseSelector(fmt.Sprintf(\"metadata.name!=%s\", cr.Name))\n\t\tif err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\n\t\tlo := client.ListOptions{\n\t\t\tFieldSelector: fieldSelector,\n\t\t\tNamespace:     cr.Namespace,\n\t\t}\n\t\tvar appList v1alpha1.AppList\n\t\terr = v.g8sClient.List(ctx, &appList, &lo)\n\t\tif err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\n\t\tapps = appList.Items\n\t}\n\n\tfor _, app := range apps {\n\t\tif app.Spec.Name == cr.Spec.Name {\n\t\t\tif entry.Spec.Restrictions.ClusterSingleton {\n\t\t\t\treturn microerror.Maskf(validationError, \"app %#q can only be installed once in cluster %#q\",\n\t\t\t\t\tcr.Spec.Name, cr.Namespace)\n\t\t\t}\n\t\t\tif entry.Spec.Restrictions.NamespaceSingleton {\n\t\t\t\tif app.Spec.Namespace == cr.Spec.Namespace {\n\t\t\t\t\treturn microerror.Maskf(validationError, \"app %#q can only be installed only once in namespace %#q\",\n\t\t\t\t\t\tcr.Spec.Name, key.Namespace(cr))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateNamespaceUpdate(ctx context.Context, app, currentApp v1alpha1.App) error {\n\tif key.Namespace(app) != key.Namespace(currentApp) {\n\t\treturn microerror.Maskf(validationError, \"target namespace for app %#q cannot be changed from %#q to %#q\", app.Name,\n\t\t\tkey.Namespace(currentApp), key.Namespace(app))\n\t}\n\n\treturn nil\n}\n\nfunc (v *Validator) validateUserConfig(ctx context.Context, cr v1alpha1.App) error {\n\tif key.IsManagedByFlux(cr, v.projectName) {\n\t\treturn nil\n\t}\n\n\tif key.UserConfigMapName(cr) != \"\" {\n\t\t// NGINX Ingress Controller is no longer a pre-installed app\n\t\t// managed by cluster-operator. So we don't need to restrict\n\t\t// the name.\n\t\tif key.CatalogName(cr) == defaultCatalogName && key.AppName(cr) != nginxIngressControllerAppName {\n\t\t\tconfigMapName := fmt.Sprintf(\"%s-user-values\", cr.Name)\n\t\t\tif key.UserConfigMapName(cr) != configMapName {\n\t\t\t\treturn microerror.Maskf(validationError, \"user configmap must be named %#q for app in default catalog\", configMapName)\n\t\t\t}\n\t\t}\n\n\t\tns := key.UserConfigMapNamespace(cr)\n\t\tif ns == \"\" {\n\t\t\treturn microerror.Maskf(validationError, namespaceNotFoundReasonTemplate, \"configmap\", key.UserConfigMapName(cr))\n\t\t}\n\n\t\t_, err := v.k8sClient.CoreV1().ConfigMaps(ns).Get(ctx, key.UserConfigMapName(cr), metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\treturn microerror.Maskf(validationError, resourceNotFoundTemplate, \"configmap\", key.UserConfigMapName(cr), ns)\n\t\t} else if err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\t}\n\n\tif key.UserSecretName(cr) != \"\" {\n\t\tif key.CatalogName(cr) == defaultCatalogName {\n\t\t\tsecretName := fmt.Sprintf(\"%s-user-secrets\", cr.Name)\n\t\t\tif key.UserSecretName(cr) != secretName {\n\t\t\t\treturn microerror.Maskf(validationError, \"user secret must be named %#q for app in default catalog\", secretName)\n\t\t\t}\n\t\t}\n\n\t\tns := key.UserSecretNamespace(cr)\n\t\tif ns == \"\" {\n\t\t\treturn microerror.Maskf(validationError, namespaceNotFoundReasonTemplate, \"secret\", key.UserSecretName(cr))\n\t\t}\n\n\t\t_, err := v.k8sClient.CoreV1().Secrets(key.UserSecretNamespace(cr)).Get(ctx, key.UserSecretName(cr), metav1.GetOptions{})\n\t\tif apierrors.IsNotFound(err) {\n\t\t\treturn microerror.Maskf(validationError, resourceNotFoundTemplate, \"secret\", key.UserSecretName(cr), ns)\n\t\t} else if err != nil {\n\t\t\treturn microerror.Mask(err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc contains(s []v1alpha1.Provider, e v1alpha1.Provider) bool {\n\tfor _, a := range s {\n\t\tif a == e {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n"}
{"sample": "// Code generated by protoc-gen-go-grpc. DO NOT EDIT.\n// versions:\n// - protoc-gen-go-grpc v1.2.0\n// - protoc             v3.19.4\n// source: api/proto/apirpc.proto\n\npackage api\n\nimport (\n\tcontext \"context\"\n\tgrpc \"google.golang.org/grpc\"\n\tcodes \"google.golang.org/grpc/codes\"\n\tstatus \"google.golang.org/grpc/status\"\n)\n\n// This is a compile-time assertion to ensure that this generated file\n// is compatible with the grpc package it is being compiled against.\n// Requires gRPC-Go v1.32.0 or later.\nconst _ = grpc.SupportPackageIsVersion7\n\n// ApiServiceClient is the client API for ApiService service.\n//\n// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.\ntype ApiServiceClient interface {\n\tGetNodeInfo(ctx context.Context, in *EmptyRequest, opts ...grpc.CallOption) (*NodeInfoResponse, error)\n}\n\ntype apiServiceClient struct {\n\tcc grpc.ClientConnInterface\n}\n\nfunc NewApiServiceClient(cc grpc.ClientConnInterface) ApiServiceClient {\n\treturn &apiServiceClient{cc}\n}\n\nfunc (c *apiServiceClient) GetNodeInfo(ctx context.Context, in *EmptyRequest, opts ...grpc.CallOption) (*NodeInfoResponse, error) {\n\tout := new(NodeInfoResponse)\n\terr := c.cc.Invoke(ctx, \"/rpcpb.ApiService/GetNodeInfo\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}\n\n// ApiServiceServer is the server API for ApiService service.\n// All implementations should embed UnimplementedApiServiceServer\n// for forward compatibility\ntype ApiServiceServer interface {\n\tGetNodeInfo(context.Context, *EmptyRequest) (*NodeInfoResponse, error)\n}\n\n// UnimplementedApiServiceServer should be embedded to have forward compatible implementations.\ntype UnimplementedApiServiceServer struct {\n}\n\nfunc (UnimplementedApiServiceServer) GetNodeInfo(context.Context, *EmptyRequest) (*NodeInfoResponse, error) {\n\treturn nil, status.Errorf(codes.Unimplemented, \"method GetNodeInfo not implemented\")\n}\n\n// UnsafeApiServiceServer may be embedded to opt out of forward compatibility for this service.\n// Use of this interface is not recommended, as added methods to ApiServiceServer will\n// result in compilation errors.\ntype UnsafeApiServiceServer interface {\n\tmustEmbedUnimplementedApiServiceServer()\n}\n\nfunc RegisterApiServiceServer(s grpc.ServiceRegistrar, srv ApiServiceServer) {\n\ts.RegisterService(&ApiService_ServiceDesc, srv)\n}\n\nfunc _ApiService_GetNodeInfo_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {\n\tin := new(EmptyRequest)\n\tif err := dec(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif interceptor == nil {\n\t\treturn srv.(ApiServiceServer).GetNodeInfo(ctx, in)\n\t}\n\tinfo := &grpc.UnaryServerInfo{\n\t\tServer:     srv,\n\t\tFullMethod: \"/rpcpb.ApiService/GetNodeInfo\",\n\t}\n\thandler := func(ctx context.Context, req interface{}) (interface{}, error) {\n\t\treturn srv.(ApiServiceServer).GetNodeInfo(ctx, req.(*EmptyRequest))\n\t}\n\treturn interceptor(ctx, in, info, handler)\n}\n\n// ApiService_ServiceDesc is the grpc.ServiceDesc for ApiService service.\n// It's only intended for direct use with grpc.RegisterService,\n// and not to be introspected or modified (even as a copy)\nvar ApiService_ServiceDesc = grpc.ServiceDesc{\n\tServiceName: \"rpcpb.ApiService\",\n\tHandlerType: (*ApiServiceServer)(nil),\n\tMethods: []grpc.MethodDesc{\n\t\t{\n\t\t\tMethodName: \"GetNodeInfo\",\n\t\t\tHandler:    _ApiService_GetNodeInfo_Handler,\n\t\t},\n\t},\n\tStreams:  []grpc.StreamDesc{},\n\tMetadata: \"api/proto/apirpc.proto\",\n}\n"}
{"sample": "package roaming\n\nimport (\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/andrewflash/benam-lora-network-server/internal/config\"\n\t\"github.com/andrewflash/benam-lora-network-server/internal/test\"\n\t\"github.com/andrewflash/lorawan\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/stretchr/testify/require\"\n)\n\nfunc TestIsRoamingDevAddr(t *testing.T) {\n\tnetID = lorawan.NetID{1, 2, 3}\n\n\tt.Run(\"DevAddr is roaming\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\troamingEnabled = true\n\n\t\tdevAddr := lorawan.DevAddr{6, 7, 8, 9}\n\t\tdevAddr.SetAddrPrefix(lorawan.NetID{3, 2, 1})\n\n\t\tassert.True(IsRoamingDevAddr(devAddr))\n\t})\n\n\tt.Run(\"DevAddr is not roaming\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\troamingEnabled = true\n\n\t\tdevAddr := lorawan.DevAddr{6, 7, 8, 9}\n\t\tdevAddr.SetAddrPrefix(netID)\n\n\t\tassert.False(IsRoamingDevAddr(devAddr))\n\t})\n\n\tt.Run(\"DevAddr is roaming, roaming disabled\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\troamingEnabled = false\n\n\t\tdevAddr := lorawan.DevAddr{6, 7, 8, 9}\n\t\tdevAddr.SetAddrPrefix(lorawan.NetID{3, 2, 1})\n\n\t\tassert.False(IsRoamingDevAddr(devAddr))\n\t})\n}\n\nfunc TestGetClientForNetID(t *testing.T) {\n\tassert := require.New(t)\n\n\tconf := test.GetConfig()\n\tconf.Roaming.Servers = []config.RoamingServer{\n\t\t{\n\t\t\tNetID:          lorawan.NetID{6, 6, 6},\n\t\t\tPassiveRoaming: true,\n\t\t},\n\t}\n\tassert.NoError(Setup(conf))\n\n\tt.Run(\"Roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tc, err := GetClientForNetID(lorawan.NetID{6, 6, 6})\n\t\tassert.NoError(err)\n\t\tassert.NotNil(c)\n\t})\n\n\tt.Run(\"No roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\t_, err := GetClientForNetID(lorawan.NetID{6, 6, 7})\n\t\tassert.Equal(ErrNoAgreement, errors.Cause(err))\n\t})\n\n\tt.Run(\"No roaming agreement, default client enabled\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tconf.Roaming.Default.Enabled = true\n\t\tconf.Roaming.Default.PassiveRoaming = true\n\t\tassert.NoError(Setup(conf))\n\n\t\tc, err := GetClientForNetID(lorawan.NetID{6, 6, 7})\n\t\tassert.NoError(err)\n\t\tassert.NotNil(c)\n\t})\n}\n\nfunc TestGetPassiveRoamingLifetime(t *testing.T) {\n\tassert := require.New(t)\n\n\tconf := test.GetConfig()\n\tconf.Roaming.Servers = []config.RoamingServer{\n\t\t{\n\t\t\tNetID:                  lorawan.NetID{6, 6, 6},\n\t\t\tPassiveRoaming:         true,\n\t\t\tPassiveRoamingLifetime: time.Hour,\n\t\t},\n\t}\n\tassert.NoError(Setup(conf))\n\n\tt.Run(\"Roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tassert.Equal(time.Hour, GetPassiveRoamingLifetime(lorawan.NetID{6, 6, 6}))\n\t})\n\n\tt.Run(\"No roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tassert.Equal(time.Duration(0), GetPassiveRoamingLifetime(lorawan.NetID{6, 6, 7}))\n\t})\n\n\tt.Run(\"Default roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\n\t\tconf := test.GetConfig()\n\t\tconf.Roaming.Servers = []config.RoamingServer{\n\t\t\t{\n\t\t\t\tNetID:                  lorawan.NetID{6, 6, 6},\n\t\t\t\tPassiveRoaming:         true,\n\t\t\t\tPassiveRoamingLifetime: time.Hour,\n\t\t\t},\n\t\t}\n\t\tconf.Roaming.Default.Enabled = true\n\t\tconf.Roaming.Default.PassiveRoamingLifetime = time.Minute\n\t\tassert.NoError(Setup(conf))\n\n\t\tassert.Equal(time.Minute, GetPassiveRoamingLifetime(lorawan.NetID{6, 6, 7}))\n\t})\n}\n\nfunc TestGetPassiveRoamingKEKLabel(t *testing.T) {\n\tassert := require.New(t)\n\tconf := test.GetConfig()\n\tconf.Roaming.Servers = []config.RoamingServer{\n\t\t{\n\t\t\tNetID:                  lorawan.NetID{6, 6, 6},\n\t\t\tPassiveRoaming:         true,\n\t\t\tPassiveRoamingKEKLabel: \"test-kek\",\n\t\t},\n\t}\n\tassert.NoError(Setup(conf))\n\n\tt.Run(\"Roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tassert.Equal(\"test-kek\", GetPassiveRoamingKEKLabel(lorawan.NetID{6, 6, 6}))\n\t})\n\n\tt.Run(\"No roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tassert.Equal(\"\", GetPassiveRoamingKEKLabel(lorawan.NetID{6, 6, 7}))\n\t})\n\n\tt.Run(\"Default roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\t\tconf := test.GetConfig()\n\t\tconf.Roaming.Servers = []config.RoamingServer{\n\t\t\t{\n\t\t\t\tNetID:                  lorawan.NetID{6, 6, 6},\n\t\t\t\tPassiveRoaming:         true,\n\t\t\t\tPassiveRoamingKEKLabel: \"test-kek\",\n\t\t\t},\n\t\t}\n\t\tconf.Roaming.Default.Enabled = true\n\t\tconf.Roaming.Default.PassiveRoamingKEKLabel = \"default-kek\"\n\t\tassert.NoError(Setup(conf))\n\n\t\tassert.Equal(\"default-kek\", GetPassiveRoamingKEKLabel(lorawan.NetID{6, 6, 7}))\n\t})\n}\n\nfunc TestGetNetIDsForDevAddr(t *testing.T) {\n\tassert := require.New(t)\n\tconf := test.GetConfig()\n\tconf.Roaming.Servers = []config.RoamingServer{\n\t\t{\n\t\t\tNetID:                  lorawan.NetID{6, 6, 6},\n\t\t\tPassiveRoaming:         true,\n\t\t\tPassiveRoamingKEKLabel: \"test-kek\",\n\t\t},\n\t}\n\tassert.NoError(Setup(conf))\n\n\tt.Run(\"Roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\n\t\tdevAddr := lorawan.DevAddr{6, 7, 8, 9}\n\t\tdevAddr.SetAddrPrefix(lorawan.NetID{6, 6, 6})\n\n\t\tassert.Equal([]lorawan.NetID{{6, 6, 6}}, GetNetIDsForDevAddr(devAddr))\n\t})\n\n\tt.Run(\"No roaming agreement\", func(t *testing.T) {\n\t\tassert := require.New(t)\n\n\t\tdevAddr := lorawan.DevAddr{6, 7, 8, 9}\n\t\tdevAddr.SetAddrPrefix(lorawan.NetID{6, 6, 7})\n\n\t\tassert.Len(GetNetIDsForDevAddr(devAddr), 0)\n\t})\n}\n"}
{"sample": "package imgur\n\nimport (\n\t\"encoding/json\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"time\"\n\t\"errors\"\n)\n\ntype imgurClient struct {\n\tclientId        string\n\tbaseUrl         string\n\thttpClient      *http.Client\n\tUserLimit       int\n\tUserRemaining   int\n\tUserReset       time.Time\n\tClientLimit     int\n\tClientRemaining int\n}\n\ntype Comment struct {\n\tId         int       `json:\"id\"`\n\tImageId    string    `json:\"image_id\"`\n\tComment    string    `json:\"comment\"`\n\tAuthor     string    `json:\"author\"`\n\tAuthorId   int       `json:\"author_id\"`\n\tOnAlbum    bool      `json:\"on_album\"`\n\tAlbumCover string    `json:\"album_cover\"`\n\tDateTime   int       `json:\"datetime\"`\n\tUps        int       `json:\"ups\"`\n\tDowns      int       `json:\"downs\"`\n\tPoints     int       `json:\"points\"`\n\tParentId   int       `json:\"parent_id\"`\n\tDeleted    bool      `json:\"deleted\"`\n\tChildren   []Comment `json:\"children\"`\n}\n\ntype Image struct {\n\tId          string `json:\"id\"`\n\tTitle       string `json:\"title\"`\n\tDescription string `json:\"description\"`\n\tDateTime    int    `json:\"datetime\"`\n\tType        string `json:\"type\"`\n\tAnimated    bool   `json:\"animated\"`\n\tWidth       int    `json:\"width\"`\n\tHeight      int    `json:\"height\"`\n\tSize        int    `json:\"size\"`\n\tViews       int    `json:\"views\"`\n\tBandwidth   int    `json:\"bandwidth\"`\n\tLink        string `json:\"link\"`\n\tNsfw        bool   `json:\"nsfw\"`\n\tSection     string `json:\"section\"`\n}\n\ntype ImgurGallery struct {\n\tId             string    `json:\"id\"`\n\tTitle          string    `json:\"title\"`\n\tDescription    string    `json:\"description\"`\n\tDateTime       int       `json:\"datetime\"`\n\tCover          string    `json:\"cover\"`\n\tNsfw           bool      `json:\"nsfw\"`\n\tCommentCount   int       `json:\"comment_count\"`\n\tCommentPreview []Comment `json:\"comment_preview\"`\n\tTopic          string    `json:\"topic\"`\n\tImageCount     int       `json:\"images_count\"`\n\tImages         []Image   `json:\"images\"`\n}\n\nconst baseImgurUrl = \"https://api.imgur.com/3\"\n\nfunc NewClient(clientId string) imgurClient {\n\tiClient := imgurClient{\n\t\tclientId:   clientId,\n\t\thttpClient: &http.Client{},\n\t\tbaseUrl:    baseImgurUrl,\n\t}\n\n\treturn iClient\n}\n\nfunc (c *imgurClient) get(url string, params map[string]string, r io.Reader) (*http.Response, error) {\n\trequest, err := http.NewRequest(\"GET\", c.baseUrl+url, r)\n\trequest.Header.Add(\"Authorization\", \"Client-ID \"+c.clientId)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvalues := request.URL.Query()\n\tfor k, s := range params {\n\t\tvalues.Add(k, s)\n\t}\n\trequest.URL.RawQuery = values.Encode()\n\tresp, err := c.httpClient.Do(request)\n\n\tc.UserLimit, _ = strconv.Atoi(resp.Header.Get(\"X-RateLimit-UserLimit\"))\n\tc.UserRemaining, _ = strconv.Atoi(resp.Header.Get(\"X-RateLimit-UserRemaining\"))\n\tuserResetInt, _ := strconv.ParseInt(resp.Header.Get(\"X-RateLimit-UserReset\"), 10, 64)\n\tc.ClientLimit, _ = strconv.Atoi(resp.Header.Get(\"X-RateLimit-ClientLimit\"))\n\tc.ClientRemaining, _ = strconv.Atoi(resp.Header.Get(\"X-RateLimit-ClientRemaining\"))\n\n\tc.UserReset = time.Unix(userResetInt, 0)\n\treturn resp, err\n}\n\nfunc (c *imgurClient) GetAlbum(url string, page, perPage int) ([]Image, error) {\n\timages := struct {\n\t\tData    []Image `json:\"data\"`\n\t\tSuccess bool    `json:\"success\"`\n\t\tStatus  int     `json:\"status\"`\n\t}{}\n\n\tparams := make(map[string]string)\n\n\tparams[\"page\"] = strconv.Itoa(page)\n\tparams[\"perPage\"] = strconv.Itoa(perPage)\n\n\tresp, err := c.get(url, params, nil)\n\n\tif err != nil {\n\t\treturn images.Data, err\n\t}\n\n\n\trespBytes, readErr := ioutil.ReadAll(resp.Body)\n\n\tif resp.StatusCode != 200 {\n\t\treturn  images.Data, errors.New(string(respBytes))\n\t}\n\n\tif readErr != nil {\n\t\treturn images.Data, readErr\n\t}\n\tmarshalErr := json.Unmarshal(respBytes, &images)\n\n\treturn images.Data, marshalErr\n}\n"}
{"sample": "package mapping_test\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/mrrtf/pigiron/mapping\"\n)\n\nfunc UnmarshalTestRandomPos(data []byte) (TestRandomPos, error) {\n\tvar r TestRandomPos\n\terr := json.Unmarshal(data, &r)\n\treturn r, err\n}\n\nfunc (r *TestRandomPos) Marshal() ([]byte, error) {\n\treturn json.Marshal(r)\n}\n\ntype TestRandomPos struct {\n\tTestpositions []Testposition `json:\"testpositions\"`\n}\n\ntype Testposition struct {\n\tDe      mapping.DEID `json:\"de\"`\n\tBending BoolString   `json:\"bending\"`\n\tOutside BoolString   `json:\"isoutside,omitempty\"`\n\tX       float64      `json:\"x\"`\n\tY       float64      `json:\"y\"`\n\tPX      float64      `json:\"px\"`\n\tPY      float64      `json:\"py\"`\n\tSX      float64      `json:\"sx\"`\n\tSY      float64      `json:\"sy\"`\n\tDsid    int64        `json:\"dsid\"`\n\tDsch    int64        `json:\"dsch\"`\n}\n\nfunc (tp Testposition) String() string {\n\treturn fmt.Sprintf(\"DE %4d %s X %v Y %v Outside %v -> fecID %d fecChannel %d PX %v PY %v SX %v SY %v\",\n\t\ttp.De, mapping.PlaneAbbreviation(tp.isBendingPlane()), tp.X, tp.Y, tp.Outside == \"true\",\n\t\ttp.Dsid, tp.Dsch, tp.PX, tp.PY, tp.SX, tp.SY)\n}\n\nfunc (tp Testposition) isBendingPlane() bool {\n\treturn tp.Bending == \"true\"\n}\n\nfunc (tp Testposition) isOutside() bool {\n\treturn tp.Outside == \"true\"\n}\n\ntype BoolString string\n\nconst (\n\tFalse BoolString = \"false\"\n\tTrue  BoolString = \"true\"\n)\n"}
{"sample": "package metadata\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"strconv\"\n\n\t\"github.com/incognitochain/incognito-chain/common\"\n\t\"github.com/incognitochain/incognito-chain/dataaccessobject/statedb\"\n\tmetadataCommon \"github.com/incognitochain/incognito-chain/metadata/common\"\n\tbtcrelaying \"github.com/incognitochain/incognito-chain/relaying/btc\"\n)\n\ntype PortalSubmitConfirmedTxRequest struct {\n\tMetadataBase\n\tTokenID       string // pTokenID in incognito chain\n\tUnshieldProof string\n\tBatchID       string\n}\n\ntype PortalSubmitConfirmedTxAction struct {\n\tMeta    PortalSubmitConfirmedTxRequest\n\tTxReqID common.Hash\n\tShardID byte\n}\n\ntype PortalSubmitConfirmedTxContent struct {\n\tTokenID      string\n\tUTXOs        []*statedb.UTXO\n\tBatchID      string\n\tTxReqID      common.Hash\n\tExternalTxID string\n\tExternalFee  uint64\n\tShardID      byte\n}\n\ntype PortalSubmitConfirmedTxStatus struct {\n\tTokenID      string\n\tUTXOs        []*statedb.UTXO\n\tBatchID      string\n\tTxHash       string\n\tExternalTxID string\n\tExternalFee  uint64\n\tStatus       int\n}\n\nfunc NewPortalSubmitConfirmedTxStatus(tokenID, batchID, externalTxID, txID string, UTXOs []*statedb.UTXO, status int, externalFee uint64) *PortalSubmitConfirmedTxStatus {\n\treturn &PortalSubmitConfirmedTxStatus{\n\t\tTokenID:      tokenID,\n\t\tUTXOs:        UTXOs,\n\t\tBatchID:      batchID,\n\t\tTxHash:       txID,\n\t\tExternalTxID: externalTxID,\n\t\tExternalFee:  externalFee,\n\t\tStatus:       status,\n\t}\n}\n\nfunc NewPortalSubmitConfirmedTxRequest(metaType int, unshieldProof, tokenID, batchID string) (*PortalSubmitConfirmedTxRequest, error) {\n\tmetadataBase := MetadataBase{\n\t\tType: metaType,\n\t}\n\n\tportalUnshieldReq := &PortalSubmitConfirmedTxRequest{\n\t\tTokenID:       tokenID,\n\t\tBatchID:       batchID,\n\t\tUnshieldProof: unshieldProof,\n\t}\n\n\tportalUnshieldReq.MetadataBase = metadataBase\n\n\treturn portalUnshieldReq, nil\n}\n\nfunc (r PortalSubmitConfirmedTxRequest) ValidateTxWithBlockChain(\n\ttxr Transaction,\n\tchainRetriever ChainRetriever,\n\tshardViewRetriever ShardViewRetriever,\n\tbeaconViewRetriever BeaconViewRetriever,\n\tshardID byte,\n\tdb *statedb.StateDB,\n) (bool, error) {\n\treturn true, nil\n}\n\nfunc (r PortalSubmitConfirmedTxRequest) ValidateSanityData(chainRetriever ChainRetriever, shardViewRetriever ShardViewRetriever, beaconViewRetriever BeaconViewRetriever, beaconHeight uint64, tx Transaction) (bool, bool, error) {\n\t// check tx type and version\n\tif tx.GetType() != common.TxNormalType {\n\t\treturn false, false, NewMetadataTxError(metadataCommon.PortalV4SubmitConfirmedTxRequestMetaError, errors.New(\"tx replace transaction must be TxNormalType\"))\n\t}\n\n\tif tx.GetVersion() != 2 {\n\t\treturn false, false, NewMetadataTxError(metadataCommon.PortalV4SubmitConfirmedTxRequestMetaError,\n\t\t\terrors.New(\"Tx submit confirmed tx request must be version 2\"))\n\t}\n\n\t// validate tokenID\n\tisPortalToken, err := chainRetriever.IsPortalToken(beaconHeight, r.TokenID, common.PortalVersion4)\n\tif !isPortalToken || err != nil {\n\t\treturn false, false, errors.New(\"TokenID is not supported currently on Portal v4\")\n\t}\n\n\t_, err = btcrelaying.ParseAndValidateSanityBTCProofFromB64EncodeStr(r.UnshieldProof)\n\tif r.BatchID == \"\" || err != nil {\n\t\treturn false, false, errors.New(\"BatchID or UnshieldProof is invalid\")\n\t}\n\n\treturn true, true, nil\n}\n\nfunc (r PortalSubmitConfirmedTxRequest) ValidateMetadataByItself() bool {\n\treturn r.Type == metadataCommon.PortalV4SubmitConfirmedTxMeta\n}\n\nfunc (r PortalSubmitConfirmedTxRequest) Hash() *common.Hash {\n\trecord := r.MetadataBase.Hash().String()\n\trecord += r.TokenID\n\trecord += r.BatchID\n\trecord += r.UnshieldProof\n\n\t// final hash\n\thash := common.HashH([]byte(record))\n\treturn &hash\n}\n\nfunc (r *PortalSubmitConfirmedTxRequest) BuildReqActions(tx Transaction, chainRetriever ChainRetriever, shardViewRetriever ShardViewRetriever, beaconViewRetriever BeaconViewRetriever, shardID byte, shardHeight uint64) ([][]string, error) {\n\tactionContent := PortalSubmitConfirmedTxAction{\n\t\tMeta:    *r,\n\t\tTxReqID: *tx.Hash(),\n\t\tShardID: shardID,\n\t}\n\tactionContentBytes, err := json.Marshal(actionContent)\n\tif err != nil {\n\t\treturn [][]string{}, err\n\t}\n\tactionContentBase64Str := base64.StdEncoding.EncodeToString(actionContentBytes)\n\taction := []string{strconv.Itoa(metadataCommon.PortalV4SubmitConfirmedTxMeta), actionContentBase64Str}\n\treturn [][]string{action}, nil\n}\n\nfunc (r *PortalSubmitConfirmedTxRequest) CalculateSize() uint64 {\n\treturn calculateSize(r)\n}\n"}
{"sample": "package lifecycle_test\n\nimport (\n\t\"io/ioutil\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"testing\"\n\n\t\"github.com/sclevine/spec\"\n\t\"github.com/sclevine/spec/report\"\n\n\t\"github.com/buildpack/lifecycle\"\n)\n\nfunc TestKnative(t *testing.T) {\n\tspec.Run(t, \"Knative\", testKnative, spec.Report(report.Terminal{}))\n}\n\nfunc testKnative(t *testing.T, when spec.G, it spec.S) {\n\tvar workspace string\n\n\tit.Before(func() {\n\t\tvar err error\n\t\tworkspace, err = ioutil.TempDir(\"\", \"knative-test-workspace\")\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: creating temp workspace dir: %s\\n\", err)\n\t\t}\n\t\tfile1, err := os.Create(filepath.Join(workspace, \"file1.txt\"))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: creating test file: %s\\n\", err)\n\t\t}\n\t\tdefer file1.Close()\n\t\tfile1.Write([]byte(\"file1 contents\"))\n\t\tif err := os.Mkdir(filepath.Join(workspace, \"app\"), 0755); err != nil {\n\t\t\tt.Fatalf(\"Error: creating app dir in workspace: %s\\n\", err)\n\t\t}\n\t\tfile2, err := os.Create(filepath.Join(workspace, \"app\", \"file2.txt\"))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: creating test file: %s\\n\", err)\n\t\t}\n\t\tdefer file2.Close()\n\t\tfile2.Write([]byte(\"file2 contents\"))\n\t})\n\n\tit.After(func() {\n\t\tif err := os.RemoveAll(workspace); err != nil {\n\t\t\tt.Fatalf(\"Error: removing temp workspace dir: %s\\n\", err)\n\t\t}\n\t})\n\n\tit(\"moves the contents of /workspace to /workspace/app and chowns /builder/home\", func() {\n\t\tif err := lifecycle.SetupKnativeLaunchDir(workspace); err != nil {\n\t\t\tt.Fatalf(\"Error: %s\\n\", err)\n\t\t}\n\t\tfile1, err := os.Open(filepath.Join(workspace, \"app\", \"file1.txt\"))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: opening <workspace>/app/file1.txt: %s\\n\", err)\n\t\t}\n\t\tcontents, err := ioutil.ReadAll(file1)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: reading <workspace>/app/file1.txt: %s\\n\", err)\n\t\t}\n\t\tif string(contents) != \"file1 contents\" {\n\t\t\tt.Fatalf(`Error: contents of  <workspace>/app/file1.txt: got %s, expected \"file1 contents\"`, contents)\n\t\t}\n\n\t\tfile2, err := os.Open(filepath.Join(workspace, \"app\", \"app\", \"file2.txt\"))\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: opening <workspace>/app/app/file2.txt: %s\\n\", err)\n\t\t}\n\t\tcontents, err = ioutil.ReadAll(file2)\n\t\tif err != nil {\n\t\t\tt.Fatalf(\"Error: reading <workspace>/app/app/file2.txt: %s\\n\", err)\n\t\t}\n\t\tif string(contents) != \"file2 contents\" {\n\t\t\tt.Fatalf(`Error: contents of  <workspace>/app/app/file2.txt: got %s, expected \"file2 contents\"`, contents)\n\t\t}\n\t})\n}\n"}
{"sample": "package views\n\nimport (\n\t\"net/http\"\n\n\t\"github.com/uadmin/uadmin\"\n)\n\n// HomeHandler handles the home page.\nfunc HomeHandler(w http.ResponseWriter, r *http.Request, session *uadmin.Session) {\n\t// Initialize the fields that we need in the custom struct.\n\ttype Context struct {\n\t\tUser        string\n\t\tOTPRequired bool\n\t}\n\n\t// Call the custom struct and assign the full name in the User field under the context object.\n\tc := Context{}\n\tc.User = session.User.FirstName + \" \" + session.User.LastName\n\n\t// Check if the user has OTPRequired enabled in the database.\n\tif session.User.OTPRequired {\n\t\t// Assign a boolean value to OTPRequired field. We will use this to manipulate the grammar in the UI.\n\t\tc.OTPRequired = true\n\t}\n\n\t// Render the home filepath and pass the context data object to the HTML file.\n\tuadmin.RenderHTML(w, r, \"templates/home.html\", c)\n\treturn\n}\n"}
{"sample": "/**\n * Copyright (C) 2015 Red Hat, Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *         http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// Copyright 2016 The etcd Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage e2e\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"testing\"\n\t\"time\"\n\n\t\"golang.org/x/net/context\"\n\n\t\"github.com/coreos/etcd/clientv3\"\n\t\"github.com/coreos/etcd/pkg/testutil\"\n)\n\nfunc TestCtlV3Migrate(t *testing.T) {\n\tdefer testutil.AfterTest(t)\n\n\tepc := setupEtcdctlTest(t, &configNoTLS, false)\n\tdefer func() {\n\t\tif errC := epc.Close(); errC != nil {\n\t\t\tt.Fatalf(\"error closing etcd processes (%v)\", errC)\n\t\t}\n\t}()\n\n\tkeys := make([]string, 3)\n\tvals := make([]string, 3)\n\tfor i := range keys {\n\t\tkeys[i] = fmt.Sprintf(\"foo_%d\", i)\n\t\tvals[i] = fmt.Sprintf(\"bar_%d\", i)\n\t}\n\tfor i := range keys {\n\t\tif err := etcdctlSet(epc, keys[i], vals[i]); err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\t}\n\n\tdataDir := epc.procs[0].cfg.dataDirPath\n\tif err := epc.StopAll(); err != nil {\n\t\tt.Fatalf(\"error closing etcd processes (%v)\", err)\n\t}\n\n\tos.Setenv(\"ETCDCTL_API\", \"3\")\n\tdefer os.Unsetenv(\"ETCDCTL_API\")\n\tcx := ctlCtx{\n\t\tt:           t,\n\t\tcfg:         configNoTLS,\n\t\tdialTimeout: 7 * time.Second,\n\t\tepc:         epc,\n\t}\n\tif err := ctlV3Migrate(cx, dataDir, \"\"); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tepc.procs[0].cfg.keepDataDir = true\n\tif err := epc.RestartAll(); err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\t// to ensure revision increment is continuous from migrated v2 data\n\tif err := ctlV3Put(cx, \"test\", \"value\", \"\"); err != nil {\n\t\tt.Fatal(err)\n\t}\n\tcli, err := clientv3.New(clientv3.Config{\n\t\tEndpoints:   epc.grpcEndpoints(),\n\t\tDialTimeout: 3 * time.Second,\n\t})\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tdefer cli.Close()\n\tresp, err := cli.Get(context.TODO(), \"test\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif len(resp.Kvs) != 1 {\n\t\tt.Fatalf(\"len(resp.Kvs) expected 1, got %+v\", resp.Kvs)\n\t}\n\tif resp.Kvs[0].CreateRevision != 7 {\n\t\tt.Fatalf(\"resp.Kvs[0].CreateRevision expected 7, got %d\", resp.Kvs[0].CreateRevision)\n\t}\n}\n\nfunc ctlV3Migrate(cx ctlCtx, dataDir, walDir string) error {\n\tcmdArgs := append(cx.PrefixArgs(), \"migrate\", \"--data-dir\", dataDir, \"--wal-dir\", walDir)\n\treturn spawnWithExpects(cmdArgs, \"finished transforming keys\")\n}\n"}
{"sample": "package gst\n\nimport (\n\t\"fmt\"\n\t\"unsafe\"\n)\n\n/*\n#cgo pkg-config: gstreamer-1.0 gstreamer-app-1.0\n#cgo LDFLAGS: -lgstapp-1.0\n#include <stdlib.h>\n#include <string.h>\n#include <gst/gst.h>\n#include <gst/app/gstappsrc.h>\n*/\nimport \"C\"\n\ntype FlowReturn C.GstFlowReturn\n\nconst (\n\tGST_FLOW_OK             = FlowReturn(C.GST_FLOW_OK)\n\tGST_FLOW_FLUSHING       = FlowReturn(C.GST_FLOW_FLUSHING)\n\tGST_FLOW_NOT_LINKED     = FlowReturn(C.GST_FLOW_NOT_LINKED)\n\tGST_FLOW_NOT_NEGOTIATED = FlowReturn(C.GST_FLOW_NOT_NEGOTIATED)\n\tGST_FLOW_ERROR          = FlowReturn(C.GST_FLOW_ERROR)\n\tGST_FLOW_NOT_SUPPORTED  = FlowReturn(C.GST_FLOW_NOT_SUPPORTED)\n)\n\nfunc (f FlowReturn) String() string {\n\tswitch f {\n\tcase GST_FLOW_OK:\n\t\treturn \"GST_FLOW_OK\"\n\tcase GST_FLOW_FLUSHING:\n\t\treturn \"GST_FLOW_FLUSHING\"\n\tcase GST_FLOW_NOT_LINKED:\n\t\treturn \"GST_FLOW_NOT_LINKED\"\n\tcase GST_FLOW_NOT_NEGOTIATED:\n\t\treturn \"GST_FLOW_NOT_NEGOTIATED\"\n\tcase GST_FLOW_ERROR:\n\t\treturn \"GST_FLOW_ERROR\"\n\tcase GST_FLOW_NOT_SUPPORTED:\n\t\treturn \"GST_FLOW_NOT_SUPPORTED\"\n\tdefault:\n\t\treturn fmt.Sprintf(\"flow error: %d\", f)\n\t}\n}\n\ntype AppSrc struct {\n\t*Element\n}\n\nfunc NewAppSrc(name string) *AppSrc {\n\treturn &AppSrc{ElementFactoryMake(\"appsrc\", name)}\n}\n\nfunc (a *AppSrc) g() *C.GstAppSrc {\n\treturn (*C.GstAppSrc)(a.GetPtr())\n}\n\nfunc (a *AppSrc) SetCaps(caps *Caps) {\n\tp := unsafe.Pointer(caps) // HACK\n\tC.gst_app_src_set_caps(a.g(), (*C.GstCaps)(p))\n}\n\nfunc (a *AppSrc) EOS() error {\n\tret := FlowReturn(C.gst_app_src_end_of_stream(a.g()))\n\tif ret != GST_FLOW_OK {\n\t\treturn fmt.Errorf(\"appsrc eos: %v\", ret)\n\t}\n\n\treturn nil\n}\n\nfunc (a *AppSrc) Write(d []byte) (int, error) {\n\tbuf := C.gst_buffer_new_allocate(nil, C.gsize(len(d)), nil)\n\tn := C.gst_buffer_fill(buf, C.gsize(0), (C.gconstpointer)(C.CBytes(d)), C.gsize(len(d)))\n\n\tret := FlowReturn(C.gst_app_src_push_buffer((*C.GstAppSrc)(a.GetPtr()), buf))\n\tif ret != GST_FLOW_OK {\n\t\treturn 0, fmt.Errorf(\"appsrc push buffer failed: %v\", ret)\n\t}\n\n\treturn int(n), nil\n}\n"}
{"sample": "// Code generated by github.com/99designs/gqlgen, DO NOT EDIT.\n\npackage model\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/minskylab/collecta/ent\"\n\t\"github.com/minskylab/collecta/uuid\"\n)\n\ntype DomainCreator struct {\n\tName     string   `json:\"name\"`\n\tEmail    string   `json:\"email\"`\n\tDomain   string   `json:\"domain\"`\n\tCallback string   `json:\"callback\"`\n\tTags     []string `json:\"tags\"`\n}\n\ntype LastSurveyState struct {\n\tLastQuestion *ent.Question `json:\"lastQuestion\"`\n\tPercent      float64       `json:\"percent\"`\n}\n\ntype LoginResponse struct {\n\tToken string `json:\"token\"`\n}\n\ntype Pair struct {\n\tKey   string `json:\"key\"`\n\tValue string `json:\"value\"`\n}\n\ntype QuestionCreator struct {\n\tTitle       string    `json:\"title\"`\n\tDescription string    `json:\"description\"`\n\tKind        InputType `json:\"kind\"`\n\tMultiple    *bool     `json:\"multiple\"`\n\tAnonymous   *bool     `json:\"anonymous\"`\n\tOptions     []*Pair   `json:\"options\"`\n}\n\ntype SurveyDomain struct {\n\tByID         *uuid.UUID `json:\"byID\"`\n\tByDomainName *string    `json:\"byDomainName\"`\n}\n\ntype SurveyGenerator struct {\n\tTitle       string             `json:\"title\"`\n\tDescription string             `json:\"description\"`\n\tTags        []string           `json:\"tags\"`\n\tQuestions   []*QuestionCreator `json:\"questions\"`\n\tTarget      *SurveyTargetUsers `json:\"target\"`\n\tMetadata    []*Pair            `json:\"metadata\"`\n\tLogic       *string            `json:\"logic\"`\n\tDue         *time.Time         `json:\"due\"`\n}\n\ntype SurveyTargetUsers struct {\n\tTargetKind SurveyAudenceKind `json:\"targetKind\"`\n\tWhitelist  []uuid.UUID       `json:\"whitelist\"`\n}\n\ntype SuveyGenerationResult struct {\n\tHow     int           `json:\"how\"`\n\tSurveys []*ent.Survey `json:\"surveys\"`\n}\n\ntype InputType string\n\nconst (\n\tInputTypeOption       InputType = \"OPTION\"\n\tInputTypeText         InputType = \"TEXT\"\n\tInputTypeBoolean      InputType = \"BOOLEAN\"\n\tInputTypeSatisfaction InputType = \"SATISFACTION\"\n)\n\nvar AllInputType = []InputType{\n\tInputTypeOption,\n\tInputTypeText,\n\tInputTypeBoolean,\n\tInputTypeSatisfaction,\n}\n\nfunc (e InputType) IsValid() bool {\n\tswitch e {\n\tcase InputTypeOption, InputTypeText, InputTypeBoolean, InputTypeSatisfaction:\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (e InputType) String() string {\n\treturn string(e)\n}\n\nfunc (e *InputType) UnmarshalGQL(v interface{}) error {\n\tstr, ok := v.(string)\n\tif !ok {\n\t\treturn fmt.Errorf(\"enums must be strings\")\n\t}\n\n\t*e = InputType(str)\n\tif !e.IsValid() {\n\t\treturn fmt.Errorf(\"%s is not a valid InputType\", str)\n\t}\n\treturn nil\n}\n\nfunc (e InputType) MarshalGQL(w io.Writer) {\n\tfmt.Fprint(w, strconv.Quote(e.String()))\n}\n\ntype SurveyAudenceKind string\n\nconst (\n\tSurveyAudenceKindPublic SurveyAudenceKind = \"PUBLIC\"\n\tSurveyAudenceKindDomain SurveyAudenceKind = \"DOMAIN\"\n\tSurveyAudenceKindClose  SurveyAudenceKind = \"CLOSE\"\n)\n\nvar AllSurveyAudenceKind = []SurveyAudenceKind{\n\tSurveyAudenceKindPublic,\n\tSurveyAudenceKindDomain,\n\tSurveyAudenceKindClose,\n}\n\nfunc (e SurveyAudenceKind) IsValid() bool {\n\tswitch e {\n\tcase SurveyAudenceKindPublic, SurveyAudenceKindDomain, SurveyAudenceKindClose:\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc (e SurveyAudenceKind) String() string {\n\treturn string(e)\n}\n\nfunc (e *SurveyAudenceKind) UnmarshalGQL(v interface{}) error {\n\tstr, ok := v.(string)\n\tif !ok {\n\t\treturn fmt.Errorf(\"enums must be strings\")\n\t}\n\n\t*e = SurveyAudenceKind(str)\n\tif !e.IsValid() {\n\t\treturn fmt.Errorf(\"%s is not a valid SurveyAudenceKind\", str)\n\t}\n\treturn nil\n}\n\nfunc (e SurveyAudenceKind) MarshalGQL(w io.Writer) {\n\tfmt.Fprint(w, strconv.Quote(e.String()))\n}\n"}
{"sample": "package aws\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/awserr\"\n\t\"github.com/aws/aws-sdk-go/service/ec2\"\n\t\"github.com/hashicorp/terraform/helper/hashcode\"\n\t\"github.com/hashicorp/terraform/helper/resource\"\n\t\"github.com/hashicorp/terraform/helper/schema\"\n)\n\n// How long to sleep if a limit-exceeded event happens\nvar routeTargetValidationError = errors.New(\"Error: more than 1 target specified. Only 1 of gateway_id, \" +\n\t\"egress_only_gateway_id, nat_gateway_id, instance_id, network_interface_id or \" +\n\t\"vpc_peering_connection_id is allowed.\")\n\n// AWS Route resource Schema declaration\nfunc resourceAwsRoute() *schema.Resource {\n\treturn &schema.Resource{\n\t\tCreate: resourceAwsRouteCreate,\n\t\tRead:   resourceAwsRouteRead,\n\t\tUpdate: resourceAwsRouteUpdate,\n\t\tDelete: resourceAwsRouteDelete,\n\t\tExists: resourceAwsRouteExists,\n\n\t\tSchema: map[string]*schema.Schema{\n\t\t\t\"destination_cidr_block\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tForceNew: true,\n\t\t\t},\n\t\t\t\"destination_ipv6_cidr_block\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tForceNew: true,\n\t\t\t},\n\n\t\t\t\"destination_prefix_list_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"gateway_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"egress_only_gateway_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"nat_gateway_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"instance_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"instance_owner_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"network_interface_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"origin\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"state\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tComputed: true,\n\t\t\t},\n\n\t\t\t\"route_table_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tRequired: true,\n\t\t\t},\n\n\t\t\t\"vpc_peering_connection_id\": {\n\t\t\t\tType:     schema.TypeString,\n\t\t\t\tOptional: true,\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc resourceAwsRouteCreate(d *schema.ResourceData, meta interface{}) error {\n\tconn := meta.(*AWSClient).ec2conn\n\tvar numTargets int\n\tvar setTarget string\n\tallowedTargets := []string{\n\t\t\"egress_only_gateway_id\",\n\t\t\"gateway_id\",\n\t\t\"nat_gateway_id\",\n\t\t\"instance_id\",\n\t\t\"network_interface_id\",\n\t\t\"vpc_peering_connection_id\",\n\t}\n\n\t// Check if more than 1 target is specified\n\tfor _, target := range allowedTargets {\n\t\tif len(d.Get(target).(string)) > 0 {\n\t\t\tnumTargets++\n\t\t\tsetTarget = target\n\t\t}\n\t}\n\n\tif numTargets > 1 {\n\t\treturn routeTargetValidationError\n\t}\n\n\tcreateOpts := &ec2.CreateRouteInput{}\n\t// Formulate CreateRouteInput based on the target type\n\tswitch setTarget {\n\tcase \"gateway_id\":\n\t\tcreateOpts = &ec2.CreateRouteInput{\n\t\t\tRouteTableId: aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tGatewayId:    aws.String(d.Get(\"gateway_id\").(string)),\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationCidrBlock = aws.String(v.(string))\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationIpv6CidrBlock = aws.String(v.(string))\n\t\t}\n\n\tcase \"egress_only_gateway_id\":\n\t\tcreateOpts = &ec2.CreateRouteInput{\n\t\t\tRouteTableId:                aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationIpv6CidrBlock:    aws.String(d.Get(\"destination_ipv6_cidr_block\").(string)),\n\t\t\tEgressOnlyInternetGatewayId: aws.String(d.Get(\"egress_only_gateway_id\").(string)),\n\t\t}\n\tcase \"nat_gateway_id\":\n\t\tcreateOpts = &ec2.CreateRouteInput{\n\t\t\tRouteTableId:         aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationCidrBlock: aws.String(d.Get(\"destination_cidr_block\").(string)),\n\t\t\tNatGatewayId:         aws.String(d.Get(\"nat_gateway_id\").(string)),\n\t\t}\n\tcase \"instance_id\":\n\t\tcreateOpts = &ec2.CreateRouteInput{\n\t\t\tRouteTableId: aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tInstanceId:   aws.String(d.Get(\"instance_id\").(string)),\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationCidrBlock = aws.String(v.(string))\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationIpv6CidrBlock = aws.String(v.(string))\n\t\t}\n\n\tcase \"network_interface_id\":\n\t\tcreateOpts = &ec2.CreateRouteInput{\n\t\t\tRouteTableId:       aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tNetworkInterfaceId: aws.String(d.Get(\"network_interface_id\").(string)),\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationCidrBlock = aws.String(v.(string))\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationIpv6CidrBlock = aws.String(v.(string))\n\t\t}\n\n\tcase \"vpc_peering_connection_id\":\n\t\tcreateOpts = &ec2.CreateRouteInput{\n\t\t\tRouteTableId:           aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tVpcPeeringConnectionId: aws.String(d.Get(\"vpc_peering_connection_id\").(string)),\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationCidrBlock = aws.String(v.(string))\n\t\t}\n\n\t\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\t\tcreateOpts.DestinationIpv6CidrBlock = aws.String(v.(string))\n\t\t}\n\n\tdefault:\n\t\treturn fmt.Errorf(\"An invalid target type specified: %s\", setTarget)\n\t}\n\tlog.Printf(\"[DEBUG] Route create config: %s\", createOpts)\n\n\t// Create the route\n\tvar err error\n\n\terr = resource.Retry(2*time.Minute, func() *resource.RetryError {\n\t\t_, err = conn.CreateRoute(createOpts)\n\n\t\tif err != nil {\n\t\t\tec2err, ok := err.(awserr.Error)\n\t\t\tif !ok {\n\t\t\t\treturn resource.NonRetryableError(err)\n\t\t\t}\n\t\t\tif ec2err.Code() == \"InvalidParameterException\" {\n\t\t\t\tlog.Printf(\"[DEBUG] Trying to create route again: %q\", ec2err.Message())\n\t\t\t\treturn resource.RetryableError(err)\n\t\t\t}\n\n\t\t\treturn resource.NonRetryableError(err)\n\t\t}\n\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Error creating route: %s\", err)\n\t}\n\n\tvar route *ec2.Route\n\n\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\terr = resource.Retry(2*time.Minute, func() *resource.RetryError {\n\t\t\troute, err = findResourceRoute(conn, d.Get(\"route_table_id\").(string), v.(string), \"\")\n\t\t\treturn resource.RetryableError(err)\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Error finding route after creating it: %s\", err)\n\t\t}\n\t}\n\n\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\terr = resource.Retry(2*time.Minute, func() *resource.RetryError {\n\t\t\troute, err = findResourceRoute(conn, d.Get(\"route_table_id\").(string), \"\", v.(string))\n\t\t\treturn resource.RetryableError(err)\n\t\t})\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Error finding route after creating it: %s\", err)\n\t\t}\n\t}\n\n\td.SetId(routeIDHash(d, route))\n\tresourceAwsRouteSetResourceData(d, route)\n\treturn nil\n}\n\nfunc resourceAwsRouteRead(d *schema.ResourceData, meta interface{}) error {\n\tconn := meta.(*AWSClient).ec2conn\n\trouteTableId := d.Get(\"route_table_id\").(string)\n\n\tdestinationCidrBlock := d.Get(\"destination_cidr_block\").(string)\n\tdestinationIpv6CidrBlock := d.Get(\"destination_ipv6_cidr_block\").(string)\n\n\troute, err := findResourceRoute(conn, routeTableId, destinationCidrBlock, destinationIpv6CidrBlock)\n\tif err != nil {\n\t\tif ec2err, ok := err.(awserr.Error); ok && ec2err.Code() == \"InvalidRouteTableID.NotFound\" {\n\t\t\tlog.Printf(\"[WARN] Route Table %q could not be found. Removing Route from state.\",\n\t\t\t\trouteTableId)\n\t\t\td.SetId(\"\")\n\t\t\treturn nil\n\t\t}\n\t\treturn err\n\t}\n\tresourceAwsRouteSetResourceData(d, route)\n\treturn nil\n}\n\nfunc resourceAwsRouteSetResourceData(d *schema.ResourceData, route *ec2.Route) {\n\td.Set(\"destination_prefix_list_id\", route.DestinationPrefixListId)\n\td.Set(\"gateway_id\", route.GatewayId)\n\td.Set(\"egress_only_gateway_id\", route.EgressOnlyInternetGatewayId)\n\td.Set(\"nat_gateway_id\", route.NatGatewayId)\n\td.Set(\"instance_id\", route.InstanceId)\n\td.Set(\"instance_owner_id\", route.InstanceOwnerId)\n\td.Set(\"network_interface_id\", route.NetworkInterfaceId)\n\td.Set(\"origin\", route.Origin)\n\td.Set(\"state\", route.State)\n\td.Set(\"vpc_peering_connection_id\", route.VpcPeeringConnectionId)\n}\n\nfunc resourceAwsRouteUpdate(d *schema.ResourceData, meta interface{}) error {\n\tconn := meta.(*AWSClient).ec2conn\n\tvar numTargets int\n\tvar setTarget string\n\n\tallowedTargets := []string{\n\t\t\"egress_only_gateway_id\",\n\t\t\"gateway_id\",\n\t\t\"nat_gateway_id\",\n\t\t\"network_interface_id\",\n\t\t\"instance_id\",\n\t\t\"vpc_peering_connection_id\",\n\t}\n\treplaceOpts := &ec2.ReplaceRouteInput{}\n\n\t// Check if more than 1 target is specified\n\tfor _, target := range allowedTargets {\n\t\tif len(d.Get(target).(string)) > 0 {\n\t\t\tnumTargets++\n\t\t\tsetTarget = target\n\t\t}\n\t}\n\n\tswitch setTarget {\n\t//instance_id is a special case due to the fact that AWS will \"discover\" the network_interace_id\n\t//when it creates the route and return that data.  In the case of an update, we should ignore the\n\t//existing network_interface_id\n\tcase \"instance_id\":\n\t\tif numTargets > 2 || (numTargets == 2 && len(d.Get(\"network_interface_id\").(string)) == 0) {\n\t\t\treturn routeTargetValidationError\n\t\t}\n\tdefault:\n\t\tif numTargets > 1 {\n\t\t\treturn routeTargetValidationError\n\t\t}\n\t}\n\n\t// Formulate ReplaceRouteInput based on the target type\n\tswitch setTarget {\n\tcase \"gateway_id\":\n\t\treplaceOpts = &ec2.ReplaceRouteInput{\n\t\t\tRouteTableId:         aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationCidrBlock: aws.String(d.Get(\"destination_cidr_block\").(string)),\n\t\t\tGatewayId:            aws.String(d.Get(\"gateway_id\").(string)),\n\t\t}\n\tcase \"egress_only_gateway_id\":\n\t\treplaceOpts = &ec2.ReplaceRouteInput{\n\t\t\tRouteTableId:                aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationIpv6CidrBlock:    aws.String(d.Get(\"destination_ipv6_cidr_block\").(string)),\n\t\t\tEgressOnlyInternetGatewayId: aws.String(d.Get(\"egress_only_gateway_id\").(string)),\n\t\t}\n\tcase \"nat_gateway_id\":\n\t\treplaceOpts = &ec2.ReplaceRouteInput{\n\t\t\tRouteTableId:         aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationCidrBlock: aws.String(d.Get(\"destination_cidr_block\").(string)),\n\t\t\tNatGatewayId:         aws.String(d.Get(\"nat_gateway_id\").(string)),\n\t\t}\n\tcase \"instance_id\":\n\t\treplaceOpts = &ec2.ReplaceRouteInput{\n\t\t\tRouteTableId:         aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationCidrBlock: aws.String(d.Get(\"destination_cidr_block\").(string)),\n\t\t\tInstanceId:           aws.String(d.Get(\"instance_id\").(string)),\n\t\t}\n\tcase \"network_interface_id\":\n\t\treplaceOpts = &ec2.ReplaceRouteInput{\n\t\t\tRouteTableId:         aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationCidrBlock: aws.String(d.Get(\"destination_cidr_block\").(string)),\n\t\t\tNetworkInterfaceId:   aws.String(d.Get(\"network_interface_id\").(string)),\n\t\t}\n\tcase \"vpc_peering_connection_id\":\n\t\treplaceOpts = &ec2.ReplaceRouteInput{\n\t\t\tRouteTableId:           aws.String(d.Get(\"route_table_id\").(string)),\n\t\t\tDestinationCidrBlock:   aws.String(d.Get(\"destination_cidr_block\").(string)),\n\t\t\tVpcPeeringConnectionId: aws.String(d.Get(\"vpc_peering_connection_id\").(string)),\n\t\t}\n\tdefault:\n\t\treturn fmt.Errorf(\"An invalid target type specified: %s\", setTarget)\n\t}\n\tlog.Printf(\"[DEBUG] Route replace config: %s\", replaceOpts)\n\n\t// Replace the route\n\t_, err := conn.ReplaceRoute(replaceOpts)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc resourceAwsRouteDelete(d *schema.ResourceData, meta interface{}) error {\n\tconn := meta.(*AWSClient).ec2conn\n\n\tdeleteOpts := &ec2.DeleteRouteInput{\n\t\tRouteTableId: aws.String(d.Get(\"route_table_id\").(string)),\n\t}\n\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\tdeleteOpts.DestinationCidrBlock = aws.String(v.(string))\n\t}\n\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\tdeleteOpts.DestinationIpv6CidrBlock = aws.String(v.(string))\n\t}\n\tlog.Printf(\"[DEBUG] Route delete opts: %s\", deleteOpts)\n\n\tvar err error\n\terr = resource.Retry(5*time.Minute, func() *resource.RetryError {\n\t\tlog.Printf(\"[DEBUG] Trying to delete route with opts %s\", deleteOpts)\n\t\tresp, err := conn.DeleteRoute(deleteOpts)\n\t\tlog.Printf(\"[DEBUG] Route delete result: %s\", resp)\n\n\t\tif err == nil {\n\t\t\treturn nil\n\t\t}\n\n\t\tec2err, ok := err.(awserr.Error)\n\t\tif !ok {\n\t\t\treturn resource.NonRetryableError(err)\n\t\t}\n\t\tif ec2err.Code() == \"InvalidParameterException\" {\n\t\t\tlog.Printf(\"[DEBUG] Trying to delete route again: %q\",\n\t\t\t\tec2err.Message())\n\t\t\treturn resource.RetryableError(err)\n\t\t}\n\n\t\treturn resource.NonRetryableError(err)\n\t})\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\td.SetId(\"\")\n\treturn nil\n}\n\nfunc resourceAwsRouteExists(d *schema.ResourceData, meta interface{}) (bool, error) {\n\tconn := meta.(*AWSClient).ec2conn\n\trouteTableId := d.Get(\"route_table_id\").(string)\n\n\tfindOpts := &ec2.DescribeRouteTablesInput{\n\t\tRouteTableIds: []*string{&routeTableId},\n\t}\n\n\tres, err := conn.DescribeRouteTables(findOpts)\n\tif err != nil {\n\t\tif ec2err, ok := err.(awserr.Error); ok && ec2err.Code() == \"InvalidRouteTableID.NotFound\" {\n\t\t\tlog.Printf(\"[WARN] Route Table %q could not be found.\", routeTableId)\n\t\t\treturn false, nil\n\t\t}\n\t\treturn false, fmt.Errorf(\"Error while checking if route exists: %s\", err)\n\t}\n\n\tif len(res.RouteTables) < 1 || res.RouteTables[0] == nil {\n\t\tlog.Printf(\"[WARN] Route Table %q is gone, or route does not exist.\",\n\t\t\trouteTableId)\n\t\treturn false, nil\n\t}\n\n\tif v, ok := d.GetOk(\"destination_cidr_block\"); ok {\n\t\tfor _, route := range (*res.RouteTables[0]).Routes {\n\t\t\tif route.DestinationCidrBlock != nil && *route.DestinationCidrBlock == v.(string) {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t}\n\t}\n\n\tif v, ok := d.GetOk(\"destination_ipv6_cidr_block\"); ok {\n\t\tfor _, route := range (*res.RouteTables[0]).Routes {\n\t\t\tif route.DestinationIpv6CidrBlock != nil && *route.DestinationIpv6CidrBlock == v.(string) {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\n// Create an ID for a route\nfunc routeIDHash(d *schema.ResourceData, r *ec2.Route) string {\n\n\tif r.DestinationIpv6CidrBlock != nil && *r.DestinationIpv6CidrBlock != \"\" {\n\t\treturn fmt.Sprintf(\"r-%s%d\", d.Get(\"route_table_id\").(string), hashcode.String(*r.DestinationIpv6CidrBlock))\n\t}\n\n\treturn fmt.Sprintf(\"r-%s%d\", d.Get(\"route_table_id\").(string), hashcode.String(*r.DestinationCidrBlock))\n}\n\n// Helper: retrieve a route\nfunc findResourceRoute(conn *ec2.EC2, rtbid string, cidr string, ipv6cidr string) (*ec2.Route, error) {\n\trouteTableID := rtbid\n\n\tfindOpts := &ec2.DescribeRouteTablesInput{\n\t\tRouteTableIds: []*string{&routeTableID},\n\t}\n\n\tresp, err := conn.DescribeRouteTables(findOpts)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif len(resp.RouteTables) < 1 || resp.RouteTables[0] == nil {\n\t\treturn nil, fmt.Errorf(\"Route Table %q is gone, or route does not exist.\",\n\t\t\trouteTableID)\n\t}\n\n\tif cidr != \"\" {\n\t\tfor _, route := range (*resp.RouteTables[0]).Routes {\n\t\t\tif route.DestinationCidrBlock != nil && *route.DestinationCidrBlock == cidr {\n\t\t\t\treturn route, nil\n\t\t\t}\n\t\t}\n\n\t\treturn nil, fmt.Errorf(\"Unable to find matching route for Route Table (%s) \"+\n\t\t\t\"and destination CIDR block (%s).\", rtbid, cidr)\n\t}\n\n\tif ipv6cidr != \"\" {\n\t\tfor _, route := range (*resp.RouteTables[0]).Routes {\n\t\t\tif route.DestinationIpv6CidrBlock != nil && *route.DestinationIpv6CidrBlock == ipv6cidr {\n\t\t\t\treturn route, nil\n\t\t\t}\n\t\t}\n\n\t\treturn nil, fmt.Errorf(\"Unable to find matching route for Route Table (%s) \"+\n\t\t\t\"and destination IPv6 CIDR block (%s).\", rtbid, ipv6cidr)\n\t}\n\n\treturn nil, fmt.Errorf(\"When trying to find a matching route for Route Table %q \"+\n\t\t\"you need to specify a CIDR block of IPv6 CIDR Block\", rtbid)\n\n}\n"}
{"sample": "package cred_helper_test\n\nimport (\n\t\"database/sql\"\n\t\"errors\"\n\t\"time\"\n\n\t\"code.cloudfoundry.org/lager\"\n\t\"github.com/patrickmn/go-cache\"\n\n\t\"code.cloudfoundry.org/app-autoscaler/src/autoscaler/cred_helper\"\n\n\t\"code.cloudfoundry.org/app-autoscaler/src/autoscaler/fakes\"\n\t\"code.cloudfoundry.org/app-autoscaler/src/autoscaler/models\"\n\n\t. \"github.com/onsi/ginkgo/v2\"\n\t. \"github.com/onsi/gomega\"\n)\n\nvar _ = Describe(\"CustomMetricCredHelper\", func() {\n\tvar (\n\t\tpolicyDB               *fakes.FakePolicyDB\n\t\tappId                  = \"testAppId\"\n\t\ttestUserName           = \"the-user-name\"\n\t\ttestPassword           = \"the-password\"\n\t\tuserProvidedCredential *models.Credential\n\t\tcredResult             *models.Credential\n\t\tcreds                  cred_helper.Credentials\n\t\tcredentialCache        cache.Cache\n\t)\n\n\tBeforeEach(func() {\n\t\tpolicyDB = &fakes.FakePolicyDB{}\n\t\tcredentialCache = *cache.New(10*time.Minute, -1)\n\n\t\tlogger := lager.NewLogger(\"custom_metrics_helper_test\")\n\t\tlogger.RegisterSink(lager.NewWriterSink(GinkgoWriter, lager.DEBUG))\n\n\t\tcreds = cred_helper.NewCustomMetricsCredHelperWithCache(policyDB, cred_helper.MaxRetry, credentialCache, 10*time.Minute, logger)\n\n\t})\n\tContext(\"CreateCredential\", func() {\n\t\tvar err error\n\t\tJustBeforeEach(func() {\n\t\t\tcredResult, err = creds.Create(appId, userProvidedCredential)\n\t\t})\n\t\tContext(\"when userProvideCredential is not nil\", func() {\n\t\t\tBeforeEach(func() {\n\t\t\t\tuserProvidedCredential = &models.Credential{\n\t\t\t\t\tUsername: testUserName,\n\t\t\t\t\tPassword: testPassword,\n\t\t\t\t}\n\t\t\t\tpolicyDB.SaveCredentialReturns(nil)\n\t\t\t})\n\t\t\tIt(\"saves the credential user provided\", func() {\n\n\t\t\t\tExpect(credResult.Username).To(Equal(testUserName))\n\t\t\t\tExpect(credResult.Password).To(Equal(testPassword))\n\t\t\t})\n\t\t})\n\t\tContext(\"when there is no error when calling policydb\", func() {\n\t\t\tBeforeEach(func() {\n\t\t\t\tpolicyDB.SaveCredentialReturns(nil)\n\t\t\t})\n\t\t\tContext(\"when credential does not exist\", func() {\n\t\t\t\tIt(\"should try saving only once and succeed\", func() {\n\t\t\t\t\tExpect(policyDB.SaveCredentialCallCount()).To(Equal(1))\n\t\t\t\t\tExpect(credResult).NotTo(BeNil())\n\t\t\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\t\t\t})\n\t\t\t})\n\n\t\t})\n\t\tContext(\"when there is continuous error when calling policydb\", func() {\n\t\t\tBeforeEach(func() {\n\t\t\t\tpolicyDB.GetCredentialReturns(nil, sql.ErrNoRows)\n\t\t\t\tpolicyDB.SaveCredentialReturns(errors.New(\"dberror\"))\n\n\t\t\t})\n\t\t\tIt(\"should try MaxRetry times and return error\", func() {\n\t\t\t\tExpect(policyDB.SaveCredentialCallCount()).To(Equal(cred_helper.MaxRetry))\n\t\t\t\tExpect(credResult).To(BeNil())\n\t\t\t\tExpect(err).To(HaveOccurred())\n\t\t\t})\n\t\t})\n\t})\n\tContext(\"DeleteCredential\", func() {\n\t\tvar err error\n\t\tJustBeforeEach(func() {\n\t\t\terr = creds.Delete(appId)\n\t\t})\n\t\tContext(\"when there is no error when calling policydb\", func() {\n\t\t\tBeforeEach(func() {\n\t\t\t\tpolicyDB.DeleteCredentialReturns(nil)\n\t\t\t})\n\t\t\tIt(\"should try only once and succeed\", func() {\n\t\t\t\tExpect(policyDB.DeleteCredentialCallCount()).To(Equal(1))\n\t\t\t\tExpect(err).NotTo(HaveOccurred())\n\t\t\t})\n\t\t})\n\t\tContext(\"when there is continuous error when calling policydb\", func() {\n\t\t\tBeforeEach(func() {\n\t\t\t\tpolicyDB.DeleteCredentialReturns(errors.New(\"dberror\"))\n\t\t\t})\n\t\t\tIt(\"should try MaxRetry times and return error\", func() {\n\t\t\t\tExpect(policyDB.DeleteCredentialCallCount()).To(Equal(cred_helper.MaxRetry))\n\t\t\t\tExpect(err).To(HaveOccurred())\n\t\t\t})\n\t\t})\n\t})\n\n\tContext(\"ValidateCredentials\", func() {\n\t\tContext(\"credentials exists in the cache\", func() {\n\t\t\tIt(\"should get the credentials from cache without searching from database\", func() {\n\t\t\t\tstoredCredentials := &models.Credential{\n\t\t\t\t\tUsername: \"$2a$10$YnQNQYcvl/Q2BKtThOKFZ.KB0nTIZwhKr5q1pWTTwC/PUAHsbcpFu\",\n\t\t\t\t\tPassword: \"$2a$10$6nZ73cm7IV26wxRnmm5E1.nbk9G.0a4MrbzBFPChkm5fPftsUwj9G\",\n\t\t\t\t}\n\t\t\t\tcredentialCache.Set(\"an-app-id\", storedCredentials, 10*time.Minute)\n\n\t\t\t\tvalid, err := creds.Validate(\"an-app-id\", models.Credential{Username: \"username\", Password: \"password\"})\n\t\t\t\tExpect(err).ShouldNot(HaveOccurred())\n\t\t\t\tExpect(valid).To(Equal(true))\n\n\t\t\t\tExpect(policyDB.GetCredentialCallCount()).To(Equal(0))\n\t\t\t})\n\n\t\t})\n\n\t\tContext(\"credentials do not exists in the cache but exist in the database\", func() {\n\t\t\tIt(\"should get the credentials from database, add it to the cache\", func() {\n\t\t\t\tstoredCredentials := &models.Credential{\n\t\t\t\t\tUsername: \"$2a$10$YnQNQYcvl/Q2BKtThOKFZ.KB0nTIZwhKr5q1pWTTwC/PUAHsbcpFu\",\n\t\t\t\t\tPassword: \"$2a$10$6nZ73cm7IV26wxRnmm5E1.nbk9G.0a4MrbzBFPChkm5fPftsUwj9G\",\n\t\t\t\t}\n\n\t\t\t\tpolicyDB.GetCredentialReturns(storedCredentials, nil)\n\n\t\t\t\tvalid, err := creds.Validate(\"an-app-id\", models.Credential{Username: \"username\", Password: \"password\"})\n\t\t\t\tExpect(err).ShouldNot(HaveOccurred())\n\t\t\t\tExpect(valid).To(Equal(true))\n\n\t\t\t\tExpect(policyDB.GetCredentialCallCount()).To(Equal(1))\n\n\t\t\t\t//fills the cache\n\t\t\t\t_, found := credentialCache.Get(\"an-app-id\")\n\t\t\t\tExpect(found).To(Equal(true))\n\t\t\t})\n\t\t})\n\n\t\tContext(\"when credentials neither exists in the cache nor exist in the database\", func() {\n\t\t\tIt(\"should search in both cache & database and returns an error\", func() {\n\t\t\t\tpolicyDB.GetCredentialReturns(nil, errors.New(\"some error\"))\n\n\t\t\t\tvalid, err := creds.Validate(\"an-app-id\", models.Credential{Username: \"username\", Password: \"password\"})\n\t\t\t\tExpect(err).Should(HaveOccurred())\n\t\t\t\tExpect(valid).To(Equal(false))\n\n\t\t\t\tExpect(policyDB.GetCredentialCallCount()).To(Equal(1))\n\n\t\t\t\t//fills the cache\n\t\t\t\t_, found := credentialCache.Get(\"an-app-id\")\n\t\t\t\tExpect(found).To(Equal(false))\n\t\t\t})\n\t\t})\n\n\t\tContext(\"when a stale credentials exists in the cache\", func() {\n\t\t\tIt(\"should search in the database\", func() {\n\t\t\t\tcredentialCache.Set(\"an-app-id\", &models.Credential{Username: \"some-stale-hashed-username\", Password: \"some-stale-hashed-password\"}, 10*time.Minute)\n\n\t\t\t\tstoredCredentials := &models.Credential{\n\t\t\t\t\tUsername: \"$2a$10$YnQNQYcvl/Q2BKtThOKFZ.KB0nTIZwhKr5q1pWTTwC/PUAHsbcpFu\",\n\t\t\t\t\tPassword: \"$2a$10$6nZ73cm7IV26wxRnmm5E1.nbk9G.0a4MrbzBFPChkm5fPftsUwj9G\",\n\t\t\t\t}\n\n\t\t\t\tpolicyDB.GetCredentialReturns(storedCredentials, nil)\n\n\t\t\t\tvalid, err := creds.Validate(\"an-app-id\", models.Credential{Username: \"username\", Password: \"password\"})\n\t\t\t\tExpect(err).ShouldNot(HaveOccurred())\n\t\t\t\tExpect(valid).To(Equal(true))\n\n\t\t\t\tExpect(policyDB.GetCredentialCallCount()).To(Equal(1))\n\n\t\t\t\t//fills the cache\n\t\t\t\t_, found := credentialCache.Get(\"an-app-id\")\n\t\t\t\tExpect(found).To(Equal(true))\n\t\t\t})\n\t\t})\n\t})\n})\n"}
{"sample": "package main\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"runtime\"\n\n\t\"github.com/cloud66-oss/habitus/api\"\n\t\"github.com/cloud66-oss/habitus/build\"\n\t\"github.com/cloud66-oss/habitus/configuration\"\n\t\"github.com/getsentry/raven-go\"\n\t\"github.com/op/go-logging\"\n)\n\nvar prettyFormat = logging.MustStringFormatter(\n\t\"%{color}\u25b6 %{message} %{color:reset}\",\n)\nvar plainFormat = logging.MustStringFormatter(\n\t\"[%{level}] - %{message}\",\n)\n\nvar (\n\tflagLevel       string\n\tflagShowHelp    bool\n\tflagShowVersion bool\n\tflagPrettyLog   bool\n\tVERSION         string = \"dev\"\n\tBUILD_DATE      string = \"\"\n)\n\nfunc init() {\n\t//sentry DSN setup\n\traven.SetDSN(\"https://c5b047b41b3f4de38fc93cb3df75fd43:c94164f03aba4ded84de1fa5894e6544@sentry.io/187936\")\n}\n\nconst DEFAULT_DOCKER_HOST = \"unix:///var/run/docker.sock\"\n\nfunc main() {\n\targs := os.Args[1:]\n\tdefer recoverPanic()\n\n\tvar log = logging.MustGetLogger(\"habitus\")\n\tlogging.SetFormatter(plainFormat)\n\n\tconfig := configuration.CreateConfig()\n\tflag.StringVar(&config.Buildfile, \"f\", \"build.yml\", \"Build file path. Defaults to build.yml in the workdir\")\n\tflag.StringVar(&config.Workdir, \"d\", \"\", \"Work directory for this build. Defaults to the current directory\")\n\tflag.BoolVar(&config.NoCache, \"no-cache\", false, \"Don't use cache in build\")\n\tflag.BoolVar(&config.SuppressOutput, \"suppress\", false, \"Suppress build output\")\n\tflag.BoolVar(&config.RmTmpContainers, \"rm\", true, \"Remove intermediate containers\")\n\tflag.BoolVar(&config.ForceRmTmpContainer, \"force-rm\", false, \"Force remove intermediate containers\")\n\tflag.StringVar(&config.UniqueID, \"uid\", \"\", \"Unique ID for the build. Used only for multi-tenanted build environments\")\n\tflag.StringVar(&flagLevel, \"level\", \"debug\", \"Log level: debug, info, notice, warning, error and critical\")\n\tflag.BoolVar(&flagPrettyLog, \"pretty\", true, \"Display logs with color and formatting\")\n\n\tdockerhost, ok := os.LookupEnv(\"DOCKER_HOST\")\n\tif !ok {\n\t\tdockerhost = DEFAULT_DOCKER_HOST\n\t}\n\n\tflag.StringVar(&config.DockerHost, \"host\", dockerhost, \"Docker host link. Uses DOCKER_HOST if missing.\")\n\tflag.StringVar(&config.DockerCert, \"certs\", os.Getenv(\"DOCKER_CERT_PATH\"), \"Docker cert folder. Uses DOCKER_CERT_PATH if missing\")\n\tflag.Var(&config.EnvVars, \"env\", \"Environment variables to be used in the build.yml. Uses parent process environment variables if empty\")\n\tflag.Var(&config.BuildArgs, \"build\", \"Build arguments to be used during each Dockerfile build step.\")\n\tflag.StringVar(&config.Network, \"network\", \"\", \"Set the networking mode for the RUN instructions during build. See `networkmode` in https://docs.docker.com/engine/api/v1.25/#operation/ImageBuild for available values. If omitted, the \\\"default\\\" bridge network is used, which is the same behavior as `docker build`.\")\n\tflag.BoolVar(&config.KeepSteps, \"keep-all\", false, \"Overrides the keep flag for all steps. Used for debugging\")\n\tflag.BoolVar(&config.KeepArtifacts, \"keep-artifacts\", false, \"Keep the temporary artifacts created on the host during build. Used for debugging\")\n\tflag.BoolVar(&config.UseTLS, \"use-tls\", os.Getenv(\"DOCKER_TLS_VERIFY\") == \"1\", \"Establish TLS connection with Docker daemon. Uses DOCKER_TLS_VERIFY if missing\")\n\tflag.BoolVar(&config.UseStatForPermissions, \"use-stat\", true, \"Uses the stat command inside your container to get the arfifact permissions\")\n\n\tflag.BoolVar(&config.NoSquash, \"no-cleanup\", false, \"Skip cleanup commands for this run. Used for debugging\")\n\tflag.BoolVar(&config.FroceRmImages, \"force-rmi\", false, \"Force remove of unwanted images\")\n\tflag.BoolVar(&config.NoPruneRmImages, \"noprune-rmi\", false, \"No pruning of unwanted images\")\n\tflag.StringVar(&config.OsType, \"os\", \"debian\", \"Specify the OS that the build occurs in\")\n\tflag.BoolVar(&flagShowHelp, \"help\", false, \"Display the help\")\n\tflag.BoolVar(&flagShowVersion, \"version\", false, \"Display version information\")\n\tflag.IntVar(&config.ApiPort, \"port\", 8080, \"Port to server the API\")\n\tflag.StringVar(&config.ApiBinding, \"binding\", \"192.168.99.1\", \"Network address to bind the API to. (see documentation for more info)\")\n\tflag.BoolVar(&config.SecretService, \"secrets\", false, \"Turn Secrets Service on or off\")\n\tflag.BoolVar(&config.AllowAfterBuildCommands, \"after-build-commands\", false, \"Allow to run arbitrary commands on the host after build\")\n\tflag.StringVar(&config.SecretProviders, \"sec-providers\", \"file,env\", \"All available secret providers. Comma separated\")\n\tflag.StringVar(&config.DockerMemory, \"docker-memory\", \"\", \"Memory limits to apply to Docker build operations. More: https://docs.docker.com/engine/reference/commandline/build\")\n\tflag.StringVar(&config.DockerCPUSetCPUs, \"docker-cpuset-cpus\", \"\", \"CPU binding limits to apply to Docker build operations. More: https://docs.docker.com/engine/reference/commandline/build\")\n\tflag.IntVar(&config.DockerCPUShares, \"docker-cpu-shares\", 1024, \"CPU share weighting to apply to Docker build operations. More: https://docs.docker.com/engine/reference/commandline/build\")\n\n\tflag.BoolVar(&config.UseAuthenticatedSecretServer, \"authentication-secret-server\", false, \"Enable basic authentication for secret server\")\n\tflag.StringVar(&config.AuthenticatedSecretServerPassword, \"password-secret-server\", \"admin\", \"The password for basic authentication.\")\n\tflag.StringVar(&config.AuthenticatedSecretServerUser, \"user-secret-server\", \"habitus\", \"The user for basic authentication.\")\n\n\tconfig.Logger = *log\n\tflag.Parse()\n\n\tif flagPrettyLog {\n\t\tlogging.SetFormatter(prettyFormat)\n\t}\n\n\tif flagShowHelp || (len(args) > 0 && args[0] == \"help\") {\n\t\tfmt.Println(\"Habitus - (c) 2016 Cloud 66 Inc.\")\n\t\tflag.PrintDefaults()\n\t\treturn\n\t}\n\n\tif flagShowVersion || (len(args) > 0 && args[0] == \"version\") {\n\t\tif BUILD_DATE == \"\" {\n\t\t\tfmt.Printf(\"Habitus - v%s (c) 2017 Cloud 66 Inc.\\n\", VERSION)\n\t\t} else {\n\t\t\tfmt.Printf(\"Habitus - v%s (%s) (c) 2017 Cloud 66 Inc.\\n\", VERSION, BUILD_DATE)\n\t\t}\n\t\treturn\n\t}\n\n\t// The -os flag allows free form text. Validate what was specified\n\tif !config.ValidateOsType() {\n\t\tfmt.Println(\"Invalid OS name\")\n\t\tfmt.Println(\"Please choose from \", configuration.OsTypes)\n\t\treturn\n\t}\n\n\tlevel, err := logging.LogLevel(flagLevel)\n\tif err != nil {\n\t\tfmt.Println(\"Invalid log level value. Falling back to debug\")\n\t\tlevel = logging.DEBUG\n\t}\n\tlogging.SetLevel(level, \"habitus\")\n\n\tif config.Workdir == \"\" {\n\t\tif curr, err := os.Getwd(); err != nil {\n\t\t\tlog.Fatal(\"Failed to get the current directory\")\n\t\t\tos.Exit(1)\n\t\t} else {\n\t\t\tconfig.Workdir = curr\n\t\t}\n\t}\n\n\tif config.Buildfile == \"build.yml\" {\n\t\tconfig.Buildfile = filepath.Join(config.Workdir, \"build.yml\")\n\t}\n\n\tc, err := build.LoadBuildFromFile(&config)\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed: %s\", err.Error())\n\t}\n\n\tif c.IsPrivileged && os.Getenv(\"SUDO_USER\") == \"\" {\n\t\tlog.Fatal(\"Some of the build steps require admin privileges (sudo). Please run with sudo\\nYou might want to use --certs=$DOCKER_CERT_PATH --host=$DOCKER_HOST params to make sure all environment variables are available to the process\")\n\t\tos.Exit(1)\n\t}\n\n\tb := build.NewBuilder(c, &config)\n\n\tif config.SecretService {\n\t\t// start the API\n\t\tsecret_service := &api.Server{Builder: b}\n\t\terr = secret_service.StartServer(VERSION)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Cannot start API server due to %s\", err.Error())\n\t\t\tos.Exit(2)\n\t\t}\n\t}\n\n\terr = b.StartBuild()\n\tif err != nil {\n\t\tlog.Errorf(\"Error during build %s\", err.Error())\n\t}\n}\n\nfunc recoverPanic() {\n\tif VERSION != \"dev\" {\n\t\traven.CapturePanicAndWait(func() {\n\t\t\tif rec := recover(); rec != nil {\n\t\t\t\tpanic(rec)\n\t\t\t}\n\t\t}, map[string]string{\n\t\t\t\"Version\":      VERSION,\n\t\t\t\"Platform\":     runtime.GOOS,\n\t\t\t\"Architecture\": runtime.GOARCH,\n\t\t\t\"goversion\":    runtime.Version()})\n\t}\n}\n"}
{"sample": "package util\n\nimport (\n\t\"bufio\"\n\t\"compress/gzip\"\n\t\"fmt\"\n\t\"github.com/cespare/xxhash\"\n\t\"github.com/satori/go.uuid\"\n\t\"github.com/tjones879/fake/structs\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"net/url\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n)\n\nvar rootDir = \"/home/jones/fake\"\n\nfunc getFileHash(contents string) (hash uint64) {\n\thash = xxhash.Sum64String(contents)\n\treturn\n}\n\n/*\nTake the hash of a file and get its correct file path.\nPad the front of the hash with 0's and split into 5\ngroups of 4 digits.\n*/\nfunc getPathByHash(hash uint64) (path string) {\n\tvar filePath [5]string\n\tj := 0\n\tres := \"\"\n\thashStr := fmt.Sprintf(\"%020d\", hash)\n\n\tfor i, r := range hashStr {\n\t\tres = res + string(r)\n\t\tif i > 0 && (i+1)%4 == 0 {\n\t\t\tfilePath[j] = res\n\t\t\tres = \"\"\n\t\t\tj++\n\t\t}\n\t}\n\n\tpath = rootDir\n\tfor _, s := range filePath {\n\t\tpath += \"/\" + s\n\t}\n\treturn\n}\n\n/*\nGet the file name of a page by taking the host, path, and queries.\nLimit the name to the last 30 characters.\n*/\nfunc getFileNameByURL(uri string) (name string) {\n\tmax := func(a, b int) int {\n\t\tif a > b {\n\t\t\treturn a\n\t\t}\n\t\treturn b\n\t}\n\n\tlink, _ := url.Parse(uri)\n\trunes := []rune(link.Host + link.Path + link.RawQuery)\n\tchars := max(len(runes)-30, 0)\n\tname = string(runes[chars:])\n\tname = strings.Replace(name, \"/\", \"-\", -1)\n\tname = strings.Replace(name, \".\", \"-\", -1)\n\treturn\n}\n\n/*\nCompress a file's contents into the passed bytes buffer.\n*/\nfunc compressFile(buf *bufio.Writer, contents string) {\n\tzw := gzip.NewWriter(buf)\n\t_, err := zw.Write([]byte(contents))\n\tif err != nil {\n\t\tfmt.Println(\"compressFile:\", err)\n\t}\n\tif err = zw.Close(); err != nil {\n\t\tfmt.Println(\"compressFile:\", err)\n\t}\n\treturn\n}\n\n/*\nDecompress file\n*/\nfunc decompressFile(buf io.Reader) string {\n\tzr, err := gzip.NewReader(buf)\n\tif err != nil {\n\t\tfmt.Println(\"1)decompressFile:\", err)\n\t}\n\tcontents, err := ioutil.ReadAll(zr)\n\tif err != nil {\n\t\tfmt.Println(\"2)decompressFile:\", err)\n\t}\n\tzr.Close()\n\treturn string(contents)\n}\n\n// CreateStorage TODO\nfunc CreateStorage(hash uint64, uri, contents string) (file structs.FileStorage) {\n\tfile.Hash = strconv.FormatUint(hash, 10)\n\tfile.Directory = getPathByHash(hash)\n\tfile.Name = getFileNameByURL(uri)\n\tfile.Contents = contents\n\tfile.UID = uuid.NewV4().String()\n\treturn\n}\n\n// SaveFile TODO\nfunc SaveFile(f *structs.FileStorage) {\n\tif !f.FileExists() {\n\t\tos.MkdirAll(f.Directory, 0777)\n\t\tfd, err := os.OpenFile(f.Directory+\"/\"+f.Name, os.O_CREATE|os.O_WRONLY, 0666)\n\t\tif err != nil {\n\t\t\tfmt.Println(\"SaveFile:\", err)\n\t\t}\n\t\twriter := bufio.NewWriter(fd)\n\t\tcompressFile(writer, f.Contents)\n\t\t_ = writer.Flush()\n\t\tfd.Close()\n\t}\n}\n\n/*\nLoadFile will load and decompress a file by name and hash\n*/\nfunc LoadFile(f *structs.FileStorage) {\n\tif f.FileExists() {\n\t\tfd, err := os.OpenFile(f.Directory+\"/\"+f.Name, os.O_RDONLY, 0666)\n\t\tif err != nil {\n\t\t\tfmt.Println(\"LoadFile:\", err)\n\t\t}\n\t\tf.Contents = decompressFile(fd)\n\t\tfd.Close()\n\t}\n}\n"}
{"sample": "package types\n\nimport (\n\t\"time\"\n)\n\nconst (\n\tStakeTokenDenom = \"rowan\"\n)\n\ntype AuthAccountValueCoin struct {\n\tDenom  string `json:\"denom\"`\n\tAmount string `json:\"amount\"`\n}\n\ntype AuthAccountValue struct {\n\tAddress       string                 `json:\"address\"`\n\tCoins         []AuthAccountValueCoin `json:\"coins\"`\n\tPublicKey     interface{}            `json:\"public_key\"`\n\tAccountNumber string                 `json:\"account_number\"`\n\tSequence      string                 `json:\"sequence\"`\n}\n\ntype AuthAccount struct {\n\tType  string           `json:\"type\"`\n\tValue AuthAccountValue `json:\"value\"`\n}\n\ntype AuthParams struct {\n\tMaxMemoCharacters      string `json:\"max_memo_characters\"`\n\tTxSigLimit             string `json:\"tx_sig_limit\"`\n\tTxSizeCostPerByte      string `json:\"tx_size_cost_per_byte\"`\n\tSigVerifyCostEd25519   string `json:\"sig_verify_cost_ed25519\"`\n\tSigVerifyCostSecp256K1 string `json:\"sig_verify_cost_secp256k1\"`\n}\n\ntype Auth struct {\n\tParams   AuthParams    `json:\"params\"`\n\tAccounts []AuthAccount `json:\"accounts\"`\n}\n\ntype GovTallyParams struct {\n\tQuorum    string `json:\"quorum\"`\n\tThreshold string `json:\"threshold\"`\n\tVeto      string `json:\"veto\"`\n}\n\ntype GovVotingParams struct {\n\tVotingPeriod string `json:\"voting_period\"`\n}\n\ntype GovMinDeposit []struct {\n\tDenom  string `json:\"denom\"`\n\tAmount string `json:\"amount\"`\n}\n\ntype GovDepositParams struct {\n\tMinDeposit       GovMinDeposit `json:\"min_deposit\"`\n\tMaxDepositPeriod string        `json:\"max_deposit_period\"`\n}\n\ntype Gov struct {\n\tStartingProposalID string           `json:\"starting_proposal_id\"`\n\tDeposits           interface{}      `json:\"deposits\"`\n\tVotes              interface{}      `json:\"votes\"`\n\tProposals          interface{}      `json:\"proposals\"`\n\tDepositParams      GovDepositParams `json:\"deposit_params\"`\n\tVotingParams       GovVotingParams  `json:\"voting_params\"`\n\tTallyParams        GovTallyParams   `json:\"tally_params\"`\n}\n\ntype GentxValueSignaturePubKey struct {\n\tType  string `json:\"type\"`\n\tValue string `json:\"value\"`\n}\n\ntype GentxValueSignature struct {\n\tPubKey    GentxValueSignaturePubKey `json:\"pub_key\"`\n\tSignature string                    `json:\"signature\"`\n}\n\ntype GentxValueFee struct {\n\tAmount []interface{} `json:\"amount\"`\n\tGas    string        `json:\"gas\"`\n}\n\ntype GentxValueMsgValueValue struct {\n\tDenom  string `json:\"denom\"`\n\tAmount string `json:\"amount\"`\n}\n\ntype GentxValueMsgValueCommission struct {\n\tRate          string `json:\"rate\"`\n\tMaxRate       string `json:\"max_rate\"`\n\tMaxChangeRate string `json:\"max_change_rate\"`\n}\n\ntype GentxValueMsgValueDescription struct {\n\tMoniker         string `json:\"moniker\"`\n\tIdentity        string `json:\"identity\"`\n\tWebsite         string `json:\"website\"`\n\tSecurityContact string `json:\"security_contact\"`\n\tDetails         string `json:\"details\"`\n}\n\ntype GentxValueMsgValue struct {\n\tDescription       GentxValueMsgValueDescription `json:\"description\"`\n\tCommission        GentxValueMsgValueCommission  `json:\"commission\"`\n\tMinSelfDelegation string                        `json:\"min_self_delegation\"`\n\tDelegatorAddress  string                        `json:\"delegator_address\"`\n\tValidatorAddress  string                        `json:\"validator_address\"`\n\tPubkey            string                        `json:\"pubkey\"`\n\tValue             GentxValueMsgValueValue       `json:\"value\"`\n}\n\ntype GentxValueMsg struct {\n\tType  string             `json:\"type\"`\n\tValue GentxValueMsgValue `json:\"value\"`\n}\n\ntype GentxValue struct {\n\tMsg        []GentxValueMsg       `json:\"msg\"`\n\tFee        GentxValueFee         `json:\"fee\"`\n\tSignatures []GentxValueSignature `json:\"signatures\"`\n\tMemo       string                `json:\"memo\"`\n}\n\ntype Gentx struct {\n\tType  string     `json:\"type\"`\n\tValue GentxValue `json:\"value\"`\n}\n\ntype Genutil struct {\n\tGentxs []Gentx `json:\"gentxs\"`\n}\n\ntype Upgrade struct{}\n\ntype CLPParams struct {\n\tMinCreatePoolThreshold string `json:\"min_create_pool_threshold\"`\n}\n\ntype CLP struct {\n\tParams                CLPParams   `json:\"params\"`\n\tAddressWhitelist      interface{} `json:\"address_whitelist\"`\n\tPoolList              interface{} `json:\"pool_list\"`\n\tLiquidityProviderList interface{} `json:\"liquidity_provider_list\"`\n\tCLPModuleAddress      string      `json:\"clp_module_address\"`\n}\n\ntype Faucet struct {\n\tValue string `json:\"value\"`\n}\n\ntype Supply struct {\n\tSupply []interface{} `json:\"supply\"`\n}\n\ntype Staking struct {\n\tParams               StakingParams `json:\"params\"`\n\tLastTotalPower       string        `json:\"last_total_power\"`\n\tLastValidatorPowers  interface{}   `json:\"last_validator_powers\"`\n\tValidators           interface{}   `json:\"validators\"`\n\tDelegations          interface{}   `json:\"delegations\"`\n\tUnbondingDelegations interface{}   `json:\"unbonding_delegations\"`\n\tRedelegations        interface{}   `json:\"redelegations\"`\n\tExported             bool          `json:\"exported\"`\n}\n\ntype StakingParams struct {\n\tUnbondingTime     string `json:\"unbonding_time\"`\n\tMaxValidators     int    `json:\"max_validators\"`\n\tMaxEntries        int    `json:\"max_entries\"`\n\tHistoricalEntries int    `json:\"historical_entries\"`\n\tBondDenom         string `json:\"bond_denom\"`\n}\n\ntype Distribution struct {\n\tParams                          DistributionParams `json:\"params\" yaml:\"params\"`\n\tFeePool                         interface{}        `json:\"fee_pool\" yaml:\"fee_pool\"`\n\tDelegatorWithdrawInfos          interface{}        `json:\"delegator_withdraw_infos\" yaml:\"delegator_withdraw_infos\"`\n\tPreviousProposer                interface{}        `json:\"previous_proposer\" yaml:\"previous_proposer\"`\n\tOutstandingRewards              interface{}        `json:\"outstanding_rewards\" yaml:\"outstanding_rewards\"`\n\tValidatorAccumulatedCommissions interface{}        `json:\"validator_accumulated_commissions\" yaml:\"validator_accumulated_commissions\"`\n\tValidatorHistoricalRewards      interface{}        `json:\"validator_historical_rewards\" yaml:\"validator_historical_rewards\"`\n\tValidatorCurrentRewards         interface{}        `json:\"validator_current_rewards\" yaml:\"validator_current_rewards\"`\n\tDelegatorStartingInfos          interface{}        `json:\"delegator_starting_infos\" yaml:\"delegator_starting_infos\"`\n\tValidatorSlashEvents            interface{}        `json:\"validator_slash_events\" yaml:\"validator_slash_events\"`\n}\n\ntype DistributionParams struct {\n\tCommunityTax        interface{} `json:\"community_tax\" yaml:\"community_tax\"`\n\tBaseProposerReward  interface{} `json:\"base_proposer_reward\" yaml:\"base_proposer_reward\"`\n\tBonusProposerReward interface{} `json:\"bonus_proposer_reward\" yaml:\"bonus_proposer_reward\"`\n\tWithdrawAddrEnabled interface{} `json:\"withdraw_addr_enabled\" yaml:\"withdraw_addr_enabled\"`\n}\n\ntype Slashing struct {\n\tParams       SlashingParams `json:\"params\" yaml:\"params\"`\n\tSigningInfos interface{}    `json:\"signing_infos\" yaml:\"signing_infos\"`\n\tMissedBlocks interface{}    `json:\"missed_blocks\" yaml:\"missed_blocks\"`\n}\n\ntype SlashingParams struct {\n\tSignedBlocksWindow      interface{} `json:\"signed_blocks_window\" yaml:\"signed_blocks_window\"`\n\tMinSignedPerWindow      interface{} `json:\"min_signed_per_window\" yaml:\"min_signed_per_window\"`\n\tDowntimeJailDuration    interface{} `json:\"downtime_jail_duration\" yaml:\"downtime_jail_duration\"`\n\tSlashFractionDoubleSign interface{} `json:\"slash_fraction_double_sign\" yaml:\"slash_fraction_double_sign\"`\n\tSlashFractionDowntime   interface{} `json:\"slash_fraction_downtime\" yaml:\"slash_fraction_downtime\"`\n}\ntype Bank struct {\n\tSendEnabled bool `json:\"send_enabled\"`\n}\n\ntype AppState struct {\n\tBank         Bank         `json:\"bank\"`\n\tStaking      Staking      `json:\"staking\"`\n\tParams       interface{}  `json:\"params\"`\n\tSupply       Supply       `json:\"supply\"`\n\tEthbridge    interface{}  `json:\"ethbridge\"`\n\tCLP          CLP          `json:\"clp\"`\n\tUpgrade      Upgrade      `json:\"upgrade\"`\n\tOracle       interface{}  `json:\"oracle\"`\n\tGenutil      Genutil      `json:\"genutil\"`\n\tGov          Gov          `json:\"gov\"`\n\tAuth         Auth         `json:\"auth\"`\n\tSlashing     Slashing     `json:\"slashing\"`\n\tDistribution Distribution `json:\"distribution\"`\n\tFaucet       Faucet       `json:\"faucet\"`\n\tDispensation interface{}  `json:\"dispensation\"`\n}\n\ntype Evidence struct {\n\tMaxAgeNumBlocks string `json:\"max_age_num_blocks\"`\n\tMaxAgeDuration  string `json:\"max_age_duration\"`\n}\n\ntype Validator struct {\n\tPubKeyTypes []string `json:\"pub_key_types\"`\n}\n\ntype Block struct {\n\tMaxBytes   string `json:\"max_bytes\"`\n\tMaxGas     string `json:\"max_gas\"`\n\tTimeIotaMs string `json:\"time_iota_ms\"`\n}\n\ntype ConsensusParams struct {\n\tBlock     Block     `json:\"block\"`\n\tEvidence  Evidence  `json:\"evidence\"`\n\tValidator Validator `json:\"validator\"`\n}\n\ntype Genesis struct {\n\tGenesisTime     time.Time       `json:\"genesis_time\"`\n\tChainID         string          `json:\"chain_id\"`\n\tConsensusParams ConsensusParams `json:\"consensus_params\"`\n\tAppHash         string          `json:\"app_hash\"`\n\tAppState        AppState        `json:\"app_state\"`\n}\n"}
{"sample": "// Copyright 2018 tsuru authors. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\npackage v1\n\nimport (\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n)\n\n// +genclient\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\n// App is a specification for a App resource\ntype App struct {\n\tmetav1.TypeMeta   `json:\",inline\"`\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n\tSpec AppSpec `json:\"spec\"`\n}\n\n// AppSpec is the spec for a App resource\ntype AppSpec struct {\n\tNamespaceName      string              `json:\"namespaceName\"`\n\tServiceAccountName string              `json:\"serviceAccountName\"`\n\tDeployments        map[string][]string `json:\"deployments\"`\n\tServices           map[string][]string `json:\"services\"`\n}\n\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\n// FooList is a list of Foo resources\ntype AppList struct {\n\tmetav1.TypeMeta `json:\",inline\"`\n\tmetav1.ListMeta `json:\"metadata\"`\n\n\tItems []App `json:\"items\"`\n}\n"}
{"sample": "// Copyright 2021 SIA ZZ Dats. All rights reserved.\n// Use of this source code is governed by a MIT-style\n// license that can be found in the LICENSE file.\n\npackage cose\n\n// SignMessage represents a COSE_Sign message.\ntype SignMessage struct {\n\tHeaders *Headers\n\tsigners []*Signer\n\tcontent []byte\n}\n\n// NewSignMessage creates a new SignMessage instance.\nfunc NewSignMessage() *SignMessage {\n\treturn &SignMessage{\n\t\tHeaders: NewHeaders(),\n\t\tsigners: make([]*Signer, 0),\n\t}\n}\n\n// GetMessageTag returns the COSE_Sign message tag.\nfunc (m *SignMessage) GetMessageTag() uint64 {\n\treturn MessageTagSign\n}\n\n// GetContent returns the message content.\nfunc (m *SignMessage) GetContent() []byte {\n\treturn m.content\n}\n\n// SetContent sets the message content.\nfunc (m *SignMessage) SetContent(content []byte) {\n\tm.content = content\n}\n\n// AddSigner adds a signer for the message.\nfunc (m *SignMessage) AddSigner(signer *Signer) {\n\tif signer == nil {\n\t\treturn\n\t}\n\tm.signers = append(m.signers, signer)\n}\n\nfunc (m *SignMessage) sign(e *Encoding, external []byte) (interface{}, error) {\n\tph, err := e.marshal(m.Headers.protected)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmsg := signMessage{\n\t\tProtected:   ph,\n\t\tUnprotected: m.Headers.unprotected,\n\t\tPayload:     m.GetContent(),\n\t\tSignatures:  make([]*signMessageSignature, len(m.signers)),\n\t}\n\tfor i, signer := range m.signers {\n\t\tsheaders, err := signer.GetHeaders()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tph, err := e.marshal(sheaders.protected)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tdigest, err := msg.GetDigest(e, ph, external)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tmsg.Signatures[i] = &signMessageSignature{\n\t\t\tProtected:   ph,\n\t\t\tUnprotected: sheaders.unprotected,\n\t\t}\n\t\tmsg.Signatures[i].Signature, err = signer.Sign(e.rand, digest)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn msg, nil\n}\n\ntype signMessageSignature struct {\n\t_           struct{} `cbor:\",toarray\"`\n\tProtected   []byte\n\tUnprotected map[interface{}]interface{}\n\tSignature   []byte\n}\n\ntype signMessage struct {\n\t_           struct{} `cbor:\",toarray\"`\n\tProtected   []byte\n\tUnprotected map[interface{}]interface{}\n\tPayload     []byte\n\tSignatures  []*signMessageSignature\n}\n\nfunc (m *signMessage) GetDigest(e *Encoding, signerProtected []byte, external []byte) ([]byte, error) {\n\treturn e.marshal([]interface{}{\n\t\t\"Signature\",\n\t\tm.Protected,\n\t\tsignerProtected,\n\t\texternal,\n\t\tm.Payload,\n\t})\n}\n\nfunc newSignMessage(e *Encoding, c *signMessage) (*SignMessage, error) {\n\th, err := newHeaders(e, c.Protected, c.Unprotected)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &SignMessage{\n\t\tHeaders: h,\n\t\tcontent: c.Payload,\n\t}, nil\n}\n"}
{"sample": "package websocket\n\nimport (\n\t\"github.com/gorilla/websocket\"\n\t\"github.com/madhouseminers/chatshare-server/internal/clients\"\n\t\"log\"\n\t\"net/http\"\n\t\"sync\"\n)\n\nvar upgrader = websocket.Upgrader{\n\tReadBufferSize:  1024,\n\tWriteBufferSize: 1024,\n\tCheckOrigin: func(r *http.Request) bool {\n\t\treturn true\n\t},\n}\n\ntype messageBus interface {\n\tDirect(message *clients.Message, clientName string)\n\tAddClient(client clients.Client)\n\tRemoveClient(client clients.Client)\n\tBroadcast(message *clients.Message)\n}\n\ntype httpServer struct {\n\tbus messageBus\n}\n\nfunc StartServer(bus messageBus, ws *sync.WaitGroup) *httpServer {\n\tserver := &http.Server{\n\t\tAddr: \":8080\",\n\t}\n\th := &httpServer{bus: bus}\n\thttp.HandleFunc(\"/\", func(writer http.ResponseWriter, request *http.Request) {\n\t\t_, err := writer.Write([]byte(\"OK\"))\n\t\tif err != nil {\n\t\t\tlog.Println(\"Error responding to health check: \" + err.Error())\n\t\t}\n\t})\n\thttp.HandleFunc(\"/ws\", h.upgradeHandler)\n\tws.Add(1)\n\tgo func() {\n\t\terr := server.ListenAndServe()\n\t\tif err != nil {\n\t\t\tlog.Println(\"Unable to close server: \" + err.Error())\n\t\t}\n\t\tws.Done()\n\t}()\n\treturn h\n}\n\nfunc (h *httpServer) upgradeHandler(w http.ResponseWriter, r *http.Request) {\n\tconn, err := upgrader.Upgrade(w, r, nil)\n\tif err != nil {\n\t\tlog.Println(\"Error upgrading request: \" + err.Error())\n\t\treturn\n\t}\n\tcreateHandler(conn, h.bus)\n}\n"}
{"sample": "package etcd\n\nimport (\n\t\"testing\"\n\n\t\"github.com/sensu/sensu-go/backend/store\"\n)\n\nfunc Test_checkIfMatch(t *testing.T) {\n\ttests := []struct {\n\t\tname   string\n\t\theader string\n\t\tetag   string\n\t\twant   bool\n\t}{\n\t\t{\n\t\t\tname: \"empty header should return true\",\n\t\t\tetag: `\"12345\"`,\n\t\t\twant: true,\n\t\t},\n\t\t{\n\t\t\tname:   \"empty etag should return false\",\n\t\t\theader: `\"\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   false,\n\t\t},\n\t\t{\n\t\t\tname:   \"the asterisk is a special value that represents any resource\",\n\t\t\theader: \"*\",\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   true,\n\t\t},\n\t\t{\n\t\t\tname:   \"matching etag\",\n\t\t\theader: `\"12345\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   true,\n\t\t},\n\t\t{\n\t\t\tname:   \"multiple etags can be passed in the header\",\n\t\t\theader: `\"000\", \"12345\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   true,\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif got := store.CheckIfMatch(tt.header, tt.etag); got != tt.want {\n\t\t\t\tt.Errorf(\"checkIfMatch() = %v, want %v\", got, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc Test_checkIfNoneMatch(t *testing.T) {\n\ttests := []struct {\n\t\tname   string\n\t\theader string\n\t\tetag   string\n\t\twant   bool\n\t}{\n\t\t{\n\t\t\tname: \"empty header should return true\",\n\t\t\tetag: `\"12345\"`,\n\t\t\twant: true,\n\t\t},\n\t\t{\n\t\t\tname:   \"empty etag should return true\",\n\t\t\theader: `\"\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   true,\n\t\t},\n\t\t{\n\t\t\tname:   \"the asterisk is a special value that represents any resource\",\n\t\t\theader: \"*\",\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   false,\n\t\t},\n\t\t{\n\t\t\tname:   \"matching etag\",\n\t\t\theader: `\"12345\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   false,\n\t\t},\n\t\t{\n\t\t\tname:   \"multiple etags can be passed in the header\",\n\t\t\theader: `\"000\", \"12345\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   false,\n\t\t},\n\t\t{\n\t\t\tname:   \"the W/ prefix is handled\",\n\t\t\theader: `W/\"12345\"`,\n\t\t\tetag:   `\"12345\"`,\n\t\t\twant:   false,\n\t\t},\n\t}\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tif got := store.CheckIfNoneMatch(tt.header, tt.etag); got != tt.want {\n\t\t\t\tt.Errorf(\"checkIfNoneMatch() = %v, want %v\", got, tt.want)\n\t\t\t}\n\t\t})\n\t}\n}\n"}
{"sample": "package blockchain\n\n// Copyright (c) Microsoft Corporation. All rights reserved.\n// Licensed under the MIT License. See License.txt in the project root for license information.\n//\n// Code generated by Microsoft (R) AutoRest Code Generator.\n// Changes may cause incorrect behavior and will be lost if the code is regenerated.\n\n// MemberProvisioningState enumerates the values for member provisioning state.\ntype MemberProvisioningState string\n\nconst (\n\t// Deleting ...\n\tDeleting MemberProvisioningState = \"Deleting\"\n\t// Failed ...\n\tFailed MemberProvisioningState = \"Failed\"\n\t// NotSpecified ...\n\tNotSpecified MemberProvisioningState = \"NotSpecified\"\n\t// Stale ...\n\tStale MemberProvisioningState = \"Stale\"\n\t// Succeeded ...\n\tSucceeded MemberProvisioningState = \"Succeeded\"\n\t// Updating ...\n\tUpdating MemberProvisioningState = \"Updating\"\n)\n\n// PossibleMemberProvisioningStateValues returns an array of possible values for the MemberProvisioningState const type.\nfunc PossibleMemberProvisioningStateValues() []MemberProvisioningState {\n\treturn []MemberProvisioningState{Deleting, Failed, NotSpecified, Stale, Succeeded, Updating}\n}\n\n// NameAvailabilityReason enumerates the values for name availability reason.\ntype NameAvailabilityReason string\n\nconst (\n\t// NameAvailabilityReasonAlreadyExists ...\n\tNameAvailabilityReasonAlreadyExists NameAvailabilityReason = \"AlreadyExists\"\n\t// NameAvailabilityReasonInvalid ...\n\tNameAvailabilityReasonInvalid NameAvailabilityReason = \"Invalid\"\n\t// NameAvailabilityReasonNotSpecified ...\n\tNameAvailabilityReasonNotSpecified NameAvailabilityReason = \"NotSpecified\"\n)\n\n// PossibleNameAvailabilityReasonValues returns an array of possible values for the NameAvailabilityReason const type.\nfunc PossibleNameAvailabilityReasonValues() []NameAvailabilityReason {\n\treturn []NameAvailabilityReason{NameAvailabilityReasonAlreadyExists, NameAvailabilityReasonInvalid, NameAvailabilityReasonNotSpecified}\n}\n\n// NodeProvisioningState enumerates the values for node provisioning state.\ntype NodeProvisioningState string\n\nconst (\n\t// NodeProvisioningStateDeleting ...\n\tNodeProvisioningStateDeleting NodeProvisioningState = \"Deleting\"\n\t// NodeProvisioningStateFailed ...\n\tNodeProvisioningStateFailed NodeProvisioningState = \"Failed\"\n\t// NodeProvisioningStateNotSpecified ...\n\tNodeProvisioningStateNotSpecified NodeProvisioningState = \"NotSpecified\"\n\t// NodeProvisioningStateSucceeded ...\n\tNodeProvisioningStateSucceeded NodeProvisioningState = \"Succeeded\"\n\t// NodeProvisioningStateUpdating ...\n\tNodeProvisioningStateUpdating NodeProvisioningState = \"Updating\"\n)\n\n// PossibleNodeProvisioningStateValues returns an array of possible values for the NodeProvisioningState const type.\nfunc PossibleNodeProvisioningStateValues() []NodeProvisioningState {\n\treturn []NodeProvisioningState{NodeProvisioningStateDeleting, NodeProvisioningStateFailed, NodeProvisioningStateNotSpecified, NodeProvisioningStateSucceeded, NodeProvisioningStateUpdating}\n}\n\n// Protocol enumerates the values for protocol.\ntype Protocol string\n\nconst (\n\t// ProtocolCorda ...\n\tProtocolCorda Protocol = \"Corda\"\n\t// ProtocolNotSpecified ...\n\tProtocolNotSpecified Protocol = \"NotSpecified\"\n\t// ProtocolParity ...\n\tProtocolParity Protocol = \"Parity\"\n\t// ProtocolQuorum ...\n\tProtocolQuorum Protocol = \"Quorum\"\n)\n\n// PossibleProtocolValues returns an array of possible values for the Protocol const type.\nfunc PossibleProtocolValues() []Protocol {\n\treturn []Protocol{ProtocolCorda, ProtocolNotSpecified, ProtocolParity, ProtocolQuorum}\n}\n"}
{"sample": "package abbotgopb\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/gogo/protobuf/proto\"\n)\n\nfunc NewResponse(resp proto.Marshaler) (*Response, error) {\n\tif resp == nil {\n\t\treturn &Response{Kind: RESP_DONE, Body: nil}, nil\n\t}\n\n\tvar kind ResponseType\n\tswitch resp.(type) {\n\tcase *ContainerNetworkConfigResponse:\n\t\tkind = RESP_CTR_NETWORK_CONFIG\n\tcase *ContainerNetworkStatusResponse:\n\t\tkind = RESP_CTR_NETWORK_STATUS\n\tcase *ContainerNetworkStatusListResponse:\n\t\tkind = RESP_CTR_NETWORK_STATUS_LIST\n\tcase *HostNetworkConfigResponse:\n\t\tkind = RESP_HOST_NETWORK_CONFIG\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unkonw response type\")\n\t}\n\n\tdata, err := resp.Marshal()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to marshal response body: %w\", err)\n\t}\n\n\treturn &Response{\n\t\tKind: kind,\n\t\tBody: data,\n\t}, nil\n}\n\nfunc NewContainerNetworkConfigResponse(\n\tipv4Subnet, ipv6Subnet string,\n) *ContainerNetworkConfigResponse {\n\treturn &ContainerNetworkConfigResponse{\n\t\tIpv4Subnet: ipv4Subnet,\n\t\tIpv6Subnet: ipv6Subnet,\n\t}\n}\n\nfunc NewContainerNetworkStatusResponse(\n\tpid uint32,\n\tinterfaces []*NetworkInterface,\n) *ContainerNetworkStatusResponse {\n\treturn &ContainerNetworkStatusResponse{Interfaces: interfaces}\n}\n\nfunc NewContainerNetworkStatusListResponse(\n\tnets map[string]*ContainerNetworkStatusResponse,\n) *ContainerNetworkStatusListResponse {\n\treturn &ContainerNetworkStatusListResponse{\n\t\tContainerNetworks: nets,\n\t}\n}\n\nfunc NewHostNetworkConfigResponse(\n\tinterfaces ...*HostNetworkInterface,\n) *HostNetworkConfigResponse {\n\treturn &HostNetworkConfigResponse{\n\t\tActual: interfaces,\n\t}\n}\n"}
{"sample": "package platformclientv2\nimport (\n\t\"encoding/json\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// Roledivision\ntype Roledivision struct { \n\t// RoleId - Role to be associated with the given division which forms a grant\n\tRoleId *string `json:\"roleId,omitempty\"`\n\n\n\t// DivisionId - Division associated with the given role which forms a grant\n\tDivisionId *string `json:\"divisionId,omitempty\"`\n\n}\n\n// String returns a JSON representation of the model\nfunc (o *Roledivision) String() string {\n\tj, _ := json.Marshal(o)\n\tstr, _ := strconv.Unquote(strings.Replace(strconv.Quote(string(j)), `\\\\u`, `\\u`, -1))\n\n\treturn str\n}\n"}
{"sample": "package main\n\nimport (\n\t\"bytes\"\n\t\"flag\"\n\t\"fmt\"\n\t\"log\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"text/template\"\n)\n\n// NOTE: Instead of using this script we are using bazel's go_embed_data.\n// This script may be removed in the future.\n\nvar (\n\tin         = flag.String(\"in\", \"\", \"The path to the directory that contains text files.\")\n\tout        = flag.String(\"out\", \"\", \"The path to put the generated go file.\")\n\toutPackage = flag.String(\"out-package\", \"\", \"The go package for generated file.\")\n\n\tcodeTemplate = `\npackage {{ .Package }}\n\nvar (\n{{- range $name, $data := .Data }}\n\t{{ formatName $name }} = {{ formatString $data }}\n{{- end }}\n)\n`\n)\n\nfunc main() {\n\tflag.Parse()\n\tif err := validateFlags(); err != nil {\n\t\tlog.Fatalf(\"invalidate flag: %v\", err)\n\t}\n\n\tlicense, err := os.ReadFile(\"./hack/boilerplate.go.txt\")\n\tif err != nil {\n\t\tlog.Fatalf(\"unable to read license file: %v\", err)\n\t}\n\n\tdata, err := loadData(*in)\n\tif err != nil {\n\t\tlog.Fatalf(\"unable to load data from %s: %v\", *in, err)\n\t}\n\n\tvar maxNameLength = 0\n\tfor k := range data {\n\t\tif maxNameLength < len(k) {\n\t\t\tmaxNameLength = len(k)\n\t\t}\n\t}\n\tformat := \"%-\" + fmt.Sprintf(\"%d\", maxNameLength) + \"s\"\n\tformatName := func(s string) string {\n\t\treturn fmt.Sprintf(format, s)\n\t}\n\n\tfileTemplate := string(license) + codeTemplate\n\ttmpl, err := template.New(\"template\").\n\t\tFuncs(template.FuncMap{\n\t\t\t\"formatName\":   formatName,\n\t\t\t\"formatString\": formatString,\n\t\t}).\n\t\tParse(fileTemplate)\n\tif err != nil {\n\t\tlog.Fatalf(\"unable to make template: %v\", err)\n\t}\n\n\tgeneratedCode, err := renderTemplate(tmpl, map[string]interface{}{\n\t\t\"Package\":    *outPackage,\n\t\t\"Data\":       data,\n\t\t\"NameLength\": 50,\n\t})\n\tif err != nil {\n\t\tlog.Fatalf(\"unable to render go file: %v\", err)\n\t}\n\n\tif err = os.WriteFile(*out, []byte(generatedCode), os.ModePerm); err != nil {\n\t\tlog.Fatalf(\"unable to write go file to %s: %v\", *out, err)\n\t}\n\tlog.Printf(\"successfully generated file: %s\", *out)\n}\n\nfunc validateFlags() error {\n\tif *in == \"\" {\n\t\treturn fmt.Errorf(\"in is required\")\n\t}\n\tif *out == \"\" {\n\t\treturn fmt.Errorf(\"out is required\")\n\t}\n\tif *outPackage == \"\" {\n\t\treturn fmt.Errorf(\"out-package is required\")\n\t}\n\treturn nil\n}\n\nfunc loadData(root string) (map[string]interface{}, error) {\n\tdata := make(map[string]interface{})\n\terr := filepath.Walk(root, func(path string, info os.FileInfo, err error) error {\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif path == root {\n\t\t\treturn nil\n\t\t}\n\t\tif info.IsDir() {\n\t\t\treturn filepath.SkipDir\n\t\t}\n\t\tif !info.Mode().IsRegular() {\n\t\t\treturn nil\n\t\t}\n\t\tbytes, err := os.ReadFile(path)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tdata[filepath.Base(path)] = bytes\n\t\treturn nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn data, nil\n}\n\nfunc formatString(bytes []byte) string {\n\treturn fmt.Sprintf(\"%#v\", string(bytes))\n}\n\nfunc renderTemplate(tmpl *template.Template, data map[string]interface{}) (string, error) {\n\tbuf := new(bytes.Buffer)\n\tif err := tmpl.Execute(buf, data); err != nil {\n\t\treturn \"\", err\n\t}\n\treturn buf.String(), nil\n}\n"}
{"sample": "package ctl\n\nimport (\n\t\"io\"\n\n\tkp \"gopkg.in/alecthomas/kingpin.v2\"\n)\n\n// Action is a CTL action\ntype Action func() error\n\n// CmdClause is a proxy interface to kingpin's *CmdClause\ntype CmdClause kp.CmdClause\n\n// FlagClause is a proxy interface to kingpin's *FlagClause\ntype FlagClause kp.FlagClause\n\n// Application is a proxy interface to kingpin's *Application\ntype Application interface {\n\tVersion(version string) Application\n\tParse(args []string) (command string, err error)\n\tCommand(name, help string) *CmdClause\n\tFlag(name, help string) *FlagClause\n\tTerminate(terminate func(int)) Application\n\tErrorWriter(w io.Writer) Application\n\tUsageWriter(w io.Writer) Application\n}\n\ntype proxyapp struct {\n\t*kp.Application\n}\n\n// NewApplication creates a new application instance\nfunc NewApplication(name, help string) Application {\n\treturn &proxyapp{\n\t\tApplication: kp.New(name, help),\n\t}\n}\n\nfunc (a *proxyapp) Terminate(terminate func(int)) Application {\n\ta.Application.Terminate(terminate)\n\treturn a\n}\n\nfunc (a *proxyapp) Parse(args []string) (command string, err error) {\n\treturn a.Application.Parse(args)\n}\n\n// ErrorWriter sets the io.Writer to use for errors.\nfunc (a *proxyapp) ErrorWriter(w io.Writer) Application {\n\ta.Application.ErrorWriter(w)\n\treturn a\n}\n\n// UsageWriter sets the io.Writer to use for errors.\nfunc (a *proxyapp) UsageWriter(w io.Writer) Application {\n\ta.Application.UsageWriter(w)\n\treturn a\n}\n\n// Version adds a --version flag for displaying the application version.\nfunc (a *proxyapp) Version(version string) Application {\n\ta.Application.Version(version)\n\treturn a\n}\n\n// Command adds a new top-level command.\nfunc (a *proxyapp) Command(name, help string) *CmdClause {\n\treturn (*CmdClause)(a.Application.Command(name, help))\n}\n\n// Alias adds an alias for this command.\nfunc (c *CmdClause) Alias(name string) *CmdClause {\n\tkpc := (*kp.CmdClause)(c)\n\treturn (*CmdClause)(kpc.Alias(name))\n}\n\n// Command adds a new sub-command.\nfunc (c *CmdClause) Command(name, help string) *CmdClause {\n\tkpc := (*kp.CmdClause)(c)\n\treturn (*CmdClause)(kpc.Command(name, help))\n}\n\n// Action adds a action for this command.\nfunc (c *CmdClause) Action(action Action) *CmdClause {\n\tkpc := (*kp.CmdClause)(c)\n\tkpa := func(*kp.ParseContext) error {\n\t\treturn action()\n\t}\n\treturn (*CmdClause)(kpc.Action(kpa))\n}\n\n// PreAction adds a pre-action for this command.\nfunc (c *CmdClause) PreAction(action Action) *CmdClause {\n\tkpc := (*kp.CmdClause)(c)\n\tkpa := func(*kp.ParseContext) error {\n\t\treturn action()\n\t}\n\treturn (*CmdClause)(kpc.PreAction(kpa))\n}\n\nfunc (a *proxyapp) Flag(name, help string) *FlagClause {\n\tf := a.Application.Flag(name, help)\n\treturn (*FlagClause)(f)\n}\n\n// Default values for this flag. They *must* be parseable by the value of the flag.\nfunc (f *FlagClause) Default(values ...string) *FlagClause {\n\tkpf := (*kp.FlagClause)(f)\n\treturn (*FlagClause)(kpf.Default(values...))\n}\n\n// Hidden hides a flag from usage but still allows it to be used.\nfunc (f *FlagClause) Hidden() *FlagClause {\n\tkpf := (*kp.FlagClause)(f)\n\treturn (*FlagClause)(kpf.Hidden())\n}\n\n// Required makes the flag required. You can not provide a Default() value to a Required() flag.\nfunc (f *FlagClause) Required() *FlagClause {\n\tkpf := (*kp.FlagClause)(f)\n\treturn (*FlagClause)(kpf.Required())\n}\n\n// Short sets the short flag name.\nfunc (f *FlagClause) Short(name rune) *FlagClause {\n\tkpf := (*kp.FlagClause)(f)\n\treturn (*FlagClause)(kpf.Short(name))\n}\n\n// Bool makes this flag a boolean flag.\nfunc (f *FlagClause) Bool() (target *bool) {\n\tkpf := (*kp.FlagClause)(f)\n\treturn kpf.Bool()\n}\n\n// Settings interface\ntype Settings kp.Settings\n\n// GetFilesList retruns list from command arguments\nfunc GetFilesList(s Settings) *FilesList {\n\ttarget := (*FilesList)(new([]string))\n\ts.SetValue(target)\n\treturn target\n}\n"}
{"sample": "package main\n\nimport (\n\t\"github.com/kataras/iris/v12\"\n\t\"github.com/kataras/iris/v12/mvc\"\n\n\t\"github.com/kataras/iris/v12/middleware/logger\"\n\t\"github.com/kataras/iris/v12/middleware/recover\"\n)\n\n// This example is equivalent to the\n// https://github.com/kataras/iris/blob/master/_examples/hello-world/main.go\n//\n// It seems that additional code you\n// have to write doesn't worth it\n// but remember that, this example\n// does not make use of iris mvc features like\n// the Model, Persistence or the View engine neither the Session,\n// it's very simple for learning purposes,\n// probably you'll never use such\n// as simple controller anywhere in your app.\n//\n// The cost we have on this example for using MVC\n// on the \"/hello\" path which serves JSON\n// is ~2MB per 20MB throughput on my personal laptop,\n// it's tolerated for the majority of the applications\n// but you can choose\n// what suits you best with Iris, low-level handlers: performance\n// or high-level controllers: easier to maintain and smaller codebase on large applications.\n\n// Of course you can put all these to main func, it's just a separate function\n// for the main_test.go.\nfunc newApp() *iris.Application {\n\tapp := iris.New()\n\t// Optionally, add two builtin handlers\n\t// that can recover from any http-relative panics\n\t// and log the requests to the terminal.\n\tapp.Use(recover.New())\n\tapp.Use(logger.New())\n\n\t// Serve a controller based on the root Router, \"/\".\n\tmvc.New(app).Handle(new(ExampleController))\n\treturn app\n}\n\nfunc main() {\n\tapp := newApp()\n\n\t// http://localhost:8080\n\t// http://localhost:8080/ping\n\t// http://localhost:8080/hello\n\t// http://localhost:8080/custom_path\n\tapp.Run(iris.Addr(\":8080\"))\n}\n\n// ExampleController serves the \"/\", \"/ping\" and \"/hello\".\ntype ExampleController struct{}\n\n// Get serves\n// Method:   GET\n// Resource: http://localhost:8080\nfunc (c *ExampleController) Get() mvc.Result {\n\treturn mvc.Response{\n\t\tContentType: \"text/html\",\n\t\tText:        \"<h1>Welcome</h1>\",\n\t}\n}\n\n// GetPing serves\n// Method:   GET\n// Resource: http://localhost:8080/ping\nfunc (c *ExampleController) GetPing() string {\n\treturn \"pong\"\n}\n\n// GetHello serves\n// Method:   GET\n// Resource: http://localhost:8080/hello\nfunc (c *ExampleController) GetHello() interface{} {\n\treturn map[string]string{\"message\": \"Hello Iris!\"}\n}\n\n// BeforeActivation called once, before the controller adapted to the main application\n// and of course before the server ran.\n// After version 9 you can also add custom routes for a specific controller's methods.\n// Here you can register custom method's handlers\n// use the standard router with `ca.Router` to do something that you can do without mvc as well,\n// and add dependencies that will be binded to a controller's fields or method function's input arguments.\nfunc (c *ExampleController) BeforeActivation(b mvc.BeforeActivation) {\n\tanyMiddlewareHere := func(ctx iris.Context) {\n\t\tctx.Application().Logger().Warnf(\"Inside /custom_path\")\n\t\tctx.Next()\n\t}\n\tb.Handle(\"GET\", \"/custom_path\", \"CustomHandlerWithoutFollowingTheNamingGuide\", anyMiddlewareHere)\n\n\t// or even add a global middleware based on this controller's router,\n\t// which in this example is the root \"/\":\n\t// b.Router().Use(myMiddleware)\n}\n\n// CustomHandlerWithoutFollowingTheNamingGuide serves\n// Method:   GET\n// Resource: http://localhost:8080/custom_path\nfunc (c *ExampleController) CustomHandlerWithoutFollowingTheNamingGuide() string {\n\treturn \"hello from the custom handler without following the naming guide\"\n}\n\n// GetUserBy serves\n// Method:   GET\n// Resource: http://localhost:8080/user/{username:string}\n// By is a reserved \"keyword\" to tell the framework that you're going to\n// bind path parameters in the function's input arguments, and it also\n// helps to have \"Get\" and \"GetBy\" in the same controller.\n//\n// func (c *ExampleController) GetUserBy(username string) mvc.Result {\n// \treturn mvc.View{\n// \t\tName: \"user/username.html\",\n// \t\tData: username,\n// \t}\n// }\n\n/* Can use more than one, the factory will make sure\nthat the correct http methods are being registered for each route\nfor this controller, uncomment these if you want:\n\nfunc (c *ExampleController) Post() {}\nfunc (c *ExampleController) Put() {}\nfunc (c *ExampleController) Delete() {}\nfunc (c *ExampleController) Connect() {}\nfunc (c *ExampleController) Head() {}\nfunc (c *ExampleController) Patch() {}\nfunc (c *ExampleController) Options() {}\nfunc (c *ExampleController) Trace() {}\n*/\n\n/*\nfunc (c *ExampleController) All() {}\n//        OR\nfunc (c *ExampleController) Any() {}\n\n\n\nfunc (c *ExampleController) BeforeActivation(b mvc.BeforeActivation) {\n\t// 1 -> the HTTP Method\n\t// 2 -> the route's path\n\t// 3 -> this controller's method name that should be handler for that route.\n\tb.Handle(\"GET\", \"/mypath/{param}\", \"DoIt\", optionalMiddlewareHere...)\n}\n\n// After activation, all dependencies are set-ed - so read only access on them\n// but still possible to add custom controller or simple standard handlers.\nfunc (c *ExampleController) AfterActivation(a mvc.AfterActivation) {}\n\n*/\n"}
{"sample": "/*\nCopyright 2018 The Knative Authors.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage v1alpha1\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"sort\"\n\t\"time\"\n\n\tbuild \"github.com/knative/build/pkg/apis/build/v1alpha1\"\n\n\tcorev1 \"k8s.io/api/core/v1\"\n\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n\n\t\"github.com/knative/pkg/apis\"\n)\n\n// +genclient\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\n// Configuration represents the \"floating HEAD\" of a linear history of Revisions,\n// and optionally how the containers those revisions reference are built.\n// Users create new Revisions by updating the Configuration's spec.\n// The \"latest created\" revision's name is available under status, as is the\n// \"latest ready\" revision's name.\n// See also: https://github.com/knative/serving/blob/master/docs/spec/overview.md#configuration\ntype Configuration struct {\n\tmetav1.TypeMeta `json:\",inline\"`\n\t// +optional\n\tmetav1.ObjectMeta `json:\"metadata,omitempty\"`\n\n\t// Spec holds the desired state of the Configuration (from the client).\n\t// +optional\n\tSpec ConfigurationSpec `json:\"spec,omitempty\"`\n\n\t// Status communicates the observed state of the Configuration (from the controller).\n\t// +optional\n\tStatus ConfigurationStatus `json:\"status,omitempty\"`\n}\n\n// Check that Configuration may be validated and defaulted.\nvar _ apis.Validatable = (*Configuration)(nil)\nvar _ apis.Defaultable = (*Configuration)(nil)\n\n// ConfigurationSpec holds the desired state of the Configuration (from the client).\ntype ConfigurationSpec struct {\n\t// TODO: Generation does not work correctly with CRD. They are scrubbed\n\t// by the APIserver (https://github.com/kubernetes/kubernetes/issues/58778)\n\t// So, we add Generation here. Once that gets fixed, remove this and use\n\t// ObjectMeta.Generation instead.\n\t// +optional\n\tGeneration int64 `json:\"generation,omitempty\"`\n\n\t// Build optionally holds the specification for the build to\n\t// perform to produce the Revision's container image.\n\t// +optional\n\tBuild *build.BuildSpec `json:\"build,omitempty\"`\n\n\t// RevisionTemplate holds the latest specification for the Revision to\n\t// be stamped out. If a Build specification is provided, then the\n\t// RevisionTemplate's BuildName field will be populated with the name of\n\t// the Build object created to produce the container for the Revision.\n\t// +optional\n\tRevisionTemplate RevisionTemplateSpec `json:\"revisionTemplate\"`\n}\n\n// ConfigurationConditionType is used to communicate the status of the reconciliation process.\n// See also: https://github.com/knative/serving/blob/master/docs/spec/errors.md#error-conditions-and-reporting\ntype ConfigurationConditionType string\n\nconst (\n\t// ConfigurationConditionReady is set when the configuration's latest\n\t// underlying revision has reported readiness.\n\tConfigurationConditionReady ConfigurationConditionType = \"Ready\"\n)\n\ntype ConfigurationConditionSlice []ConfigurationCondition\n\n// Len implements sort.Interface\nfunc (ccs ConfigurationConditionSlice) Len() int {\n\treturn len(ccs)\n}\n\n// Less implements sort.Interface\nfunc (ccs ConfigurationConditionSlice) Less(i, j int) bool {\n\treturn ccs[i].Type < ccs[j].Type\n}\n\n// Swap implements sort.Interface\nfunc (ccs ConfigurationConditionSlice) Swap(i, j int) {\n\tccs[i], ccs[j] = ccs[j], ccs[i]\n}\n\nvar _ sort.Interface = (ConfigurationConditionSlice)(nil)\n\n// ConfigurationCondition defines a readiness condition for a Configuration.\n// See: https://github.com/kubernetes/community/blob/master/contributors/devel/api-conventions.md#typical-status-properties\ntype ConfigurationCondition struct {\n\tType ConfigurationConditionType `json:\"type\" description:\"type of Configuration condition\"`\n\n\tStatus corev1.ConditionStatus `json:\"status\" description:\"status of the condition, one of True, False, Unknown\"`\n\n\t// +optional\n\t// We use VolatileTime in place of metav1.Time to exclude this from creating equality.Semantic\n\t// differences (all other things held constant).\n\tLastTransitionTime VolatileTime `json:\"lastTransitionTime,omitempty\" description:\"last time the condition transit from one status to another\"`\n\n\t// +optional\n\tReason string `json:\"reason,omitempty\" description:\"one-word CamelCase reason for the condition's last transition\"`\n\n\t// +optional\n\tMessage string `json:\"message,omitempty\" description:\"human-readable message indicating details about last transition\"`\n}\n\n// ConfigurationStatus communicates the observed state of the Configuration (from the controller).\ntype ConfigurationStatus struct {\n\t// Conditions communicates information about ongoing/complete\n\t// reconciliation processes that bring the \"spec\" inline with the observed\n\t// state of the world.\n\t// +optional\n\tConditions ConfigurationConditionSlice `json:\"conditions,omitempty\"`\n\n\t// LatestReadyRevisionName holds the name of the latest Revision stamped out\n\t// from this Configuration that has had its \"Ready\" condition become \"True\".\n\t// +optional\n\tLatestReadyRevisionName string `json:\"latestReadyRevisionName,omitempty\"`\n\n\t// LatestCreatedRevisionName is the last revision that was created from this\n\t// Configuration. It might not be ready yet, for that use LatestReadyRevisionName.\n\t// +optional\n\tLatestCreatedRevisionName string `json:\"latestCreatedRevisionName,omitempty\"`\n\n\t// ObservedGeneration is the 'Generation' of the Configuration that\n\t// was last processed by the controller. The observed generation is updated\n\t// even if the controller failed to process the spec and create the Revision.\n\t// +optional\n\tObservedGeneration int64 `json:\"observedGeneration,omitempty\"`\n}\n\n// +k8s:deepcopy-gen:interfaces=k8s.io/apimachinery/pkg/runtime.Object\n\n// ConfigurationList is a list of Configuration resources\ntype ConfigurationList struct {\n\tmetav1.TypeMeta `json:\",inline\"`\n\tmetav1.ListMeta `json:\"metadata\"`\n\n\tItems []Configuration `json:\"items\"`\n}\n\nfunc (r *Configuration) GetGeneration() int64 {\n\treturn r.Spec.Generation\n}\n\nfunc (r *Configuration) SetGeneration(generation int64) {\n\tr.Spec.Generation = generation\n}\n\nfunc (r *Configuration) GetSpecJSON() ([]byte, error) {\n\treturn json.Marshal(r.Spec)\n}\n\n// IsReady looks at the conditions on the ConfigurationStatus.\n// ConfigurationConditionReady returns true if ConditionStatus is True\nfunc (cs *ConfigurationStatus) IsReady() bool {\n\tif c := cs.GetCondition(ConfigurationConditionReady); c != nil {\n\t\treturn c.Status == corev1.ConditionTrue\n\t}\n\treturn false\n}\n\n// IsLatestReadyRevisionNameUpToDate returns true if the Configuration is ready\n// and LatestCreateRevisionName is equal to LatestReadyRevisionName. Otherwise\n// it returns false.\nfunc (cs *ConfigurationStatus) IsLatestReadyRevisionNameUpToDate() bool {\n\treturn cs.IsReady() &&\n\t\tcs.LatestCreatedRevisionName == cs.LatestReadyRevisionName\n}\n\nfunc (config *ConfigurationStatus) GetCondition(t ConfigurationConditionType) *ConfigurationCondition {\n\tfor _, cond := range config.Conditions {\n\t\tif cond.Type == t {\n\t\t\treturn &cond\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (cs *ConfigurationStatus) setCondition(new *ConfigurationCondition) {\n\tif new == nil {\n\t\treturn\n\t}\n\tt := new.Type\n\tvar conditions ConfigurationConditionSlice\n\tfor _, cond := range cs.Conditions {\n\t\tif cond.Type != t {\n\t\t\tconditions = append(conditions, cond)\n\t\t} else {\n\t\t\t// If we'd only update the LastTransitionTime, then return.\n\t\t\tnew.LastTransitionTime = cond.LastTransitionTime\n\t\t\tif reflect.DeepEqual(new, &cond) {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\tnew.LastTransitionTime = VolatileTime{metav1.NewTime(time.Now())}\n\tconditions = append(conditions, *new)\n\tsort.Sort(conditions)\n\tcs.Conditions = conditions\n}\n\nfunc (cs *ConfigurationStatus) InitializeConditions() {\n\tfor _, cond := range []ConfigurationConditionType{\n\t\tConfigurationConditionReady,\n\t} {\n\t\tif rc := cs.GetCondition(cond); rc == nil {\n\t\t\tcs.setCondition(&ConfigurationCondition{\n\t\t\t\tType:   cond,\n\t\t\t\tStatus: corev1.ConditionUnknown,\n\t\t\t})\n\t\t}\n\t}\n}\n\nfunc (cs *ConfigurationStatus) SetLatestCreatedRevisionName(name string) {\n\tcs.LatestCreatedRevisionName = name\n\tif cs.LatestReadyRevisionName != name {\n\t\tcs.setCondition(&ConfigurationCondition{\n\t\t\tType:   ConfigurationConditionReady,\n\t\t\tStatus: corev1.ConditionUnknown,\n\t\t})\n\t}\n}\n\nfunc (cs *ConfigurationStatus) SetLatestReadyRevisionName(name string) {\n\tcs.LatestReadyRevisionName = name\n\tfor _, cond := range []ConfigurationConditionType{\n\t\tConfigurationConditionReady,\n\t} {\n\t\tcs.setCondition(&ConfigurationCondition{\n\t\t\tType:   cond,\n\t\t\tStatus: corev1.ConditionTrue,\n\t\t})\n\t}\n}\n\nfunc (cs *ConfigurationStatus) MarkLatestCreatedFailed(name, message string) {\n\tcct := []ConfigurationConditionType{ConfigurationConditionReady}\n\tif cs.LatestReadyRevisionName == \"\" {\n\t\tcct = append(cct, ConfigurationConditionReady)\n\t}\n\tfor _, cond := range cct {\n\t\tcs.setCondition(&ConfigurationCondition{\n\t\t\tType:    cond,\n\t\t\tStatus:  corev1.ConditionFalse,\n\t\t\tReason:  \"RevisionFailed\",\n\t\t\tMessage: fmt.Sprintf(\"Revision %q failed with message: %q.\", name, message),\n\t\t})\n\t}\n}\n\nfunc (cs *ConfigurationStatus) MarkRevisionCreationFailed(message string) {\n\tcs.setCondition(&ConfigurationCondition{\n\t\tType:    ConfigurationConditionReady,\n\t\tStatus:  corev1.ConditionFalse,\n\t\tReason:  \"RevisionFailed\",\n\t\tMessage: fmt.Sprintf(\"Revision creation failed with message: %q.\", message),\n\t})\n}\n\nfunc (cs *ConfigurationStatus) MarkLatestReadyDeleted() {\n\tcct := []ConfigurationConditionType{ConfigurationConditionReady}\n\tfor _, cond := range cct {\n\t\tcs.setCondition(&ConfigurationCondition{\n\t\t\tType:    cond,\n\t\t\tStatus:  corev1.ConditionFalse,\n\t\t\tReason:  \"RevisionDeleted\",\n\t\t\tMessage: fmt.Sprintf(\"Revision %q was deleted.\", cs.LatestReadyRevisionName),\n\t\t})\n\t}\n\tcs.LatestReadyRevisionName = \"\"\n}\n"}
{"sample": "/***\nCopyright 2014 Cisco Systems Inc. All rights reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\nhttp://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage objdb\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"golang.org/x/net/context\"\n\n\tlog \"github.com/Sirupsen/logrus\"\n\t\"github.com/coreos/etcd/client\"\n)\n\n// Service state\ntype etcdServiceState struct {\n\tServiceName string        // Name of the service\n\tKeyName     string        // Service key name\n\tTTL         time.Duration // TTL for the service\n\tHostAddr    string        // Host name or IP address where its running\n\tPort        int           // Port number where its listening\n\tHostname    string        // Host name where its running\n\n\t// Channel to stop ttl refresh\n\tstopChan chan bool\n}\n\n// RegisterService Register a service\n// Service is registered with a ttl for 60sec and a goroutine is created\n// to refresh the ttl.\nfunc (ep *EtcdClient) RegisterService(serviceInfo ServiceInfo) error {\n\tkeyName := \"/contiv.io/service/\" + serviceInfo.ServiceName + \"/\" +\n\t\tserviceInfo.HostAddr + \":\" + strconv.Itoa(serviceInfo.Port)\n\tttl := time.Duration(serviceInfo.TTL) * time.Second\n\n\tlog.Infof(\"Registering service key: %s, value: %+v\", keyName, serviceInfo)\n\n\t// if there is a previously registered service, stop refreshing it\n\tif ep.serviceDb[keyName] != nil {\n\t\tep.serviceDb[keyName].stopChan <- true\n\t}\n\n\t// JSON format the object\n\tjsonVal, err := json.Marshal(serviceInfo)\n\tif err != nil {\n\t\tlog.Errorf(\"Json conversion error. Err %v\", err)\n\t\treturn err\n\t}\n\n\t// create service state\n\tsrvState := etcdServiceState{\n\t\tServiceName: serviceInfo.ServiceName,\n\t\tKeyName:     keyName,\n\t\tTTL:         ttl,\n\t\tHostAddr:    serviceInfo.HostAddr,\n\t\tPort:        serviceInfo.Port,\n\t\tstopChan:    make(chan bool, 1),\n\t\tHostname:    serviceInfo.Hostname,\n\t}\n\n\t// Run refresh in background\n\tgo ep.refreshService(&srvState, string(jsonVal[:]))\n\n\t// Store it in DB\n\tep.serviceDb[keyName] = &srvState\n\n\treturn nil\n}\n\n// GetService lists all end points for a service\nfunc (ep *EtcdClient) GetService(name string) ([]ServiceInfo, error) {\n\tkeyName := \"/contiv.io/service/\" + name + \"/\"\n\n\t_, srvcList, err := ep.getServiceState(keyName)\n\treturn srvcList, err\n}\n\nfunc (ep *EtcdClient) getServiceState(key string) (uint64, []ServiceInfo, error) {\n\tvar srvcList []ServiceInfo\n\tretryCount := 0\n\n\t// Get the object from etcd client\n\tresp, err := ep.kapi.Get(context.Background(), key, &client.GetOptions{Recursive: true, Sort: true})\n\tfor err != nil && err.Error() == client.ErrClusterUnavailable.Error() {\n\t\t// Retry after a delay\n\t\tretryCount++\n\t\tif retryCount%16 == 0 {\n\t\t\tlog.Warnf(\"%v -- Retrying...\", err)\n\t\t}\n\n\t\ttime.Sleep(time.Second)\n\t\tresp, err = ep.kapi.Get(context.Background(), key,\n\t\t\t&client.GetOptions{Recursive: true, Sort: true})\n\t}\n\n\tif err != nil {\n\t\tif strings.Contains(err.Error(), \"Key not found\") {\n\t\t\treturn 0, nil, nil\n\t\t}\n\n\t\tlog.Errorf(\"Error getting key %s. Err: %v\", key, err)\n\t\treturn 0, nil, err\n\t}\n\n\tif !resp.Node.Dir {\n\t\tlog.Errorf(\"Err. Response is not a directory: %+v\", resp.Node)\n\t\treturn 0, nil, errors.New(\"Invalid Response from etcd\")\n\t}\n\n\t// Parse each node in the directory\n\tfor _, node := range resp.Node.Nodes {\n\t\tvar respSrvc ServiceInfo\n\t\t// Parse JSON response\n\t\terr = json.Unmarshal([]byte(node.Value), &respSrvc)\n\t\tif err != nil {\n\t\t\tlog.Errorf(\"Error parsing object %s, Err %v\", node.Value, err)\n\t\t\treturn 0, nil, err\n\t\t}\n\n\t\tsrvcList = append(srvcList, respSrvc)\n\t}\n\n\twatchIndex := resp.Index\n\treturn watchIndex, srvcList, nil\n}\n\n// initServiceState reads the current state and injects it to the channel\n// additionally, it returns the next index to watch\nfunc (ep *EtcdClient) initServiceState(key string, eventCh chan WatchServiceEvent) (uint64, error) {\n\tmIndex, srvcList, err := ep.getServiceState(key)\n\tif err != nil {\n\t\treturn mIndex, err\n\t}\n\n\t// walk each service and inject it as an add event\n\tfor _, srvInfo := range srvcList {\n\t\tlog.Debugf(\"Sending service add event: %+v\", srvInfo)\n\t\t// Send Add event\n\t\teventCh <- WatchServiceEvent{\n\t\t\tEventType:   WatchServiceEventAdd,\n\t\t\tServiceInfo: srvInfo,\n\t\t}\n\t}\n\n\treturn mIndex, nil\n}\n\n// WatchService Watch for a service\nfunc (ep *EtcdClient) WatchService(name string, eventCh chan WatchServiceEvent, stopCh chan bool) error {\n\tkeyName := \"/contiv.io/service/\" + name + \"/\"\n\n\t// Create channels\n\twatchCh := make(chan *client.Response, 1)\n\n\t// Create watch context\n\twatchCtx, watchCancel := context.WithCancel(context.Background())\n\n\t// Start the watch thread\n\tgo func() {\n\t\t// Get current state and etcd index to watch\n\t\twatchIndex, err := ep.initServiceState(keyName, eventCh)\n\t\tif err != nil {\n\t\t\tlog.Fatalf(\"Unable to watch service key: %s - %v\", keyName,\n\t\t\t\terr)\n\t\t}\n\n\t\tlog.Infof(\"Watching for service: %s at index %v\", keyName, watchIndex)\n\t\t// Start the watch\n\t\twatcher := ep.kapi.Watcher(keyName, &client.WatcherOptions{AfterIndex: watchIndex, Recursive: true})\n\t\tif watcher == nil {\n\t\t\tlog.Errorf(\"Error watching service %s. Etcd returned invalid watcher\", keyName)\n\n\t\t\t// Emit the event\n\t\t\teventCh <- WatchServiceEvent{EventType: WatchServiceEventError}\n\t\t}\n\n\t\t// Keep getting next event\n\t\tfor {\n\t\t\t// Block till next watch event\n\t\t\tetcdRsp, err := watcher.Next(watchCtx)\n\t\t\tif err != nil && err.Error() == client.ErrClusterUnavailable.Error() {\n\t\t\t\tlog.Infof(\"Stopping watch on key %s\", keyName)\n\t\t\t\treturn\n\t\t\t} else if err != nil {\n\t\t\t\tlog.Errorf(\"Error %v during watch. Watch thread exiting\", err)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Send it to watch channel\n\t\t\twatchCh <- etcdRsp\n\t\t}\n\t}()\n\n\t// handle messages from watch service\n\tgo func() {\n\t\tvar srvMap = make(map[string]ServiceInfo)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase watchResp := <-watchCh:\n\t\t\t\tvar srvInfo ServiceInfo\n\n\t\t\t\tlog.Debugf(\"Received event {%#v}\\n Node: {%#v}\\n PrevNade: {%#v}\", watchResp, watchResp.Node, watchResp.PrevNode)\n\n\t\t\t\t// derive service info from key\n\t\t\t\tsrvKey := strings.TrimPrefix(watchResp.Node.Key, \"/contiv.io/service/\")\n\n\t\t\t\t// We ignore all events except Set/Delete/Expire\n\t\t\t\t// Note that Set event doesnt exactly mean new service end point.\n\t\t\t\t// If a service restarts and re-registers before it expired, we'll\n\t\t\t\t// receive set again. receivers need to handle this case\n\t\t\t\tif _, ok := srvMap[srvKey]; !ok && watchResp.Action == \"set\" {\n\t\t\t\t\t// Parse JSON response\n\t\t\t\t\terr := json.Unmarshal([]byte(watchResp.Node.Value), &srvInfo)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Errorf(\"Error parsing object %s, Err %v\", watchResp.Node.Value, err)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\tlog.Infof(\"Sending service add event: %+v\", srvInfo)\n\t\t\t\t\t// Send Add event\n\t\t\t\t\teventCh <- WatchServiceEvent{\n\t\t\t\t\t\tEventType:   WatchServiceEventAdd,\n\t\t\t\t\t\tServiceInfo: srvInfo,\n\t\t\t\t\t}\n\n\t\t\t\t\t// save it in cache\n\t\t\t\t\tsrvMap[srvKey] = srvInfo\n\t\t\t\t} else if (watchResp.Action == \"delete\") || (watchResp.Action == \"expire\") {\n\t\t\t\t\t// Parse JSON response\n\t\t\t\t\terr := json.Unmarshal([]byte(watchResp.PrevNode.Value), &srvInfo)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Errorf(\"Error parsing object %s, Err %v\", watchResp.Node.Value, err)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\n\t\t\t\t\tlog.Infof(\"Sending service del event: %+v\", srvInfo)\n\n\t\t\t\t\t// Send Delete event\n\t\t\t\t\teventCh <- WatchServiceEvent{\n\t\t\t\t\t\tEventType:   WatchServiceEventDel,\n\t\t\t\t\t\tServiceInfo: srvInfo,\n\t\t\t\t\t}\n\n\t\t\t\t\t// remove it from cache\n\t\t\t\t\tdelete(srvMap, srvKey)\n\t\t\t\t}\n\t\t\tcase stopReq := <-stopCh:\n\t\t\t\tif stopReq {\n\t\t\t\t\t// Stop watch and return\n\t\t\t\t\tlog.Infof(\"Stopping watch on %s\", keyName)\n\t\t\t\t\twatchCancel()\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}()\n\n\treturn nil\n}\n\n// DeregisterService Deregister a service\n// This removes the service from the registry and stops the refresh groutine\nfunc (ep *EtcdClient) DeregisterService(serviceInfo ServiceInfo) error {\n\tkeyName := \"/contiv.io/service/\" + serviceInfo.ServiceName + \"/\" +\n\t\tserviceInfo.HostAddr + \":\" + strconv.Itoa(serviceInfo.Port)\n\n\t// Find it in the database\n\tsrvState := ep.serviceDb[keyName]\n\tif srvState == nil {\n\t\tlog.Errorf(\"Could not find the service in db %s\", keyName)\n\t\treturn errors.New(\"Service not found\")\n\t}\n\n\t// stop the refresh thread and delete service\n\tsrvState.stopChan <- true\n\tdelete(ep.serviceDb, keyName)\n\n\t// Delete the service instance\n\t_, err := ep.kapi.Delete(context.Background(), keyName, nil)\n\tif err != nil {\n\t\tlog.Errorf(\"Error deleting key %s. Err: %v\", keyName, err)\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// Keep refreshing the service every 30sec\nfunc (ep *EtcdClient) refreshService(srvState *etcdServiceState, keyVal string) {\n\t// Set it via etcd client\n\t_, err := ep.kapi.Set(context.Background(), srvState.KeyName, keyVal, &client.SetOptions{TTL: srvState.TTL})\n\tif err != nil {\n\t\tlog.Errorf(\"Error setting key %s, Err: %v\", srvState.KeyName, err)\n\t}\n\n\t// Loop forever\n\tfor {\n\t\tselect {\n\t\tcase <-time.After(srvState.TTL / 3):\n\t\t\tlog.Debugf(\"Refreshing key: %s\", srvState.KeyName)\n\n\t\t\t_, err := ep.kapi.Set(context.Background(), srvState.KeyName, keyVal, &client.SetOptions{TTL: srvState.TTL})\n\t\t\tif err != nil {\n\t\t\t\tlog.Errorf(\"Error setting key %s, Err: %v\", srvState.KeyName, err)\n\t\t\t}\n\n\t\tcase <-srvState.stopChan:\n\t\t\tlog.Infof(\"Stop refreshing key: %s\", srvState.KeyName)\n\t\t\treturn\n\t\t}\n\t}\n}\n"}
{"sample": "package leap\n\nimport (\n\t\"errors\"\n\t\"io\"\n\t\"io/ioutil\"\n\t\"testing\"\n\n\t\"github.com/hybridgroup/gobot\"\n)\n\ntype NullReadWriteCloser struct{}\n\nvar writeError error = nil\n\nfunc (NullReadWriteCloser) Write(p []byte) (int, error) {\n\treturn len(p), writeError\n}\nfunc (NullReadWriteCloser) Read(b []byte) (int, error) {\n\treturn len(b), nil\n}\nfunc (NullReadWriteCloser) Close() error {\n\treturn nil\n}\n\nfunc initTestLeapMotionDriver() *LeapMotionDriver {\n\ta := NewLeapMotionAdaptor(\"bot\", \"\")\n\ta.connect = func(port string) (io.ReadWriteCloser, error) {\n\t\treturn &NullReadWriteCloser{}, nil\n\t}\n\ta.Connect()\n\treceive = func(ws io.ReadWriteCloser, buf *[]byte) {\n\t\tfile, _ := ioutil.ReadFile(\"./test/support/example_frame.json\")\n\t\tcopy(*buf, file)\n\t}\n\treturn NewLeapMotionDriver(a, \"bot\")\n}\n\nfunc TestLeapMotionDriver(t *testing.T) {\n\td := initTestLeapMotionDriver()\n\tgobot.Assert(t, d.Name(), \"bot\")\n\tgobot.Assert(t, d.Connection().Name(), \"bot\")\n}\nfunc TestLeapMotionDriverStart(t *testing.T) {\n\td := initTestLeapMotionDriver()\n\tgobot.Assert(t, len(d.Start()), 0)\n\n\td = initTestLeapMotionDriver()\n\twriteError = errors.New(\"write error\")\n\tgobot.Assert(t, d.Start()[0], errors.New(\"write error\"))\n\n}\n\nfunc TestLeapMotionDriverHalt(t *testing.T) {\n\td := initTestLeapMotionDriver()\n\tgobot.Assert(t, len(d.Halt()), 0)\n}\n\nfunc TestLeapMotionDriverParser(t *testing.T) {\n\td := initTestLeapMotionDriver()\n\tfile, _ := ioutil.ReadFile(\"./test/support/example_frame.json\")\n\tparsedFrame := d.ParseFrame(file)\n\n\tif parsedFrame.Hands == nil || parsedFrame.Pointables == nil || parsedFrame.Gestures == nil {\n\t\tt.Errorf(\"ParseFrame incorrectly parsed frame\")\n\t}\n\n\tgobot.Assert(t, parsedFrame.Timestamp, 4729292670)\n\tgobot.Assert(t, parsedFrame.Hands[0].X(), 117.546)\n\tgobot.Assert(t, parsedFrame.Hands[0].Y(), 236.007)\n\tgobot.Assert(t, parsedFrame.Hands[0].Z(), 76.3394)\n}\n"}
{"sample": "package database\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"github.com/aaronland/go-roster\"\n\t\"github.com/whosonfirst/go-reader\"\n\t\"github.com/whosonfirst/go-whosonfirst-spatial\"\n\t\"github.com/whosonfirst/go-writer\"\n\t\"net/url\"\n\t\"sort\"\n\t\"strings\"\n)\n\ntype SpatialDatabase interface {\n\treader.Reader\n\twriter.Writer\n\tspatial.SpatialIndex\n}\n\ntype SpatialDatabaseInitializeFunc func(ctx context.Context, uri string) (SpatialDatabase, error)\n\nvar spatial_databases roster.Roster\n\nfunc ensureSpatialRoster() error {\n\n\tif spatial_databases == nil {\n\n\t\tr, err := roster.NewDefaultRoster()\n\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tspatial_databases = r\n\t}\n\n\treturn nil\n}\n\nfunc RegisterSpatialDatabase(ctx context.Context, scheme string, f SpatialDatabaseInitializeFunc) error {\n\n\terr := ensureSpatialRoster()\n\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn spatial_databases.Register(ctx, scheme, f)\n}\n\nfunc Schemes() []string {\n\n\tctx := context.Background()\n\tschemes := []string{}\n\n\terr := ensureSpatialRoster()\n\n\tif err != nil {\n\t\treturn schemes\n\t}\n\n\tfor _, dr := range spatial_databases.Drivers(ctx) {\n\t\tscheme := fmt.Sprintf(\"%s://\", strings.ToLower(dr))\n\t\tschemes = append(schemes, scheme)\n\t}\n\n\tsort.Strings(schemes)\n\treturn schemes\n}\n\nfunc NewSpatialDatabase(ctx context.Context, uri string) (SpatialDatabase, error) {\n\n\tu, err := url.Parse(uri)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tscheme := u.Scheme\n\n\ti, err := spatial_databases.Driver(ctx, scheme)\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tf := i.(SpatialDatabaseInitializeFunc)\n\treturn f(ctx, uri)\n}\n"}
{"sample": "// Generated by github.com/temporalio/temporal-aws-sdk-generator\n// from github.com/aws/aws-sdk-go version 1.35.7\n\npackage route53resolverstub\n\nimport (\n\t\"github.com/aws/aws-sdk-go/service/route53resolver\"\n\t\"go.uber.org/cadence/workflow\"\n\n\t\"github.com/banzaicloud/cadence-aws-sdk/clients\"\n)\n\n// ensure that imports are valid even if not used by the generated code\nvar _ clients.VoidFuture\n\ntype Client interface {\n\tAssociateResolverEndpointIpAddress(ctx workflow.Context, input *route53resolver.AssociateResolverEndpointIpAddressInput) (*route53resolver.AssociateResolverEndpointIpAddressOutput, error)\n\tAssociateResolverEndpointIpAddressAsync(ctx workflow.Context, input *route53resolver.AssociateResolverEndpointIpAddressInput) *AssociateResolverEndpointIpAddressFuture\n\n\tAssociateResolverQueryLogConfig(ctx workflow.Context, input *route53resolver.AssociateResolverQueryLogConfigInput) (*route53resolver.AssociateResolverQueryLogConfigOutput, error)\n\tAssociateResolverQueryLogConfigAsync(ctx workflow.Context, input *route53resolver.AssociateResolverQueryLogConfigInput) *AssociateResolverQueryLogConfigFuture\n\n\tAssociateResolverRule(ctx workflow.Context, input *route53resolver.AssociateResolverRuleInput) (*route53resolver.AssociateResolverRuleOutput, error)\n\tAssociateResolverRuleAsync(ctx workflow.Context, input *route53resolver.AssociateResolverRuleInput) *AssociateResolverRuleFuture\n\n\tCreateResolverEndpoint(ctx workflow.Context, input *route53resolver.CreateResolverEndpointInput) (*route53resolver.CreateResolverEndpointOutput, error)\n\tCreateResolverEndpointAsync(ctx workflow.Context, input *route53resolver.CreateResolverEndpointInput) *CreateResolverEndpointFuture\n\n\tCreateResolverQueryLogConfig(ctx workflow.Context, input *route53resolver.CreateResolverQueryLogConfigInput) (*route53resolver.CreateResolverQueryLogConfigOutput, error)\n\tCreateResolverQueryLogConfigAsync(ctx workflow.Context, input *route53resolver.CreateResolverQueryLogConfigInput) *CreateResolverQueryLogConfigFuture\n\n\tCreateResolverRule(ctx workflow.Context, input *route53resolver.CreateResolverRuleInput) (*route53resolver.CreateResolverRuleOutput, error)\n\tCreateResolverRuleAsync(ctx workflow.Context, input *route53resolver.CreateResolverRuleInput) *CreateResolverRuleFuture\n\n\tDeleteResolverEndpoint(ctx workflow.Context, input *route53resolver.DeleteResolverEndpointInput) (*route53resolver.DeleteResolverEndpointOutput, error)\n\tDeleteResolverEndpointAsync(ctx workflow.Context, input *route53resolver.DeleteResolverEndpointInput) *DeleteResolverEndpointFuture\n\n\tDeleteResolverQueryLogConfig(ctx workflow.Context, input *route53resolver.DeleteResolverQueryLogConfigInput) (*route53resolver.DeleteResolverQueryLogConfigOutput, error)\n\tDeleteResolverQueryLogConfigAsync(ctx workflow.Context, input *route53resolver.DeleteResolverQueryLogConfigInput) *DeleteResolverQueryLogConfigFuture\n\n\tDeleteResolverRule(ctx workflow.Context, input *route53resolver.DeleteResolverRuleInput) (*route53resolver.DeleteResolverRuleOutput, error)\n\tDeleteResolverRuleAsync(ctx workflow.Context, input *route53resolver.DeleteResolverRuleInput) *DeleteResolverRuleFuture\n\n\tDisassociateResolverEndpointIpAddress(ctx workflow.Context, input *route53resolver.DisassociateResolverEndpointIpAddressInput) (*route53resolver.DisassociateResolverEndpointIpAddressOutput, error)\n\tDisassociateResolverEndpointIpAddressAsync(ctx workflow.Context, input *route53resolver.DisassociateResolverEndpointIpAddressInput) *DisassociateResolverEndpointIpAddressFuture\n\n\tDisassociateResolverQueryLogConfig(ctx workflow.Context, input *route53resolver.DisassociateResolverQueryLogConfigInput) (*route53resolver.DisassociateResolverQueryLogConfigOutput, error)\n\tDisassociateResolverQueryLogConfigAsync(ctx workflow.Context, input *route53resolver.DisassociateResolverQueryLogConfigInput) *DisassociateResolverQueryLogConfigFuture\n\n\tDisassociateResolverRule(ctx workflow.Context, input *route53resolver.DisassociateResolverRuleInput) (*route53resolver.DisassociateResolverRuleOutput, error)\n\tDisassociateResolverRuleAsync(ctx workflow.Context, input *route53resolver.DisassociateResolverRuleInput) *DisassociateResolverRuleFuture\n\n\tGetResolverDnssecConfig(ctx workflow.Context, input *route53resolver.GetResolverDnssecConfigInput) (*route53resolver.GetResolverDnssecConfigOutput, error)\n\tGetResolverDnssecConfigAsync(ctx workflow.Context, input *route53resolver.GetResolverDnssecConfigInput) *GetResolverDnssecConfigFuture\n\n\tGetResolverEndpoint(ctx workflow.Context, input *route53resolver.GetResolverEndpointInput) (*route53resolver.GetResolverEndpointOutput, error)\n\tGetResolverEndpointAsync(ctx workflow.Context, input *route53resolver.GetResolverEndpointInput) *GetResolverEndpointFuture\n\n\tGetResolverQueryLogConfig(ctx workflow.Context, input *route53resolver.GetResolverQueryLogConfigInput) (*route53resolver.GetResolverQueryLogConfigOutput, error)\n\tGetResolverQueryLogConfigAsync(ctx workflow.Context, input *route53resolver.GetResolverQueryLogConfigInput) *GetResolverQueryLogConfigFuture\n\n\tGetResolverQueryLogConfigAssociation(ctx workflow.Context, input *route53resolver.GetResolverQueryLogConfigAssociationInput) (*route53resolver.GetResolverQueryLogConfigAssociationOutput, error)\n\tGetResolverQueryLogConfigAssociationAsync(ctx workflow.Context, input *route53resolver.GetResolverQueryLogConfigAssociationInput) *GetResolverQueryLogConfigAssociationFuture\n\n\tGetResolverQueryLogConfigPolicy(ctx workflow.Context, input *route53resolver.GetResolverQueryLogConfigPolicyInput) (*route53resolver.GetResolverQueryLogConfigPolicyOutput, error)\n\tGetResolverQueryLogConfigPolicyAsync(ctx workflow.Context, input *route53resolver.GetResolverQueryLogConfigPolicyInput) *GetResolverQueryLogConfigPolicyFuture\n\n\tGetResolverRule(ctx workflow.Context, input *route53resolver.GetResolverRuleInput) (*route53resolver.GetResolverRuleOutput, error)\n\tGetResolverRuleAsync(ctx workflow.Context, input *route53resolver.GetResolverRuleInput) *GetResolverRuleFuture\n\n\tGetResolverRuleAssociation(ctx workflow.Context, input *route53resolver.GetResolverRuleAssociationInput) (*route53resolver.GetResolverRuleAssociationOutput, error)\n\tGetResolverRuleAssociationAsync(ctx workflow.Context, input *route53resolver.GetResolverRuleAssociationInput) *GetResolverRuleAssociationFuture\n\n\tGetResolverRulePolicy(ctx workflow.Context, input *route53resolver.GetResolverRulePolicyInput) (*route53resolver.GetResolverRulePolicyOutput, error)\n\tGetResolverRulePolicyAsync(ctx workflow.Context, input *route53resolver.GetResolverRulePolicyInput) *GetResolverRulePolicyFuture\n\n\tListResolverDnssecConfigs(ctx workflow.Context, input *route53resolver.ListResolverDnssecConfigsInput) (*route53resolver.ListResolverDnssecConfigsOutput, error)\n\tListResolverDnssecConfigsAsync(ctx workflow.Context, input *route53resolver.ListResolverDnssecConfigsInput) *ListResolverDnssecConfigsFuture\n\n\tListResolverEndpointIpAddresses(ctx workflow.Context, input *route53resolver.ListResolverEndpointIpAddressesInput) (*route53resolver.ListResolverEndpointIpAddressesOutput, error)\n\tListResolverEndpointIpAddressesAsync(ctx workflow.Context, input *route53resolver.ListResolverEndpointIpAddressesInput) *ListResolverEndpointIpAddressesFuture\n\n\tListResolverEndpoints(ctx workflow.Context, input *route53resolver.ListResolverEndpointsInput) (*route53resolver.ListResolverEndpointsOutput, error)\n\tListResolverEndpointsAsync(ctx workflow.Context, input *route53resolver.ListResolverEndpointsInput) *ListResolverEndpointsFuture\n\n\tListResolverQueryLogConfigAssociations(ctx workflow.Context, input *route53resolver.ListResolverQueryLogConfigAssociationsInput) (*route53resolver.ListResolverQueryLogConfigAssociationsOutput, error)\n\tListResolverQueryLogConfigAssociationsAsync(ctx workflow.Context, input *route53resolver.ListResolverQueryLogConfigAssociationsInput) *ListResolverQueryLogConfigAssociationsFuture\n\n\tListResolverQueryLogConfigs(ctx workflow.Context, input *route53resolver.ListResolverQueryLogConfigsInput) (*route53resolver.ListResolverQueryLogConfigsOutput, error)\n\tListResolverQueryLogConfigsAsync(ctx workflow.Context, input *route53resolver.ListResolverQueryLogConfigsInput) *ListResolverQueryLogConfigsFuture\n\n\tListResolverRuleAssociations(ctx workflow.Context, input *route53resolver.ListResolverRuleAssociationsInput) (*route53resolver.ListResolverRuleAssociationsOutput, error)\n\tListResolverRuleAssociationsAsync(ctx workflow.Context, input *route53resolver.ListResolverRuleAssociationsInput) *ListResolverRuleAssociationsFuture\n\n\tListResolverRules(ctx workflow.Context, input *route53resolver.ListResolverRulesInput) (*route53resolver.ListResolverRulesOutput, error)\n\tListResolverRulesAsync(ctx workflow.Context, input *route53resolver.ListResolverRulesInput) *ListResolverRulesFuture\n\n\tListTagsForResource(ctx workflow.Context, input *route53resolver.ListTagsForResourceInput) (*route53resolver.ListTagsForResourceOutput, error)\n\tListTagsForResourceAsync(ctx workflow.Context, input *route53resolver.ListTagsForResourceInput) *ListTagsForResourceFuture\n\n\tPutResolverQueryLogConfigPolicy(ctx workflow.Context, input *route53resolver.PutResolverQueryLogConfigPolicyInput) (*route53resolver.PutResolverQueryLogConfigPolicyOutput, error)\n\tPutResolverQueryLogConfigPolicyAsync(ctx workflow.Context, input *route53resolver.PutResolverQueryLogConfigPolicyInput) *PutResolverQueryLogConfigPolicyFuture\n\n\tPutResolverRulePolicy(ctx workflow.Context, input *route53resolver.PutResolverRulePolicyInput) (*route53resolver.PutResolverRulePolicyOutput, error)\n\tPutResolverRulePolicyAsync(ctx workflow.Context, input *route53resolver.PutResolverRulePolicyInput) *PutResolverRulePolicyFuture\n\n\tTagResource(ctx workflow.Context, input *route53resolver.TagResourceInput) (*route53resolver.TagResourceOutput, error)\n\tTagResourceAsync(ctx workflow.Context, input *route53resolver.TagResourceInput) *TagResourceFuture\n\n\tUntagResource(ctx workflow.Context, input *route53resolver.UntagResourceInput) (*route53resolver.UntagResourceOutput, error)\n\tUntagResourceAsync(ctx workflow.Context, input *route53resolver.UntagResourceInput) *UntagResourceFuture\n\n\tUpdateResolverDnssecConfig(ctx workflow.Context, input *route53resolver.UpdateResolverDnssecConfigInput) (*route53resolver.UpdateResolverDnssecConfigOutput, error)\n\tUpdateResolverDnssecConfigAsync(ctx workflow.Context, input *route53resolver.UpdateResolverDnssecConfigInput) *UpdateResolverDnssecConfigFuture\n\n\tUpdateResolverEndpoint(ctx workflow.Context, input *route53resolver.UpdateResolverEndpointInput) (*route53resolver.UpdateResolverEndpointOutput, error)\n\tUpdateResolverEndpointAsync(ctx workflow.Context, input *route53resolver.UpdateResolverEndpointInput) *UpdateResolverEndpointFuture\n\n\tUpdateResolverRule(ctx workflow.Context, input *route53resolver.UpdateResolverRuleInput) (*route53resolver.UpdateResolverRuleOutput, error)\n\tUpdateResolverRuleAsync(ctx workflow.Context, input *route53resolver.UpdateResolverRuleInput) *UpdateResolverRuleFuture\n}\n\nfunc NewClient() Client {\n\treturn &stub{}\n}\n"}
{"sample": "package main\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/theskch/binary-chop/common\"\n\t\"github.com/theskch/binary-chop/concurent\"\n\t\"github.com/theskch/binary-chop/loop\"\n\t\"github.com/theskch/binary-chop/recursive\"\n\n\t\"github.com/jedib0t/go-pretty/v6/table\"\n)\n\nfunc main() {\n\tskip := map[int]bool{4: true, 11: true}\n\tarray := common.GenerateRandomArray(10, skip)\n\n\tbenchmark(\"Test case 1: array of 10 elements, element present in array\", array[5], array)\n\tfmt.Println()\n\tbenchmark(\"Test case 2: array of 10 elements, element not present in array\", 4, array)\n\n\tskip = map[int]bool{980: true, 112: true, 1504: true}\n\tarray = common.GenerateRandomArray(1000, skip)\n\tfmt.Println()\n\tbenchmark(\"Test case 3: array of 1000 elements, element not present in array\", array[867], array)\n\tfmt.Println()\n\tbenchmark(\"Test case 4: array of 1000 elements, element not present in array\", 1504, array)\n\n\tskip = map[int]bool{8: true, 99000: true, 45890: true}\n\tarray = common.GenerateRandomArray(100000, skip)\n\tfmt.Println()\n\tbenchmark(\"Test case 5: array of 100000 elements, element not present in array\", array[57020], array)\n\tfmt.Println()\n\tbenchmark(\"Test case 6: array of 100000 elements, element not present in array\", 99000, array)\n\n\tskip = map[int]bool{68: true, 789503: true, 678004: true}\n\tarray = common.GenerateRandomArray(10000000, skip)\n\tfmt.Println()\n\tbenchmark(\"Test case 7: array of 10000000 elements, element not present in array\", array[587], array)\n\tfmt.Println()\n\tbenchmark(\"Test case 8: array of 10000000 elements, element not present in array\", 68, array)\n}\n\nfunc executeAndTrack(searcher common.BinarySearcher, num int, testSet []int) (time.Duration, int) {\n\tstart := time.Now()\n\tindex, _ := searcher.Search(num, testSet)\n\telapsed := time.Since(start)\n\treturn elapsed, index\n}\n\nfunc benchmark(name string, num int, array []int) {\n\tgbbs := concurent.GreedyBoundsBinarySearcher{}\n\tlbbs := loop.BoundsBinarySearcher{}\n\tlcbs := loop.ChopBinarySearcher{}\n\trbbs := recursive.BoundsBinarySearcher{}\n\trcbs := recursive.ChopBinarySearcher{}\n\n\tt := table.NewWriter()\n\tt.SetOutputMirror(os.Stdout)\n\tt.SetTitle(name)\n\tt.SetAllowedRowLength(500)\n\tt.AppendHeader(table.Row{\"#\", \"Name\t\t\t\", \"Index\t\t\t\", \"Execution Time\t\t\t\"})\n\n\tduration, index := executeAndTrack(gbbs, num, array)\n\tt.AppendRow(table.Row{\"1\", \"Greedy Bounds\", index, duration})\n\tt.AppendSeparator()\n\n\tduration, index = executeAndTrack(lbbs, num, array)\n\tt.AppendRow(table.Row{\"2\", \"Loop Bounds\", index, duration})\n\tt.AppendSeparator()\n\n\tduration, index = executeAndTrack(lcbs, num, array)\n\tt.AppendRow(table.Row{\"3\", \"Loop Chop\", index, duration})\n\tt.AppendSeparator()\n\n\tduration, index = executeAndTrack(rbbs, num, array)\n\tt.AppendRow(table.Row{\"4\", \"Recursive Bounds\", index, duration})\n\tt.AppendSeparator()\n\n\tduration, index = executeAndTrack(rcbs, num, array)\n\tt.AppendRow(table.Row{\"5\", \"Recursive Chop\", index, duration})\n\tt.AppendSeparator()\n\tt.Render()\n}\n"}
{"sample": "// Package bech32 implements bech32 encoding and decoding.\npackage bech32\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/iotaledger/iota.go/v2/bech32/internal/base32\"\n)\n\nconst (\n\tmaxStringLength = 90\n\tchecksumLength  = 6\n\tseparator       = '1'\n)\n\nvar charset = newEncoding(\"qpzry9x8gf2tvdw0s3jn54khce6mua7l\")\n\n// Encode encodes the String string and the src data as a Bech32 string.\n// It returns an error when the input is invalid.\nfunc Encode(hrp string, src []byte) (string, error) {\n\tdataLen := base32.EncodedLen(len(src))\n\tif len(hrp)+dataLen+checksumLength+1 > maxStringLength {\n\t\treturn \"\", fmt.Errorf(\"%w: String length=%d, data length=%d\", ErrInvalidLength, len(hrp), dataLen)\n\t}\n\t// validate the human-readable part\n\tif len(hrp) < 1 {\n\t\treturn \"\", fmt.Errorf(\"%w: String must not be empty\", ErrInvalidLength)\n\t}\n\tfor _, c := range hrp {\n\t\tif !isValidHRPChar(c) {\n\t\t\treturn \"\", fmt.Errorf(\"%w: not US-ASCII character in human-readable part\", ErrInvalidCharacter)\n\t\t}\n\t}\n\tif err := validateCase(hrp); err != nil {\n\t\treturn \"\", err\n\t}\n\n\t// convert the human-readable part to lower for the checksum\n\thrpLower := strings.ToLower(hrp)\n\n\t// convert to base32 and add the checksum\n\tdata := make([]uint8, base32.EncodedLen(len(src))+checksumLength)\n\tbase32.Encode(data, src)\n\tcopy(data[dataLen:], bech32CreateChecksum(hrpLower, data[:dataLen]))\n\n\t// enc the data part using the charset\n\tchars := charset.encode(data)\n\n\t// convert to a string using the corresponding charset\n\tvar res strings.Builder\n\tres.WriteString(hrp)\n\tres.WriteByte(separator)\n\tres.WriteString(chars)\n\n\t// return with the correct case\n\tif hrp == hrpLower {\n\t\treturn res.String(), nil\n\t}\n\treturn strings.ToUpper(res.String()), nil\n}\n\n// Decode decodes the Bech32 string s into its human-readable and data part.\n// It returns an error when s does not represent a valid Bech32 encoding.\n// An SyntaxError is returned when the error can be matched to a certain position in s.\nfunc Decode(s string) (string, []byte, error) {\n\tif len(s) > maxStringLength {\n\t\treturn \"\", nil, &SyntaxError{fmt.Errorf(\"%w: maximum length exceeded\", ErrInvalidLength), maxStringLength}\n\t}\n\t// validate the separator\n\thrpLen := strings.LastIndex(s, string(separator))\n\tif hrpLen == -1 {\n\t\treturn \"\", nil, ErrMissingSeparator\n\t}\n\tif hrpLen < 1 || hrpLen+checksumLength > len(s) {\n\t\treturn \"\", nil, &SyntaxError{fmt.Errorf(\"%w: invalid position\", ErrInvalidSeparator), hrpLen}\n\t}\n\t// validate characters in human-readable part\n\tfor i, c := range s[:hrpLen] {\n\t\tif !isValidHRPChar(c) {\n\t\t\treturn \"\", nil, &SyntaxError{fmt.Errorf(\"%w: not US-ASCII character in human-readable part\", ErrInvalidCharacter), i}\n\t\t}\n\t}\n\t// validate that the case of the entire string is consistent\n\tif err := validateCase(s); err != nil {\n\t\treturn \"\", nil, err\n\t}\n\n\t// convert everything to lower\n\ts = strings.ToLower(s)\n\thrp := s[:hrpLen]\n\tchars := s[hrpLen+1:]\n\n\t// decode the data part\n\tdata, err := charset.decode(chars)\n\tif err != nil {\n\t\treturn \"\", nil, &SyntaxError{fmt.Errorf(\"%w: non-charset character in data part\", ErrInvalidCharacter), hrpLen + 1 + len(data)}\n\t}\n\n\t// validate the checksum\n\tif len(data) < checksumLength || !bech32VerifyChecksum(hrp, data) {\n\t\treturn \"\", nil, &SyntaxError{ErrInvalidChecksum, len(s) - checksumLength}\n\t}\n\tdata = data[:len(data)-checksumLength]\n\n\t// decode the data part\n\tdst := make([]byte, base32.DecodedLen(len(data)))\n\tif _, err := base32.Decode(dst, data); err != nil {\n\t\tvar e *base32.CorruptInputError\n\t\tif errors.As(err, &e) {\n\t\t\treturn \"\", nil, &SyntaxError{e.Unwrap(), hrpLen + 1 + e.Offset}\n\t\t}\n\t\treturn \"\", nil, err\n\t}\n\treturn hrp, dst, nil\n}\n\nfunc isValidHRPChar(r rune) bool {\n\t// it must only contain US-ASCII characters, with each character having a value in the range [33-126]\n\treturn r >= 33 && r <= 126\n}\n\nfunc validateCase(s string) error {\n\tupper, lower := firstUpper(s), firstLower(s)\n\tif upper < lower && upper >= 0 {\n\t\treturn &SyntaxError{ErrMixedCase, lower}\n\t}\n\tif lower < upper && lower >= 0 {\n\t\treturn &SyntaxError{ErrMixedCase, upper}\n\t}\n\treturn nil\n}\n\nfunc firstUpper(s string) int {\n\tlower := strings.ToLower(s)\n\tfor i := range s {\n\t\tif lower[i] != s[i] {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn -1\n}\n\nfunc firstLower(s string) int {\n\tlower := strings.ToUpper(s)\n\tfor i := range s {\n\t\tif lower[i] != s[i] {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn -1\n}\n"}
{"sample": "package buildnum\n\nimport (\n\t\"errors\"\n\t\"net/http\"\n\t\"net/http/httptest\"\n\t\"testing\"\n\n\t\"github.com/jenkins-x/jx/pkg/buildnum/mocks/matchers\"\n\t\"github.com/jenkins-x/jx/pkg/kube\"\n\t. \"github.com/petergtz/pegomock\"\n\n\tbuild_num_test \"github.com/jenkins-x/jx/pkg/buildnum/mocks\"\n\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestVendGET(t *testing.T) {\n\tmockIssuer := build_num_test.NewMockBuildNumberIssuer()\n\tpID := kube.NewPipelineIDFromString(\"owner1/repo1/branch1\")\n\texpectedBuildNum := \"3\"\n\tWhen(mockIssuer.NextBuildNumber(matchers.EqKubePipelineID(pID))).ThenReturn(expectedBuildNum, nil)\n\n\trespRecord := makeVendRequest(t, http.MethodGet, \"/vend/owner1/repo1/branch1\", mockIssuer)\n\tassert.Equal(t, http.StatusOK, respRecord.Code,\n\t\t\"Expected OK status code for valid /vend GET request.\")\n\tbody := respRecord.Body.String()\n\tassert.Equal(t, expectedBuildNum, body)\n}\n\nfunc TestVendGETMissingPipeline(t *testing.T) {\n\tmockIssuer := build_num_test.NewMockBuildNumberIssuer()\n\tpID := kube.NewPipelineIDFromString(\"\")\n\texpectedBuildNum := \"543\"\n\tWhen(mockIssuer.NextBuildNumber(matchers.EqKubePipelineID(pID))).ThenReturn(expectedBuildNum, nil)\n\n\trespRecord := makeVendRequest(t, http.MethodGet, \"/vend/\", mockIssuer)\n\tassert.Equal(t, http.StatusBadRequest, respRecord.Code,\n\t\t\"Expected Bad Request for /vend GET request with missing pipeline.\")\n}\n\nfunc TestVendUnsupportedMethod(t *testing.T) {\n\tmockIssuer := build_num_test.NewMockBuildNumberIssuer()\n\n\trespRecord := makeVendRequest(t, http.MethodDelete, \"/vend/a/b/c\", mockIssuer)\n\tassert.Equal(t, http.StatusMethodNotAllowed, respRecord.Code,\n\t\t\"Expected Method Not Allowed status code for valid /vend DELETE request.\")\n}\n\nfunc TestVendError(t *testing.T) {\n\tmockIssuer := build_num_test.NewMockBuildNumberIssuer()\n\terr := errors.New(\"something bad getting a build number\")\n\tWhen(mockIssuer.NextBuildNumber(matchers.AnyKubePipelineID())).ThenReturn(\"\", err)\n\n\trespRecord := makeVendRequest(t, http.MethodGet, \"/vend/owner1/repo1/branch1\", mockIssuer)\n\tassert.Equal(t, http.StatusInternalServerError, respRecord.Code,\n\t\t\"Expected Internal Server Error status code for /vend GET request when BuildNumberIssuer fails.\")\n}\n\nfunc makeVendRequest(t *testing.T, method string, path string, mockIssuer BuildNumberIssuer) *httptest.ResponseRecorder {\n\tserver := NewHTTPBuildNumberServer(\"\", 1234, mockIssuer)\n\n\treq, err := http.NewRequest(method, path, nil)\n\tif err != nil {\n\t\tt.Fatal(\"Unexpected error setting up fake HTTP request.\", err)\n\t}\n\n\trr := httptest.NewRecorder()\n\n\tserver.vend(rr, req)\n\n\treturn rr\n}\n"}
{"sample": "package dnstap\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"testing\"\n\t\"time\"\n)\n\nfunc dialAndSend(t *testing.T, network, address string) *FrameStreamSockOutput {\n\tvar addr net.Addr\n\tvar err error\n\tswitch network {\n\tcase \"unix\":\n\t\taddr, err = net.ResolveUnixAddr(network, address)\n\tcase \"tcp\", \"tcp4\", \"tcp6\":\n\t\taddr, err = net.ResolveTCPAddr(network, address)\n\tdefault:\n\t\terr = fmt.Errorf(\"invalid network %s\", network)\n\t}\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tvar out *FrameStreamSockOutput\n\toutputChan := make(chan *FrameStreamSockOutput)\n\n\tgo func() {\n\t\to, err := NewFrameStreamSockOutput(addr)\n\t\tif err != nil {\n\t\t\tt.Fatal(err)\n\t\t}\n\n\t\to.SetDialer(&net.Dialer{Timeout: time.Second})\n\t\to.SetTimeout(time.Second)\n\t\to.SetRetryInterval(time.Second)\n\n\t\toutputChan <- o\n\t}()\n\n\tselect {\n\tcase out = <-outputChan:\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"can't create a new encoder\")\n\t}\n\n\tgo out.RunOutputLoop()\n\tout.GetOutputChannel() <- []byte(\"frame\")\n\treturn out\n}\n\nfunc readOne(t *testing.T, out chan []byte) {\n\tselect {\n\tcase <-out:\n\tcase <-time.After(time.Second):\n\t\tt.Fatal(\"timed out waiting for frame\")\n\t}\n}\n\n// Test if dnstap can accept multiple connections on the socket\nfunc TestMultiConn(t *testing.T) {\n\tin, err := NewFrameStreamSockInputFromPath(\"dnstap.sock\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tout := make(chan []byte)\n\tgo in.ReadInto(out)\n\n\t// send two framestream messages on different connections\n\tdefer dialAndSend(t, \"unix\", \"dnstap.sock\").Close()\n\tdefer dialAndSend(t, \"unix\", \"dnstap.sock\").Close()\n\n\treadOne(t, out)\n\treadOne(t, out)\n}\n\nfunc TestReconnect(t *testing.T) {\n\t// Find an open port on localhost by opening a listener on an\n\t// unspecified port, querying its address, then closing it.\n\tl, err := net.Listen(\"tcp\", \"localhost:0\")\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tladdr := l.Addr()\n\tl.Close()\n\n\tdefer dialAndSend(t, laddr.Network(), laddr.String()).Close()\n\tdefer dialAndSend(t, laddr.Network(), laddr.String()).Close()\n\ttime.Sleep(1500 * time.Millisecond)\n\tl, err = net.Listen(laddr.Network(), laddr.String())\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tin := NewFrameStreamSockInput(l)\n\tout := make(chan []byte)\n\tgo in.ReadInto(out)\n\treadOne(t, out)\n\treadOne(t, out)\n}\n"}
{"sample": "package ds\n\nimport (\n\th \"github.com/lebedev-yury/cities/test_helpers\"\n\t. \"github.com/smartystreets/goconvey/convey\"\n\t\"testing\"\n)\n\nfunc TestAppStatus(t *testing.T) {\n\tConvey(\"Test is indexed\", t, func() {\n\t\tConvey(\"Returns true when status is ok\", func() {\n\t\t\tappStatus := AppStatus{Statistics: &Statistics{Status: \"ok\"}}\n\t\t\tSo(appStatus.IsIndexed(), ShouldBeTrue)\n\t\t})\n\n\t\tConvey(\"Returns false when status is not ok\", func() {\n\t\t\tappStatus := AppStatus{}\n\t\t\tSo(appStatus.IsIndexed(), ShouldBeFalse)\n\t\t})\n\t})\n\n\tConvey(\"Test get app status\", t, func() {\n\t\tdb := h.CreateDB(t)\n\t\tCreateStatisticsBucket(db)\n\n\t\tConvey(\"When indexing is done\", func() {\n\t\t\th.PutToBucket(t, db, StatisticsBucketName, \"cities_count\", \"1000\")\n\t\t\th.PutToBucket(t, db, StatisticsBucketName, \"city_names_count\", \"2000\")\n\n\t\t\tappStatus := GetAppStatus(db)\n\n\t\t\tConvey(\"Sets app status to \\\"ok\\\"\", func() {\n\t\t\t\tSo(appStatus.Statistics.Status, ShouldEqual, \"ok\")\n\t\t\t})\n\n\t\t\tConvey(\"Has correct cities count\", func() {\n\t\t\t\tSo(appStatus.Statistics.CitiesCount, ShouldEqual, 1000)\n\t\t\t})\n\n\t\t\tConvey(\"Has correct city names count\", func() {\n\t\t\t\tSo(appStatus.Statistics.CityNamesCount, ShouldEqual, 2000)\n\t\t\t})\n\t\t})\n\n\t\tConvey(\"When still indexing\", func() {\n\t\t\th.DeleteFromBucket(t, db, StatisticsBucketName, \"cities_count\")\n\t\t\th.DeleteFromBucket(t, db, StatisticsBucketName, \"city_names_count\")\n\n\t\t\tappStatus := GetAppStatus(db)\n\n\t\t\tConvey(\"Sets the app status to \\\"indexing\\\"\", func() {\n\t\t\t\tSo(appStatus.Statistics.Status, ShouldEqual, \"indexing\")\n\t\t\t})\n\n\t\t\tConvey(\"Has 0 for cities count\", func() {\n\t\t\t\tSo(appStatus.Statistics.CitiesCount, ShouldEqual, 0)\n\t\t\t})\n\n\t\t\tConvey(\"Has 0 for city names count\", func() {\n\t\t\t\tSo(appStatus.Statistics.CityNamesCount, ShouldEqual, 0)\n\t\t\t})\n\t\t})\n\t})\n}\n"}
{"sample": "package dbs\n\n//Licensed under the Apache License, Version 2.0 (the \"License\");\n//you may not use this file except in compliance with the License.\n//You may obtain a copy of the License at\n//\n//http://www.apache.org/licenses/LICENSE-2.0\n//\n//Unless required by applicable law or agreed to in writing, software\n//distributed under the License is distributed on an \"AS IS\" BASIS,\n//WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//See the License for the specific language governing permissions and\n//limitations under the License.\n//\n// Code generated by Alibaba Cloud SDK Code Generator.\n// Changes may cause incorrect behavior and will be lost if the code is regenerated.\n\nimport (\n\t\"github.com/CRORCR/alibaba-cloud-sdk-go/sdk/requests\"\n\t\"github.com/CRORCR/alibaba-cloud-sdk-go/sdk/responses\"\n)\n\n// DescribeJobErrorCode invokes the dbs.DescribeJobErrorCode API synchronously\nfunc (client *Client) DescribeJobErrorCode(request *DescribeJobErrorCodeRequest) (response *DescribeJobErrorCodeResponse, err error) {\n\tresponse = CreateDescribeJobErrorCodeResponse()\n\terr = client.DoAction(request, response)\n\treturn\n}\n\n// DescribeJobErrorCodeWithChan invokes the dbs.DescribeJobErrorCode API asynchronously\nfunc (client *Client) DescribeJobErrorCodeWithChan(request *DescribeJobErrorCodeRequest) (<-chan *DescribeJobErrorCodeResponse, <-chan error) {\n\tresponseChan := make(chan *DescribeJobErrorCodeResponse, 1)\n\terrChan := make(chan error, 1)\n\terr := client.AddAsyncTask(func() {\n\t\tdefer close(responseChan)\n\t\tdefer close(errChan)\n\t\tresponse, err := client.DescribeJobErrorCode(request)\n\t\tif err != nil {\n\t\t\terrChan <- err\n\t\t} else {\n\t\t\tresponseChan <- response\n\t\t}\n\t})\n\tif err != nil {\n\t\terrChan <- err\n\t\tclose(responseChan)\n\t\tclose(errChan)\n\t}\n\treturn responseChan, errChan\n}\n\n// DescribeJobErrorCodeWithCallback invokes the dbs.DescribeJobErrorCode API asynchronously\nfunc (client *Client) DescribeJobErrorCodeWithCallback(request *DescribeJobErrorCodeRequest, callback func(response *DescribeJobErrorCodeResponse, err error)) <-chan int {\n\tresult := make(chan int, 1)\n\terr := client.AddAsyncTask(func() {\n\t\tvar response *DescribeJobErrorCodeResponse\n\t\tvar err error\n\t\tdefer close(result)\n\t\tresponse, err = client.DescribeJobErrorCode(request)\n\t\tcallback(response, err)\n\t\tresult <- 1\n\t})\n\tif err != nil {\n\t\tdefer close(result)\n\t\tcallback(nil, err)\n\t\tresult <- 0\n\t}\n\treturn result\n}\n\n// DescribeJobErrorCodeRequest is the request struct for api DescribeJobErrorCode\ntype DescribeJobErrorCodeRequest struct {\n\t*requests.RpcRequest\n\tClientToken string `position:\"Query\" name:\"ClientToken\"`\n\tLanguage    string `position:\"Query\" name:\"Language\"`\n\tOwnerId     string `position:\"Query\" name:\"OwnerId\"`\n\tTaskId      string `position:\"Query\" name:\"TaskId\"`\n}\n\n// DescribeJobErrorCodeResponse is the response struct for api DescribeJobErrorCode\ntype DescribeJobErrorCodeResponse struct {\n\t*responses.BaseResponse\n\tSuccess        bool   `json:\"Success\" xml:\"Success\"`\n\tErrCode        string `json:\"ErrCode\" xml:\"ErrCode\"`\n\tErrMessage     string `json:\"ErrMessage\" xml:\"ErrMessage\"`\n\tHttpStatusCode int    `json:\"HttpStatusCode\" xml:\"HttpStatusCode\"`\n\tRequestId      string `json:\"RequestId\" xml:\"RequestId\"`\n\tItem           Item   `json:\"Item\" xml:\"Item\"`\n}\n\n// CreateDescribeJobErrorCodeRequest creates a request to invoke DescribeJobErrorCode API\nfunc CreateDescribeJobErrorCodeRequest() (request *DescribeJobErrorCodeRequest) {\n\trequest = &DescribeJobErrorCodeRequest{\n\t\tRpcRequest: &requests.RpcRequest{},\n\t}\n\trequest.InitWithApiInfo(\"Dbs\", \"2019-03-06\", \"DescribeJobErrorCode\", \"cbs\", \"openAPI\")\n\trequest.Method = requests.POST\n\treturn\n}\n\n// CreateDescribeJobErrorCodeResponse creates a response to parse from DescribeJobErrorCode response\nfunc CreateDescribeJobErrorCodeResponse() (response *DescribeJobErrorCodeResponse) {\n\tresponse = &DescribeJobErrorCodeResponse{\n\t\tBaseResponse: &responses.BaseResponse{},\n\t}\n\treturn\n}\n"}
{"sample": "// Copyright 2017 Northern.tech AS\n//\n//    Licensed under the Apache License, Version 2.0 (the \"License\");\n//    you may not use this file except in compliance with the License.\n//    You may obtain a copy of the License at\n//\n//        http://www.apache.org/licenses/LICENSE-2.0\n//\n//    Unless required by applicable law or agreed to in writing, software\n//    distributed under the License is distributed on an \"AS IS\" BASIS,\n//    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//    See the License for the specific language governing permissions and\n//    limitations under the License.\n// Code generated by mockery v1.0.0\npackage mocks\n\nimport context \"context\"\nimport mock \"github.com/stretchr/testify/mock\"\nimport model \"github.com/mendersoftware/useradm/model\"\n\n// DataStore is an autogenerated mock type for the DataStore type\ntype DataStore struct {\n\tmock.Mock\n}\n\n// CreateUser provides a mock function with given fields: ctx, u\nfunc (_m *DataStore) CreateUser(ctx context.Context, u *model.User) error {\n\tret := _m.Called(ctx, u)\n\n\tvar r0 error\n\tif rf, ok := ret.Get(0).(func(context.Context, *model.User) error); ok {\n\t\tr0 = rf(ctx, u)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}\n\n// DeleteUser provides a mock function with given fields: ctx, id\nfunc (_m *DataStore) DeleteUser(ctx context.Context, id string) error {\n\tret := _m.Called(ctx, id)\n\n\tvar r0 error\n\tif rf, ok := ret.Get(0).(func(context.Context, string) error); ok {\n\t\tr0 = rf(ctx, id)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}\n\n// GetUserByEmail provides a mock function with given fields: ctx, email\nfunc (_m *DataStore) GetUserByEmail(ctx context.Context, email string) (*model.User, error) {\n\tret := _m.Called(ctx, email)\n\n\tvar r0 *model.User\n\tif rf, ok := ret.Get(0).(func(context.Context, string) *model.User); ok {\n\t\tr0 = rf(ctx, email)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*model.User)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(context.Context, string) error); ok {\n\t\tr1 = rf(ctx, email)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}\n\n// GetUserById provides a mock function with given fields: ctx, id\nfunc (_m *DataStore) GetUserById(ctx context.Context, id string) (*model.User, error) {\n\tret := _m.Called(ctx, id)\n\n\tvar r0 *model.User\n\tif rf, ok := ret.Get(0).(func(context.Context, string) *model.User); ok {\n\t\tr0 = rf(ctx, id)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).(*model.User)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(context.Context, string) error); ok {\n\t\tr1 = rf(ctx, id)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}\n\n// GetUsers provides a mock function with given fields: ctx\nfunc (_m *DataStore) GetUsers(ctx context.Context) ([]model.User, error) {\n\tret := _m.Called(ctx)\n\n\tvar r0 []model.User\n\tif rf, ok := ret.Get(0).(func(context.Context) []model.User); ok {\n\t\tr0 = rf(ctx)\n\t} else {\n\t\tif ret.Get(0) != nil {\n\t\t\tr0 = ret.Get(0).([]model.User)\n\t\t}\n\t}\n\n\tvar r1 error\n\tif rf, ok := ret.Get(1).(func(context.Context) error); ok {\n\t\tr1 = rf(ctx)\n\t} else {\n\t\tr1 = ret.Error(1)\n\t}\n\n\treturn r0, r1\n}\n\n// UpdateUser provides a mock function with given fields: ctx, id, u\nfunc (_m *DataStore) UpdateUser(ctx context.Context, id string, u *model.UserUpdate) error {\n\tret := _m.Called(ctx, id, u)\n\n\tvar r0 error\n\tif rf, ok := ret.Get(0).(func(context.Context, string, *model.UserUpdate) error); ok {\n\t\tr0 = rf(ctx, id, u)\n\t} else {\n\t\tr0 = ret.Error(0)\n\t}\n\n\treturn r0\n}\n"}
{"sample": "package core\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"syscall\"\n\t\"testing\"\n\t\"time\"\n\n\t\"github.com/stretchr/testify/suite\"\n)\n\ntype MinionTestSuite struct {\n\tsuite.Suite\n}\n\nfunc TestMinionTestSuite(t *testing.T) {\n\tsuite.Run(t, new(MinionTestSuite))\n}\n\nfunc (suite *MinionTestSuite) TestFinishNormal() {\n\n\tmock := childForTest()\n\tminion := NewMinion(mock)\n\tctx := context.Background()\n\n\tsuite.Nil(minion.Run(ctx))\n\tsuite.True(mock.finished)\n\tsuite.False(mock.stopped)\n}\n\nfunc (suite *MinionTestSuite) TestStopProcessing() {\n\n\tmock := childForTest()\n\tminion := NewMinion(mock)\n\tctx := context.Background()\n\n\tgo minion.Run(ctx)\n\ttime.Sleep(2 * time.Second)\n\tminion.Stop()\n\n\ttime.Sleep(1 * time.Second)\n\tsuite.True(mock.counter > 1)\n\tsuite.False(mock.finished)\n\tsuite.True(mock.stopped)\n}\n\nfunc (suite *MinionTestSuite) TestWithoutChild() {\n\n\tminion := NewMinion(nil)\n\tctx := context.Background()\n\n\tsuite.NotNil(minion.Run(ctx))\n}\n\nfunc (suite *MinionTestSuite) TestProcessingError() {\n\n\tmock := childForTest()\n\tmock.shouldEndWithError = true\n\tminion := NewMinion(mock)\n\tctx := context.Background()\n\n\tsuite.NotNil(minion.Run(ctx))\n\tsuite.True(mock.finished)\n\tsuite.False(mock.stopped)\n}\n\nfunc (suite *MinionTestSuite) TestStopProcessingOnOsSignals() {\n\n\tmock := childForTest()\n\tosSignalChan := make(chan os.Signal)\n\tminion := NewMinion(mock)\n\tminion.sigObserver = newSigObserverWithChan(osSignalChan)\n\tctx := context.Background()\n\n\tgo minion.Run(ctx)\n\ttime.Sleep(2 * time.Second)\n\tosSignalChan <- syscall.SIGTERM\n\n\ttime.Sleep(1 * time.Second)\n\tsuite.True(mock.counter > 1)\n\tsuite.False(mock.finished)\n\tsuite.True(mock.stopped)\n}\n"}
{"sample": "package dynamic\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n)\n\n// SynthesizeExtras is a type that wants to pass extra values to the Synthesize\n// function. The key-value pairs will be included as-is without inspection by\n// the Synthesize function. This is useful for populated synthesized values with\n// functions or computed values.\ntype SynthesizeExtras interface {\n\t// SynthesizeExtras returns a map of extra values to include when passing\n\t// to Synthesize().\n\tSynthesizeExtras() map[string]interface{}\n}\n\n// SetField inserts a value into v at path.\n//\n// For example, if the marshalled representation of v is\n// {\"foo\": \"bar\", \"baz\": { \"value\": 5 }},\n// Then SetField(v, \"baz.value\", 10) will result in\n// {\"foo\": \"bar\", \"baz\": { \"value\": 10 }}.\n//\n// v's reflect.Kind must be reflect.Struct, or a non-nil error will\n// be returned. If the path refers to a struct field, then v must\n// be addressable, or an error will be returned.\nfunc SetField(v interface{}, path string, value interface{}) error {\n\tstrukt := reflect.Indirect(reflect.ValueOf(v))\n\tif !strukt.IsValid() {\n\t\treturn errors.New(\"SetField on nil Attributes\")\n\t}\n\tif kind := strukt.Kind(); kind != reflect.Struct {\n\t\treturn fmt.Errorf(\"invalid type (want struct): %v\", kind)\n\t}\n\tfieldsp := structFieldPool.Get().(*[]structField)\n\tdefer func() {\n\t\t*fieldsp = (*fieldsp)[:0]\n\t\tstructFieldPool.Put(fieldsp)\n\t}()\n\tgetJSONFields(strukt, true, fieldsp)\n\tfields := *fieldsp\n\tf, ok := lookupField(fields, path)\n\tif !ok {\n\t\treturn fmt.Errorf(\"dynamic: no such field: %q\", path)\n\t}\n\tfield := f.Value\n\tif !field.IsValid() {\n\t\treturn fmt.Errorf(\"dynamic: field is invalid: %s\", path)\n\t}\n\tif !field.CanSet() {\n\t\treturn fmt.Errorf(\"dynamic: struct field not addressable: %q\", path)\n\t}\n\tfield.Set(reflect.ValueOf(value))\n\treturn nil\n}\n\n// GetField gets a field from v according to its name.\n// If GetField doesn't find a struct field with the corresponding name, then\n// it will try to dynamically find the corresponding item in the 'Extended'\n// field. GetField is case-sensitive, but extended attribute names will be\n// converted to CamelCaps.\nfunc GetField(v interface{}, name string) (interface{}, error) {\n\tif len(name) == 0 {\n\t\treturn nil, errors.New(\"dynamic: empty path specified\")\n\t}\n\tif v == nil {\n\t\treturn nil, errors.New(\"dynamic: GetField with nil\")\n\t}\n\n\tif s := string([]rune(name)[0]); strings.Title(s) != s {\n\t\t// Exported fields are always upper-cased for the first rune\n\t\tname = strings.Title(s) + string([]rune(name)[1:])\n\t}\n\tstrukt := reflect.Indirect(reflect.ValueOf(v))\n\tif kind := strukt.Kind(); kind != reflect.Struct {\n\t\treturn nil, fmt.Errorf(\"invalid type (want struct): %v\", kind)\n\t}\n\tfield := strukt.FieldByName(name)\n\tif field.IsValid() {\n\t\tfield := reflect.Indirect(field)\n\t\tif field.Kind() == reflect.Map {\n\t\t\treturn reflectMapToMapParameters(field), nil\n\t\t}\n\t\treturn field.Interface(), nil\n\t}\n\n\treturn nil, fmt.Errorf(\"missing field: %q\", name)\n}\n\n// reflectMapToMapParameters turns a reflect.Map into a map[string]interface{}\nfunc reflectMapToMapParameters(v reflect.Value) interface{} {\n\tresult := make(map[string]interface{})\n\tfor _, key := range v.MapKeys() {\n\t\tif key.Kind() != reflect.String {\n\t\t\t// Fallback - if the map has a non-string key type, return the\n\t\t\t// variable as-is.\n\t\t\treturn v.Interface()\n\t\t}\n\t\tresult[key.Interface().(string)] = v.MapIndex(key).Interface()\n\t}\n\treturn result\n}\n\n// Synthesize recursively turns structs into map[string]interface{}\n// values. It works on most datatypes. Synthesize panics if it is\n// called on channels.\n//\n// Synthesize will use the json tag from struct fields to name map\n// keys, if the json tag is present.\nfunc Synthesize(v interface{}) interface{} {\n\tvalue := reflect.Indirect(reflect.ValueOf(v))\n\tswitch value.Kind() {\n\tcase reflect.Struct:\n\t\tresult := synthesizeStruct(value)\n\t\tif m, ok := v.(SynthesizeExtras); ok {\n\t\t\tfor k, v := range m.SynthesizeExtras() {\n\t\t\t\tresult[k] = v\n\t\t\t}\n\t\t}\n\t\tmeta, ok := result[\"metadata\"]\n\t\tif ok {\n\t\t\tmeta, ok := meta.(map[string]interface{})\n\t\t\tif ok {\n\t\t\t\t// hack alert! put the metadata fields into the top-level object\n\t\t\t\t// to avoid breaking user expectations.\n\t\t\t\tfor k, v := range meta {\n\t\t\t\t\tresult[k] = v\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn result\n\tcase reflect.Slice, reflect.Array:\n\t\treturn synthesizeSlice(value)\n\tcase reflect.Map:\n\t\treturn synthesizeMap(value)\n\tcase reflect.Chan:\n\t\tpanic(\"can't synthesize channel\")\n\tcase reflect.Invalid:\n\t\t// We got passed a nil\n\t\treturn nil\n\tdefault:\n\t\tif value.CanInterface() {\n\t\t\treturn value.Interface()\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// SynthesizeMethods returns a map of method names to methods from v.\nfunc SynthesizeMethods(v interface{}) map[string]interface{} {\n\tvalue := reflect.ValueOf(v)\n\tif value.IsZero() {\n\t\treturn nil\n\t}\n\ttyp := value.Type()\n\tn := value.NumMethod()\n\tresult := make(map[string]interface{}, n)\n\tfor i := 0; i < n; i++ {\n\t\tmethodValue := value.Method(i)\n\t\tmethodType := typ.Method(i)\n\t\tresult[methodType.Name] = methodValue.Interface()\n\t}\n\treturn result\n}\n\nfunc synthesizeSlice(value reflect.Value) interface{} {\n\tlength := value.Len()\n\tslice := make([]interface{}, length)\n\tfor i := 0; i < length; i++ {\n\t\tval := value.Index(i)\n\t\tvar elt interface{} = nil\n\t\tif val.CanInterface() {\n\t\t\telt = val.Interface()\n\t\t}\n\t\tslice[i] = Synthesize(elt)\n\t}\n\treturn slice\n}\n\nfunc synthesizeMap(value reflect.Value) interface{} {\n\ttyp := value.Type()\n\tkeyT := typ.Key()\n\tif keyT.Kind() != reflect.String {\n\t\t// Maps without string keys are not supported\n\t\treturn map[string]interface{}{}\n\t}\n\tlength := value.Len()\n\tout := make(map[string]interface{}, length)\n\tfor _, key := range value.MapKeys() {\n\t\tval := value.MapIndex(key)\n\t\tvar elt interface{}\n\t\tif val.CanInterface() {\n\t\t\telt = val.Interface()\n\t\t}\n\t\tout[key.Interface().(string)] = Synthesize(elt)\n\t}\n\treturn out\n}\n\nfunc synthesizeStruct(value reflect.Value) map[string]interface{} {\n\tnumField := value.NumField()\n\tout := make(map[string]interface{}, numField)\n\tt := value.Type()\n\tfor i := 0; i < numField; i++ {\n\t\tfield := t.Field(i)\n\t\tif field.PkgPath != \"\" {\n\t\t\t// unexported fields are not included in the synthesis\n\t\t\tcontinue\n\t\t}\n\t\ts := structField{Field: field}\n\t\tfieldName, _ := s.jsonFieldName()\n\t\tfieldValue := value.Field(i)\n\n\t\tswitch fieldValue.Kind() {\n\t\tcase reflect.Struct:\n\t\t\t// Recursively convert all fields to synthesized values\n\t\t\tfields := synthesizeStruct(fieldValue)\n\n\t\t\t// flatten embedded fields to the top level\n\t\t\tif t.Field(i).Anonymous {\n\t\t\t\tfor k, v := range fields {\n\t\t\t\t\tout[k] = v\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tout[fieldName] = fields\n\t\t\t}\n\t\tcase reflect.Slice, reflect.Array:\n\t\t\tout[fieldName] = synthesizeSlice(fieldValue)\n\t\tcase reflect.Map:\n\t\t\tout[fieldName] = synthesizeMap(fieldValue)\n\t\tdefault:\n\t\t\tif fieldValue.CanInterface() {\n\t\t\t\tout[fieldName] = Synthesize(fieldValue.Interface())\n\t\t\t} else {\n\t\t\t\tout[fieldName] = nil\n\t\t\t}\n\t\t}\n\t}\n\n\treturn out\n}\n"}
{"sample": "/*\n * Copyright (c) 2017, MegaEase\n * All rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage spec\n\nimport (\n\t\"fmt\"\n\n\tk8sresource \"k8s.io/apimachinery/pkg/api/resource\"\n\n\t\"github.com/megaease/easegress/pkg/filter/requestadaptor\"\n\t\"github.com/megaease/easegress/pkg/object/httpserver\"\n)\n\nconst (\n\tAutoScaleMetricCPU         = \"cpu\"\n\tAutoScaleMetricConcurrency = \"concurrency\"\n\tAutoScaleMetricRPS         = \"rps\"\n\n\t// ProviderKnative is the faas provider Knative.\n\tProviderKnative = \"knative\"\n)\n\ntype (\n\t// Admin describes the Function.\n\tAdmin struct {\n\t\t// SyncInterval is the interval for reconciling local FaaSFunction state and FaaSProvider's.\n\t\tSyncInterval string `yaml:\"syncInterval\" jsonschema:\"required,format=duration\"`\n\n\t\t// Provider is the FaaSProvider.\n\t\tProvider string `yaml:\"provider\" jsonschema:\"required\"`\n\n\t\t// HTTPServer is the HTTP traffic gate for accepting ingress traffic.\n\t\tHTTPServer *httpserver.Spec `yaml:\"httpServer\" jsonschema:\"required\"`\n\n\t\t// Currently we only supports knative type faas provider, so this filed should be\n\t\t// \"required\" right now.\n\t\tKnative *Knative `yaml:\"knative\" jsonschema:\"required\"`\n\t}\n\n\t// Function contains the FaaSFunction's spec ,runtime status with a build-in fsm.\n\tFunction struct {\n\t\tSpec   *Spec   `yaml:\"spec\" jsonschema:\"required\"`\n\t\tStatus *Status `yaml:\"status\" jsonschema:\"required\"`\n\t\tFsm    *FSM    `yaml:\"fsm\" jsonschema:\"omitempty\"`\n\t}\n\n\t// Spec is the spec of FaaSFunction.\n\tSpec struct {\n\t\tName           string `yaml:\"name\" jsonschema:\"required\"`\n\t\tImage          string `yaml:\"image\" jsonschema:\"required\"`\n\t\tPort           int    `yaml:\"port\" jsonschema:\"omitempty\"`\n\t\tAutoScaleType  string `yaml:\"autoScaleType\" jsonschema:\"required\"`\n\t\tAutoScaleValue string `yaml:\"autoScaleValue\" jsonschema:\"required\"`\n\t\tMinReplica     int    `yaml:\"minReplica\" jsonschema:\"omitempty\"`\n\t\tMaxReplica     int    `yaml:\"maxReplica\" jsonschema:\"omitempty\"`\n\t\tLimitCPU       string `yaml:\"limitCPU\" jsonschema:\"omitempty\"`\n\t\tLimitMemory    string `yaml:\"limitMemory\" jsonschema:\"omitempty\"`\n\t\tRequestCPU     string `yaml:\"requestCPU\" jsonschema:\"omitempty\"`\n\t\tRequestMemory  string `yaml:\"requestMemory\" jsonschema:\"omitempty\"`\n\n\t\tRequestAdaptor *requestadaptor.Spec `yaml:\"requestAdaptor\" jsonschema:\"required\"`\n\t}\n\n\t// Status is the status of faas function.\n\tStatus struct {\n\t\tName    string            `yaml:\"name\" jsonschema:\"required\"`\n\t\tState   State             `yaml:\"state\" jsonschema:\"required\"`\n\t\tEvent   Event             `yaml:\"event\" jsonschema:\"required\"`\n\t\tExtData map[string]string `yaml:\"extData\" jsonschema:\"omitempty\"`\n\t}\n\n\t// Knative is the faas provider Knative.\n\tKnative struct {\n\t\tHostSuffix      string `yaml:\"hostSuffix\" jsonschema:\"required\"`\n\t\tNetworkLayerURL string `yaml:\"networkLayerURL\" jsonschema:\"required,format=uri\"`\n\n\t\tNamespace string `yaml:\"namespace\" jsonschema:\"omitempty\"`\n\t\tTimeout   string `yaml:\"timeout\" jsonschema:\"omitempty,format=duration\"`\n\t}\n)\n\n// Validate valid FaaSFunction's spec.\nfunc (spec *Spec) Validate() error {\n\tif spec.MinReplica > spec.MaxReplica {\n\t\treturn fmt.Errorf(\"invalided minreplica: %d and maxreplica: %d\", spec.MinReplica, spec.MaxReplica)\n\t}\n\n\tswitch spec.AutoScaleType {\n\tcase AutoScaleMetricCPU, AutoScaleMetricConcurrency, AutoScaleMetricRPS:\n\t\t//\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown autoscale type: %s\", spec.AutoScaleType)\n\t}\n\n\tcheckK8s := func() (errMsg error) {\n\t\tdefer func() {\n\t\t\tif err := recover(); err != nil {\n\t\t\t\terrMsg = fmt.Errorf(\"k8s resource value check failed: %v\", err)\n\t\t\t}\n\t\t}()\n\n\t\t// check if k8s resource valid or note\n\t\tk8sresource.MustParse(spec.LimitMemory)\n\t\tk8sresource.MustParse(spec.LimitCPU)\n\t\tk8sresource.MustParse(spec.RequestCPU)\n\t\tk8sresource.MustParse(spec.RequestMemory)\n\t\treturn\n\t}\n\n\treturn checkK8s()\n}\n\n// Next turns function's states into next states by given event.\nfunc (function *Function) Next(event Event) (updated bool, err error) {\n\tupdated = false\n\toldState := function.Fsm.Current()\n\terr = function.Fsm.Next(event)\n\tif err != nil {\n\t\treturn\n\t}\n\n\tif oldState != function.Fsm.Current() {\n\t\tupdated = true\n\t\tfunction.Status.State = function.Fsm.currentState\n\t}\n\tfunction.Status.Event = event\n\treturn\n}\n"}
{"sample": "package bits\n\n/**\n * Given a word, returns array of words, prefix of which is word\n */\nfunc (f *FrozenTrie) GetSuggestedWords(word string, limit int) []string {\n\tvar result []string\n\n\tnode := f.GetRoot()\n\n\t// find the node corresponding to the last char of input\n\tfor _, runeValue := range word {\n\t\tvar child FrozenTrieNode\n\t\tvar j uint = 0\n\t\tfor ; j < node.GetChildCount(); j++ {\n\t\t\tchild = node.GetChild(j)\n\t\t\tif child.letter == string(runeValue) {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// not found, return.\n\t\tif j == node.GetChildCount() {\n\t\t\treturn result\n\t\t}\n\n\t\tnode = child\n\t}\n\n\t// The node corresponding to the last letter of word is found.\n\t// Use this node as root. traversing the trie in level order.\n\treturn f.traverseSubTrie(node, word, limit)\n}\n\nfunc (f *FrozenTrie) traverseSubTrie(node FrozenTrieNode, prefix string, limit int) []string {\n\tvar result []string\n\n\tvar level []FrozenTrieNode\n\tlevel = append(level, node)\n\tvar prefixLevel []string\n\tprefixLevel = append(prefixLevel, prefix)\n\n\tfor len(level) > 0 {\n\t\tnodeNow := level[0]\n\t\tlevel = level[1:]\n\t\tprefixNow := prefixLevel[0]\n\t\tprefixLevel = prefixLevel[1:]\n\n\t\t// if the prefix is a legal word.\n\t\tif nodeNow.final {\n\t\t\tresult = append(result, prefixNow)\n\t\t\tif len(result) > limit {\n\t\t\t\treturn result\n\t\t\t}\n\t\t}\n\n\t\tvar i uint = 0\n\t\tfor ; i < nodeNow.GetChildCount(); i++ {\n\t\t\tchild := nodeNow.GetChild(i)\n\t\t\tlevel = append(level, child)\n\t\t\tprefixLevel = append(prefixLevel, prefixNow+child.letter)\n\t\t}\n\t}\n\n\treturn result\n}\n"}
{"sample": "package cwl\n\nimport (\n\t\"github.com/commondream/yamlast\"\n)\n\nfunc (l *loader) preprocess(n node) (node, error) {\n\tswitch n.Kind {\n\n\tcase yamlast.MappingNode:\n\t\tfor i := 0; i < len(n.Children)-1; i += 2 {\n\t\t\tk := n.Children[i]\n\t\t\tv := n.Children[i+1]\n\t\t\tswitch k.Value {\n\t\t\tcase \"$import\":\n\t      if _, ok := l.resolver.(noResolver); ok {\n          return n, nil\n        }\n\t\t\t\tb, _, err := l.resolver.Resolve(l.base, v.Value)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tyamlnode, err := yamlast.Parse(b)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\t// TODO set line/col/file of the new nodes\n\t\t\t\treturn yamlnode.Children[0], nil\n\n\t\t\tcase \"$include\":\n\t      if _, ok := l.resolver.(noResolver); ok {\n          return n, nil\n        }\n\t\t\t\tb, _, err := l.resolver.Resolve(l.base, v.Value)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\t// TODO check line/col of the new node is correct\n\t\t\t\treturn node(&yamlast.Node{\n\t\t\t\t\tKind:   yamlast.ScalarNode,\n\t\t\t\t\tLine:   n.Line,\n\t\t\t\t\tColumn: n.Column,\n\t\t\t\t\tValue:  string(b),\n\t\t\t\t}), nil\n\n\t\t\t// TODO $mixin\n\n\t\t\tdefault:\n\t\t\t\tx, err := l.preprocess(v)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tn.Children[i+1] = x\n\t\t\t}\n\t\t}\n\n\tcase yamlast.SequenceNode:\n\t\tfor i, c := range n.Children {\n\t\t\tx, err := l.preprocess(c)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tn.Children[i] = x\n\t\t}\n\t}\n\treturn n, nil\n}\n"}
{"sample": "package tree\n\nimport (\n\t\"testing\"\n\n\t. \"github.com/onsi/ginkgo/v2\"\n\t. \"github.com/onsi/gomega\"\n)\n\nvar _ = Describe(\"BST\", func() {\n\tvar bst *BST\n\tAssertBSTBehavior := func() {\n\t\tIt(\"should be empty\", func() {\n\t\t\tExpect(bst.IsEmpty()).To(BeTrue())\n\t\t\tExpect(bst.Size()).To(BeZero())\n\t\t})\n\n\t\tIt(\"can Add nodes\", func() {\n\t\t\tbst.Add(10)\n\t\t\tbst.Add(19)\n\t\t\tbst.Add(5)\n\t\t\tbst.Add(18)\n\t\t\tbst.Add(27)\n\t\t\tbst.Add(1)\n\t\t\tbst.Add(10)\n\t\t\tbst.Add(18)\n\t\t\tbst.Add(15)\n\t\t\tbst.Add(22)\n\n\t\t\tExpect(bst.IsEmpty()).To(BeFalse())\n\t\t\tExpect(bst.Size()).To(Equal(8))\n\t\t})\n\n\t\tIt(\"can know whether node contains\", func() {\n\t\t\tExpect(bst.Contains(10)).To(BeTrue())\n\t\t\tExpect(bst.Contains(19)).To(BeTrue())\n\t\t\tExpect(bst.Contains(5)).To(BeTrue())\n\t\t\tExpect(bst.Contains(11)).To(BeFalse())\n\t\t})\n\n\t\tSpecify(\"pre order traverse\", func() {\n\t\t\tbst.PreOrder()\n\t\t\tGinkgoWriter.Println(\"\\n\")\n\t\t})\n\n\t\tSpecify(\"in order traverse\", func() {\n\t\t\tbst.InOrder()\n\t\t\tGinkgoWriter.Println(\"\\n\")\n\t\t})\n\n\t\tSpecify(\"post order traverse\", func() {\n\t\t\tbst.PostOrder()\n\t\t\tGinkgoWriter.Println(\"\\n\")\n\t\t})\n\n\t\tSpecify(\"pre order nr traverse\", func() {\n\t\t\tbst.PreOrderNR()\n\t\t\tGinkgoWriter.Println(\"\\n\")\n\t\t})\n\n\t\tSpecify(\"level order\", func() {\n\t\t\tbst.LevelOrder()\n\t\t\tGinkgoWriter.Println(\"\\n\")\n\t\t})\n\n\t\tSpecify(\"get min/max node\", func() {\n\t\t\tExpect(bst.Min()).To(BeEquivalentTo(1))\n\t\t\tExpect(bst.Max()).To(BeEquivalentTo(27))\n\t\t})\n\n\t\tSpecify(\"delete min/max node\", func() {\n\t\t\tExpect(bst.RemoveMin()).To(BeEquivalentTo(1))\n\t\t\tExpect(bst.RemoveMax()).To(BeEquivalentTo(27))\n\t\t})\n\n\t\tSpecify(\"delete nodes\", func() {\n\t\t\tbst.Remove(1)\n\t\t\tbst.Remove(100)\n\t\t\tbst.Remove(18)\n\t\t\tbst.Remove(20)\n\t\t\tbst.Remove(15)\n\t\t\tbst.Remove(10)\n\t\t\tbst.Remove(5)\n\t\t\tbst.Remove(19)\n\t\t\tbst.Remove(22)\n\t\t})\n\t}\n\n\tDescribe(\"BST\", Ordered, func() {\n\t\tBeforeAll(func() {\n\t\t\tbst = NewBST()\n\t\t})\n\n\t\tAssertBSTBehavior()\n\t})\n})\n\nfunc TestBST(t *testing.T) {\n\tRegisterFailHandler(Fail)\n\tRunSpecs(t, \"BST Suite\")\n}\n"}
{"sample": "/*\nCopyright \u00a9 2021 The Authors of gotabgo\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\npackage cmd\n\nimport (\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/groundfoundation/gotabgo\"\n\thomedir \"github.com/mitchellh/go-homedir\"\n\tlog \"github.com/sirupsen/logrus\"\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/viper\"\n)\n\ntype opts struct {\n\tpassword         string\n\tserver           string\n\ttls              bool\n\tusername         string\n\tserverApiVersion string\n}\n\nvar (\n\tcfgFile string\n\n\tdebug bool\n\n\toptions opts\n\n\ttabApi *gotabgo.TabApi\n\n\t// rootCmd represents the base command when called without any subcommands\n\trootCmd = &cobra.Command{\n\t\tUse:   \"gotabgo [serverinfo]\",\n\t\tShort: \"A cli tool for interacting with Tableau Server\",\n\t\tLong: `\ngotabgo is a CLI library for Tableau Server that enables administration from\nthe command line.`,\n\t\t// Uncomment the following line if your bare application\n\t\t// has an action associated with it:\n\t\t// Run: func(cmd *cobra.Command, args []string) { },\n\t\tPersistentPreRunE: func(cmd *cobra.Command, args []string) (e error) {\n\n\t\t\tconnectOpt := opts{\n\t\t\t\tserver:           viper.GetString(\"server\"),\n\t\t\t\ttls:              viper.GetBool(\"tls\"),\n\t\t\t\tserverApiVersion: viper.GetString(\"apiversion\"),\n\t\t\t}\n\t\t\ttabApi, e = gotabgo.NewTabApi(connectOpt.server,\n\t\t\t\tconnectOpt.serverApiVersion, connectOpt.tls,\n\t\t\t\tgotabgo.Xml)\n\t\t\tlog.Debugf(\"tabApi struct: %v\", tabApi)\n\t\t\treturn e\n\t\t},\n\t}\n)\n\n// Execute adds all child commands to the root command and sets flags appropriately.\n// This is called by main.main(). It only needs to happen once to the rootCmd.\nfunc Execute() {\n\tcobra.CheckErr(rootCmd.Execute())\n}\n\nfunc init() {\n\tcobra.OnInitialize(initConfig)\n\n\t// Here you will define your flags and configuration settings.\n\t// Cobra supports persistent flags, which, if defined here,\n\t// will be global for your application.\n\n\trootCmd.PersistentFlags().StringVar(&cfgFile, \"config\", \"\", \"config file (default is $HOME/.gotabgo.yaml)\")\n\trootCmd.PersistentFlags().StringVarP(&options.username, \"username\", \"u\", \"\", \"username to use when connecting to Tableau Server\")\n\trootCmd.PersistentFlags().StringVarP(&options.password, \"password\", \"p\", \"\", \"password for the user\")\n\trootCmd.PersistentFlags().StringVarP(&options.server, \"server\", \"s\", \"\", \"the hostname of the server\")\n\trootCmd.Flags().StringVarP(&options.serverApiVersion, \"apiversion\", \"a\", \"3.9\", \"specify which version of the api to user\")\n\trootCmd.Flags().BoolVar(&options.tls, \"tls\", true, \"whether to use TLS or not when connecting\")\n\n\tviper.BindPFlag(\"username\", rootCmd.PersistentFlags().Lookup(\"username\"))\n\tviper.BindPFlag(\"password\", rootCmd.PersistentFlags().Lookup(\"password\"))\n\tviper.BindPFlag(\"server\", rootCmd.PersistentFlags().Lookup(\"server\"))\n\tviper.BindPFlag(\"apiversion\", rootCmd.Flags().Lookup(\"apiversion\"))\n\tviper.BindPFlag(\"tls\", rootCmd.Flags().Lookup(\"tls\"))\n\n\t// Cobra also supports local flags, which will only run\n\t// when this action is called directly.\n\trootCmd.Flags().BoolP(\"toggle\", \"t\", false, \"Help message for toggle\")\n\trootCmd.Flags().BoolVarP(&debug, \"debug\", \"d\", false, \"Turn on debuf output\")\n\n\tif debug {\n\t\tlog.SetLevel(log.DebugLevel)\n\t}\n\n}\n\n// initConfig reads in config file and ENV variables if set.\nfunc initConfig() {\n\tif cfgFile != \"\" {\n\t\t// Use config file from the flag.\n\t\tviper.SetConfigFile(cfgFile)\n\t} else {\n\t\t// Find home directory.\n\t\thome, err := homedir.Dir()\n\t\tcobra.CheckErr(err)\n\n\t\t// Search config in home directory with name \".gotabgo\" (without extension).\n\t\tviper.AddConfigPath(home)\n\t\tviper.SetConfigName(\".gotabgo\")\n\t}\n\n\tviper.AutomaticEnv() // read in environment variables that match\n\n\t// If a config file is found, read it in.\n\tif err := viper.ReadInConfig(); err == nil {\n\t\tfmt.Fprintln(os.Stderr, \"Using config file:\", viper.ConfigFileUsed())\n\t}\n}\n"}
{"sample": "package golang\n\nimport (\n\t\"github.com/jschaf/pggen/internal/codegen/golang/gotype\"\n\t\"sort\"\n)\n\n// ImportSet contains a set of imports required by one Go file.\ntype ImportSet struct {\n\timports map[string]struct{}\n}\n\nfunc NewImportSet() *ImportSet {\n\treturn &ImportSet{imports: make(map[string]struct{}, 4)}\n}\n\n// AddPackage adds a fully qualified package path to the set, like\n// \"github.com/jschaf/pggen/foo\".\nfunc (s *ImportSet) AddPackage(p string) {\n\ts.imports[p] = struct{}{}\n}\n\n// AddType adds all fully qualified package paths needed for type and any child\n// types.\nfunc (s *ImportSet) AddType(typ gotype.Type) {\n\ts.AddPackage(typ.Import())\n\tcomp, ok := typ.(gotype.CompositeType)\n\tif !ok {\n\t\treturn\n\t}\n\tfor _, childType := range comp.FieldTypes {\n\t\ts.AddType(childType)\n\t}\n}\n\n// SortedPackages returns a new slice containing the sorted packages, suitable\n// for an import statement.\nfunc (s *ImportSet) SortedPackages() []string {\n\timps := make([]string, 0, len(s.imports))\n\tfor pkg := range s.imports {\n\t\tif pkg != \"\" {\n\t\t\timps = append(imps, pkg)\n\t\t}\n\t}\n\tsort.Strings(imps)\n\treturn imps\n}\n"}
{"sample": "// Copyright 2021 The Matrix.org Foundation C.I.C.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage router\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"time\"\n\n\t\"github.com/matrix-org/pinecone/types\"\n)\n\n// SourceAddr implements net.Addr, containing a source-routed\n// path to another node.\ntype SourceAddr struct {\n\ttypes.SwitchPorts\n}\n\nfunc (a *SourceAddr) Network() string {\n\treturn \"ps\"\n}\n\nfunc (a *SourceAddr) String() string {\n\treturn fmt.Sprintf(\"path %v\", a.SwitchPorts)\n}\n\n// GreedyAddr implements net.Addr, containing a greedy-routed\n// set of destination coordinates to another node.\ntype GreedyAddr struct {\n\ttypes.SwitchPorts\n}\n\nfunc (a *GreedyAddr) Network() string {\n\treturn \"pg\"\n}\n\nfunc (a *GreedyAddr) String() string {\n\treturn fmt.Sprintf(\"coords %v\", a.SwitchPorts)\n}\n\n// ReadFrom reads the next packet that was delivered to this\n// node over the Pinecone network. Only traffic packets will\n// be returned here - no protocol messages will be included.\n// The net.Addr returned will contain the appropriate return\n// path based on the mechanism used to deliver the packet.\n// If the packet was delivered using greedy routing, then the\n// net.Addr will contain the source coordinates. If the packet\n// was delivered using source routing, then the net.Addr will\n// contain the source-routed path back to the sender.\nfunc (r *Router) ReadFrom(p []byte) (n int, addr net.Addr, err error) {\n\tframe := <-r.recv\n\tswitch frame.Type {\n\tcase types.TypeGreedy:\n\t\taddr = &GreedyAddr{frame.Source}\n\n\tcase types.TypeSource:\n\t\taddr = &SourceAddr{frame.Source} // TODO: should get the remainder of the path\n\n\tcase types.TypeVirtualSnakeBootstrap:\n\t\taddr = &frame.SourceKey\n\n\tcase types.TypeVirtualSnake:\n\t\taddr = &frame.SourceKey\n\n\tdefault:\n\t\tr.log.Println(\"Not expecting non-source/non-greedy frame\")\n\t\treturn\n\t}\n\n\tn = len(frame.Payload)\n\tcopy(p, frame.Payload)\n\treturn\n}\n\n// WriteTo sends a packet into the Pinecone network. The\n// packet will be sent as a traffic packet. The net.Addr must\n// be one of the Pinecone address types (e.g. GreedyAddr or\n// SourceAddr), as this will dictate the method of delivery\n// used to forward the packet.\nfunc (r *Router) WriteTo(p []byte, addr net.Addr) (n int, err error) {\n\ttimer := time.NewTimer(time.Second * 5)\n\tdefer func() {\n\t\tif !timer.Stop() {\n\t\t\t<-timer.C\n\t\t}\n\t}()\n\n\tswitch ga := addr.(type) {\n\tcase *GreedyAddr:\n\t\tselect {\n\t\tcase <-timer.C:\n\t\t\treturn 0, fmt.Errorf(\"router appears to be deadlocked\")\n\t\tcase r.send <- types.Frame{\n\t\t\tVersion:     types.Version0,\n\t\t\tType:        types.TypeGreedy,\n\t\t\tDestination: ga.SwitchPorts,\n\t\t\tSource:      r.Coords(),\n\t\t\tPayload:     p,\n\t\t}:\n\t\t\treturn len(p), nil\n\t\t}\n\n\tcase *SourceAddr:\n\t\tselect {\n\t\tcase <-timer.C:\n\t\t\treturn 0, fmt.Errorf(\"router appears to be deadlocked\")\n\t\tcase r.send <- types.Frame{\n\t\t\tVersion:     types.Version0,\n\t\t\tType:        types.TypeSource,\n\t\t\tDestination: ga.SwitchPorts,\n\t\t\tPayload:     p,\n\t\t}:\n\t\t\treturn len(p), nil\n\t\t}\n\n\tcase *types.PublicKey:\n\t\tselect {\n\t\tcase <-timer.C:\n\t\t\treturn 0, fmt.Errorf(\"router appears to be deadlocked\")\n\t\tcase r.send <- types.Frame{\n\t\t\tVersion:        types.Version0,\n\t\t\tType:           types.TypeVirtualSnake,\n\t\t\tDestinationKey: *ga,\n\t\t\tSourceKey:      r.PublicKey(),\n\t\t\tPayload:        p,\n\t\t}:\n\t\t\treturn len(p), nil\n\t\t}\n\n\tdefault:\n\t\terr = fmt.Errorf(\"unknown address type\")\n\t\treturn\n\t}\n}\n\n// LocalAddr returns a net.Addr containing the greedy routing\n// coordinates for this node.\nfunc (r *Router) LocalAddr() net.Addr {\n\tpublic := r.PublicKey()\n\treturn &public\n}\n\n// SetDeadline is not implemented.\nfunc (r *Router) SetDeadline(t time.Time) error {\n\treturn nil\n}\n\n// SetReadDeadline is not implemented.\nfunc (r *Router) SetReadDeadline(t time.Time) error {\n\treturn nil\n}\n\n// SetWriteDeadline is not implemented.\nfunc (r *Router) SetWriteDeadline(t time.Time) error {\n\treturn nil\n}\n"}
{"sample": "package restfulapi\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"go-live/functions\"\n\t\"go-live/models\"\n\t\"go-live/orm\"\n\t\"net/http\"\n\t\"strconv\"\n\n\t\"github.com/julienschmidt/httprouter\"\n)\n\n// App Restful API\nfunc CreateAppHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tappname := ps.ByName(\"appname\")\n\tliveon := r.FormValue(\"liveon\")\n\tif liveon == \"\" {\n\t\tliveon = \"on\"\n\t}\n\n\terr := models.CreateApp(&models.App{\n\t\tAppname: appname,\n\t\tLiveon:  liveon,\n\t})\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &Response{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully created this app.\",\n\t})\n}\n\nfunc ListAppsHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tapps, err := models.GetAllApps()\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &AppsResponse{\n\t\tCode:    http.StatusOK,\n\t\tData:    apps,\n\t\tMessage: \"Successfully acquired all applications.\",\n\t})\n}\n\nfunc GetAppByIdHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tappid := ps.ByName(\"appid\")\n\tif appid == \"\" {\n\t\tSendErrorResponse(w, http.StatusBadRequest, \"Appid is not be null.\")\n\t\treturn\n\t}\n\n\tid, err := strconv.Atoi(appid)\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tapp, err := models.GetAppById(id)\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &AppResponse{\n\t\tCode:    http.StatusOK,\n\t\tData:    app,\n\t\tMessage: \"Successfully obtained the corresponding application.\",\n\t})\n}\n\nfunc DeleteAppByIdHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tappid := ps.ByName(\"appid\")\n\tif appid == \"\" {\n\t\tSendErrorResponse(w, http.StatusBadRequest, \"Appid is not be null.\")\n\t\treturn\n\t}\n\n\tid, err := strconv.Atoi(appid)\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tif !models.CheckAppById(id) {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, \"This app is not in the database.\")\n\t\treturn\n\t}\n\n\tapp, err := models.GetAppById(id)\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\terr = models.DeleteApp(&models.App{Id: id})\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\terr = models.DeleteLive(&models.Live{App: app.Appname})\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &Response{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully deleted this app.\",\n\t})\n}\n\n// Live Restful API\nfunc CreateLiveHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tappname := ps.ByName(\"appname\")\n\tlivename := ps.ByName(\"livename\")\n\n\ttoken := functions.RandomString(6)\n\n\terr := models.CreateLive(&models.Live{\n\t\tApp:      appname,\n\t\tLivename: livename,\n\t\tToken:    token,\n\t})\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &LiveTokenResponse{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully created this live.\",\n\t\tToken:   token,\n\t})\n}\n\nfunc ListLivesHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tlives, err := models.GetAllLives()\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusBadRequest, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &LivesResponse{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully acquired all lives.\",\n\t\tData:    lives,\n\t})\n}\n\nfunc ListLivesByAppnameHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tappname := ps.ByName(\"appname\")\n\n\tlives, err := models.GetAllLivesByappname(appname)\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusBadRequest, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &LivesResponse{\n\t\tCode:    http.StatusOK,\n\t\tMessage: fmt.Sprintf(\"Successfully acquired all lives : %s.\", appname),\n\t\tData:    lives,\n\t})\n}\n\nfunc GetLiveByIdHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tvar lives []models.Live\n\tappname := ps.ByName(\"appname\")\n\tliveid := ps.ByName(\"liveid\")\n\n\terr := orm.Gorm.Where(\"app = ?\", appname).Where(\"id = ?\", liveid).Find(&lives).Error\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tif len(lives) == 0 {\n\t\tSendErrorResponse(w, http.StatusBadRequest, errors.New(\"lives cannot find.\").Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &LiveResponse{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully obtained the corresponding live.\",\n\t\tData:    lives[0],\n\t})\n}\n\nfunc RefershLiveTokenByIdHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tvar lives []models.Live\n\tappname := ps.ByName(\"appname\")\n\tliveid := ps.ByName(\"liveid\")\n\ttoken := functions.RandomString(6)\n\n\terr := orm.Gorm.Where(\"app = ?\", appname).Where(\"id = ?\", liveid).Find(&lives).Error\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tif len(lives) == 0 {\n\t\tSendErrorResponse(w, http.StatusBadRequest, errors.New(\"lives cannot find.\").Error())\n\t\treturn\n\t}\n\n\terr = orm.Gorm.Model(&lives[0]).Update(\"Token\", token).Error\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &LiveTokenResponse{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully refreshed Token.\",\n\t\tToken:   token,\n\t})\n}\n\nfunc DeleteLiveByIdHandler(w http.ResponseWriter, r *http.Request, ps httprouter.Params) {\n\tappname := ps.ByName(\"appname\")\n\tliveid := ps.ByName(\"liveid\")\n\n\tid, err := strconv.Atoi(liveid)\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tif !models.CheckLiveById(id) {\n\t\tSendErrorResponse(w, http.StatusBadRequest, \"This live not in database.\")\n\t\treturn\n\t}\n\n\terr = models.DeleteLive(&models.Live{\n\t\tApp: appname,\n\t\tId:  id,\n\t})\n\n\tif err != nil {\n\t\tSendErrorResponse(w, http.StatusInternalServerError, err.Error())\n\t\treturn\n\t}\n\n\tSendResponse(w, http.StatusOK, &Response{\n\t\tCode:    http.StatusOK,\n\t\tMessage: \"Successfully deleted this live.\",\n\t})\n}\n"}
{"sample": "// Code generated by protoc-gen-go-grpc. DO NOT EDIT.\n\npackage optimus\n\nimport (\n\tcontext \"context\"\n\tgrpc \"google.golang.org/grpc\"\n\tcodes \"google.golang.org/grpc/codes\"\n\tstatus \"google.golang.org/grpc/status\"\n)\n\n// This is a compile-time assertion to ensure that this generated file\n// is compatible with the grpc package it is being compiled against.\n// Requires gRPC-Go v1.32.0 or later.\nconst _ = grpc.SupportPackageIsVersion7\n\n// ProjectServiceClient is the client API for ProjectService service.\n//\n// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.\ntype ProjectServiceClient interface {\n\t// RegisterProject creates a new optimus project\n\tRegisterProject(ctx context.Context, in *RegisterProjectRequest, opts ...grpc.CallOption) (*RegisterProjectResponse, error)\n\t// ListProjects returns list of registered projects and configurations\n\tListProjects(ctx context.Context, in *ListProjectsRequest, opts ...grpc.CallOption) (*ListProjectsResponse, error)\n}\n\ntype projectServiceClient struct {\n\tcc grpc.ClientConnInterface\n}\n\nfunc NewProjectServiceClient(cc grpc.ClientConnInterface) ProjectServiceClient {\n\treturn &projectServiceClient{cc}\n}\n\nfunc (c *projectServiceClient) RegisterProject(ctx context.Context, in *RegisterProjectRequest, opts ...grpc.CallOption) (*RegisterProjectResponse, error) {\n\tout := new(RegisterProjectResponse)\n\terr := c.cc.Invoke(ctx, \"/odpf.optimus.core.v1beta1.ProjectService/RegisterProject\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}\n\nfunc (c *projectServiceClient) ListProjects(ctx context.Context, in *ListProjectsRequest, opts ...grpc.CallOption) (*ListProjectsResponse, error) {\n\tout := new(ListProjectsResponse)\n\terr := c.cc.Invoke(ctx, \"/odpf.optimus.core.v1beta1.ProjectService/ListProjects\", in, out, opts...)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn out, nil\n}\n\n// ProjectServiceServer is the server API for ProjectService service.\n// All implementations must embed UnimplementedProjectServiceServer\n// for forward compatibility\ntype ProjectServiceServer interface {\n\t// RegisterProject creates a new optimus project\n\tRegisterProject(context.Context, *RegisterProjectRequest) (*RegisterProjectResponse, error)\n\t// ListProjects returns list of registered projects and configurations\n\tListProjects(context.Context, *ListProjectsRequest) (*ListProjectsResponse, error)\n\tmustEmbedUnimplementedProjectServiceServer()\n}\n\n// UnimplementedProjectServiceServer must be embedded to have forward compatible implementations.\ntype UnimplementedProjectServiceServer struct {\n}\n\nfunc (UnimplementedProjectServiceServer) RegisterProject(context.Context, *RegisterProjectRequest) (*RegisterProjectResponse, error) {\n\treturn nil, status.Errorf(codes.Unimplemented, \"method RegisterProject not implemented\")\n}\nfunc (UnimplementedProjectServiceServer) ListProjects(context.Context, *ListProjectsRequest) (*ListProjectsResponse, error) {\n\treturn nil, status.Errorf(codes.Unimplemented, \"method ListProjects not implemented\")\n}\nfunc (UnimplementedProjectServiceServer) mustEmbedUnimplementedProjectServiceServer() {}\n\n// UnsafeProjectServiceServer may be embedded to opt out of forward compatibility for this service.\n// Use of this interface is not recommended, as added methods to ProjectServiceServer will\n// result in compilation errors.\ntype UnsafeProjectServiceServer interface {\n\tmustEmbedUnimplementedProjectServiceServer()\n}\n\nfunc RegisterProjectServiceServer(s grpc.ServiceRegistrar, srv ProjectServiceServer) {\n\ts.RegisterService(&ProjectService_ServiceDesc, srv)\n}\n\nfunc _ProjectService_RegisterProject_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {\n\tin := new(RegisterProjectRequest)\n\tif err := dec(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif interceptor == nil {\n\t\treturn srv.(ProjectServiceServer).RegisterProject(ctx, in)\n\t}\n\tinfo := &grpc.UnaryServerInfo{\n\t\tServer:     srv,\n\t\tFullMethod: \"/odpf.optimus.core.v1beta1.ProjectService/RegisterProject\",\n\t}\n\thandler := func(ctx context.Context, req interface{}) (interface{}, error) {\n\t\treturn srv.(ProjectServiceServer).RegisterProject(ctx, req.(*RegisterProjectRequest))\n\t}\n\treturn interceptor(ctx, in, info, handler)\n}\n\nfunc _ProjectService_ListProjects_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {\n\tin := new(ListProjectsRequest)\n\tif err := dec(in); err != nil {\n\t\treturn nil, err\n\t}\n\tif interceptor == nil {\n\t\treturn srv.(ProjectServiceServer).ListProjects(ctx, in)\n\t}\n\tinfo := &grpc.UnaryServerInfo{\n\t\tServer:     srv,\n\t\tFullMethod: \"/odpf.optimus.core.v1beta1.ProjectService/ListProjects\",\n\t}\n\thandler := func(ctx context.Context, req interface{}) (interface{}, error) {\n\t\treturn srv.(ProjectServiceServer).ListProjects(ctx, req.(*ListProjectsRequest))\n\t}\n\treturn interceptor(ctx, in, info, handler)\n}\n\n// ProjectService_ServiceDesc is the grpc.ServiceDesc for ProjectService service.\n// It's only intended for direct use with grpc.RegisterService,\n// and not to be introspected or modified (even as a copy)\nvar ProjectService_ServiceDesc = grpc.ServiceDesc{\n\tServiceName: \"odpf.optimus.core.v1beta1.ProjectService\",\n\tHandlerType: (*ProjectServiceServer)(nil),\n\tMethods: []grpc.MethodDesc{\n\t\t{\n\t\t\tMethodName: \"RegisterProject\",\n\t\t\tHandler:    _ProjectService_RegisterProject_Handler,\n\t\t},\n\t\t{\n\t\t\tMethodName: \"ListProjects\",\n\t\t\tHandler:    _ProjectService_ListProjects_Handler,\n\t\t},\n\t},\n\tStreams:  []grpc.StreamDesc{},\n\tMetadata: \"odpf/optimus/core/v1beta1/project.proto\",\n}\n"}
{"sample": "//\n// Package lru is a very simple implementation of LRU Cache structure.\n//\npackage lru\n\n// Cache is LRU cache implementation\ntype Cache struct {\n\tsize  int\n\tqueue *queue\n\tdata  map[string]*cacheEntry\n}\n\ntype cacheEntry struct {\n\tvalue interface{}\n\tqItem *queueItem\n}\n\n// NewCache creates new instance of LRU cache\n// with pre-initialized data structures to `size`\nfunc NewCache(size int) *Cache {\n\treturn &Cache{\n\t\tsize:  size,\n\t\tqueue: &queue{},\n\t\tdata:  make(map[string]*cacheEntry, size),\n\t}\n}\n\n// Len returns size of cached data\nfunc (c *Cache) Len() int {\n\treturn len(c.data)\n}\n\n// Put a key-value pair into cache, it will update entry\n// if it already exists\n// This operation will make entry most recently used\nfunc (c *Cache) Put(key string, value interface{}) {\n\tif _, exists := c.data[key]; exists {\n\t\t// update existing node and move qNode in front\n\t\tc.data[key].value = value\n\t\tc.queue.upfront(c.data[key].qItem)\n\t} else {\n\t\tif len(c.data) == c.size {\n\t\t\t// evict least used node from cache\n\t\t\tqItem := c.queue.tail\n\t\t\tdelete(c.data, qItem.key)\n\t\t\tc.queue.evict(qItem)\n\t\t}\n\t\t// write new cache entry\n\t\tc.data[key] = &cacheEntry{\n\t\t\tvalue: value,\n\t\t\tqItem: c.queue.add(key),\n\t\t}\n\t}\n}\n\n// Get a value by key, return nil if value not found\n// This operation will make entry most recently used\nfunc (c *Cache) Get(key string) interface{} {\n\tif v, ok := c.data[key]; ok {\n\t\tc.queue.upfront(v.qItem)\n\t\treturn v.value\n\t}\n\treturn nil\n}\n\ntype queue struct {\n\ttail *queueItem\n\thead *queueItem\n}\n\ntype queueItem struct {\n\tnext *queueItem\n\tprev *queueItem\n\tkey  string\n}\n\n// add entry in front of queue\nfunc (q *queue) add(key string) *queueItem {\n\tnewNode := &queueItem{key: key}\n\tif q.head == nil {\n\t\t// first entry\n\t\tq.head, q.tail = newNode, newNode\n\t} else {\n\t\t// new head\n\t\tnewNode.prev = q.head\n\t\tq.head.next = newNode\n\t\tq.head = newNode\n\t}\n\treturn newNode\n}\n\n// upfront moves queueItem in front of queue\nfunc (q *queue) upfront(n *queueItem) {\n\tif n.next == nil { // already in front\n\t\treturn\n\t}\n\tif n.prev == nil { // this is tail\n\t\tn.next.prev = nil\n\t\tq.tail = n.next\n\t\tn.next = nil\n\t\tq.head.next = n\n\t\tn.prev = q.head\n\t\tq.head = n\n\t\treturn\n\t}\n\t// somewhere in the middle\n\tn.prev.next = n.next\n\tn.next.prev = n.prev\n\tn.prev, n.next = q.head, nil\n\tq.head.next = n\n\tq.head = n\n}\n\n// evict deletes node from queue\nfunc (q *queue) evict(n *queueItem) {\n\tif n.prev == nil {\n\t\tif n.key == q.head.key {\n\t\t\tn.prev, n.next = nil, nil\n\t\t\tq.tail, q.head = nil, nil\n\t\t\treturn\n\t\t}\n\t\tn.next.prev = nil\n\t\tq.tail = n.next\n\t\tn.prev, n.next = nil, nil\n\t}\n}\n"}
{"sample": "// Copyright GoFrame Author(https://goframe.org). All Rights Reserved.\n//\n// This Source Code Form is subject to the terms of the MIT License.\n// If a copy of the MIT was not distributed with this file,\n// You can obtain one at https://github.com/gogf/gf.\n\npackage glog_test\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"testing\"\n\n\t\"github.com/gogf/gf/v2/container/garray\"\n\t\"github.com/gogf/gf/v2/os/glog\"\n\t\"github.com/gogf/gf/v2/test/gtest\"\n\t\"github.com/gogf/gf/v2/text/gstr\"\n)\n\nvar arrayForHandlerTest1 = garray.NewStrArray()\n\nfunc customHandler1(ctx context.Context, input *glog.HandlerInput) {\n\tarrayForHandlerTest1.Append(input.String(false))\n\tinput.Next(ctx)\n}\n\nfunc TestLogger_SetHandlers1(t *testing.T) {\n\tgtest.C(t, func(t *gtest.T) {\n\t\tw := bytes.NewBuffer(nil)\n\t\tl := glog.NewWithWriter(w)\n\t\tl.SetHandlers(customHandler1)\n\t\tl.SetCtxKeys(\"Trace-Id\", \"Span-Id\", \"Test\")\n\t\tctx := context.WithValue(context.Background(), \"Trace-Id\", \"1234567890\")\n\t\tctx = context.WithValue(ctx, \"Span-Id\", \"abcdefg\")\n\n\t\tl.Print(ctx, 1, 2, 3)\n\t\tt.Assert(gstr.Count(w.String(), \"1234567890\"), 1)\n\t\tt.Assert(gstr.Count(w.String(), \"abcdefg\"), 1)\n\t\tt.Assert(gstr.Count(w.String(), \"1 2 3\"), 1)\n\n\t\tt.Assert(arrayForHandlerTest1.Len(), 1)\n\t\tt.Assert(gstr.Count(arrayForHandlerTest1.At(0), \"1234567890\"), 1)\n\t\tt.Assert(gstr.Count(arrayForHandlerTest1.At(0), \"abcdefg\"), 1)\n\t\tt.Assert(gstr.Count(arrayForHandlerTest1.At(0), \"1 2 3\"), 1)\n\t})\n}\n\nvar arrayForHandlerTest2 = garray.NewStrArray()\n\nfunc customHandler2(ctx context.Context, input *glog.HandlerInput) {\n\tarrayForHandlerTest2.Append(input.String(false))\n}\n\nfunc TestLogger_SetHandlers2(t *testing.T) {\n\tgtest.C(t, func(t *gtest.T) {\n\t\tw := bytes.NewBuffer(nil)\n\t\tl := glog.NewWithWriter(w)\n\t\tl.SetHandlers(customHandler2)\n\t\tl.SetCtxKeys(\"Trace-Id\", \"Span-Id\", \"Test\")\n\t\tctx := context.WithValue(context.Background(), \"Trace-Id\", \"1234567890\")\n\t\tctx = context.WithValue(ctx, \"Span-Id\", \"abcdefg\")\n\n\t\tl.Print(ctx, 1, 2, 3)\n\t\tt.Assert(gstr.Count(w.String(), \"1234567890\"), 0)\n\t\tt.Assert(gstr.Count(w.String(), \"abcdefg\"), 0)\n\t\tt.Assert(gstr.Count(w.String(), \"1 2 3\"), 0)\n\n\t\tt.Assert(arrayForHandlerTest2.Len(), 1)\n\t\tt.Assert(gstr.Count(arrayForHandlerTest2.At(0), \"1234567890\"), 1)\n\t\tt.Assert(gstr.Count(arrayForHandlerTest2.At(0), \"abcdefg\"), 1)\n\t\tt.Assert(gstr.Count(arrayForHandlerTest2.At(0), \"1 2 3\"), 1)\n\t})\n}\n\nfunc TestLogger_SetHandlers_HandlerJson(t *testing.T) {\n\tgtest.C(t, func(t *gtest.T) {\n\t\tw := bytes.NewBuffer(nil)\n\t\tl := glog.NewWithWriter(w)\n\t\tl.SetHandlers(glog.HandlerJson)\n\t\tl.SetCtxKeys(\"Trace-Id\", \"Span-Id\", \"Test\")\n\t\tctx := context.WithValue(context.Background(), \"Trace-Id\", \"1234567890\")\n\t\tctx = context.WithValue(ctx, \"Span-Id\", \"abcdefg\")\n\n\t\tl.Debug(ctx, 1, 2, 3)\n\t\tt.Assert(gstr.Count(w.String(), \"1234567890\"), 1)\n\t\tt.Assert(gstr.Count(w.String(), \"abcdefg\"), 1)\n\t\tt.Assert(gstr.Count(w.String(), `\"1 2 3\"`), 1)\n\t\tt.Assert(gstr.Count(w.String(), `\"DEBU\"`), 1)\n\t})\n}\n\nfunc Test_SetDefaultHandler(t *testing.T) {\n\tgtest.C(t, func(t *gtest.T) {\n\t\toldHandler := glog.GetDefaultHandler()\n\t\tglog.SetDefaultHandler(func(ctx context.Context, in *glog.HandlerInput) {\n\t\t\tglog.HandlerJson(ctx, in)\n\t\t})\n\t\tdefer glog.SetDefaultHandler(oldHandler)\n\n\t\tw := bytes.NewBuffer(nil)\n\t\tl := glog.NewWithWriter(w)\n\t\tl.SetCtxKeys(\"Trace-Id\", \"Span-Id\", \"Test\")\n\t\tctx := context.WithValue(context.Background(), \"Trace-Id\", \"1234567890\")\n\t\tctx = context.WithValue(ctx, \"Span-Id\", \"abcdefg\")\n\n\t\tl.Debug(ctx, 1, 2, 3)\n\t\tt.Assert(gstr.Count(w.String(), \"1234567890\"), 1)\n\t\tt.Assert(gstr.Count(w.String(), \"abcdefg\"), 1)\n\t\tt.Assert(gstr.Count(w.String(), `\"1 2 3\"`), 1)\n\t\tt.Assert(gstr.Count(w.String(), `\"DEBU\"`), 1)\n\t})\n}\n"}
{"sample": "package postgres\n\nimport (\n\t\"fmt\"\n\t\"github.com/wzslr321/models\"\n\t\"github.com/wzslr321/settings\"\n\t\"gorm.io/driver/postgres\"\n\t\"gorm.io/gorm\"\n\t\"gorm.io/gorm/logger\"\n\t\"log\"\n\t\"os\"\n\t\"time\"\n)\n\nvar DB *gorm.DB\n\nfunc checkError(err error) {\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n}\n\nfunc InitPostgre() {\n\tvar err error\n\n\tvar newLogger = logger.New(\n\t\tlog.New(os.Stdout, \"\\r\\n\", log.LstdFlags),\n\t\tlogger.Config{\n\t\t\tSlowThreshold: time.Second,\n\t\t\tLogLevel:      logger.Silent,\n\t\t\tColorful:      true,\n\t\t},\n\t)\n\n\tvar s = settings.PostgresSettings\n\n\tdsn := fmt.Sprintf(\n\t\t\"host=%s user=%s password=%s dbname=%s port=%s sslmode=%s TimeZone=%s\",\n\t\ts.Host, s.User, s.Password, s.DBName, s.Addr, s.SSLMode, s.TimeZone,\n\t)\n\n\tDB, err = gorm.Open(postgres.New(postgres.Config{\n\t\tDSN: dsn,\n\t}), &gorm.Config{\n\t\tLogger: newLogger,\n\t})\n\tcheckError(err)\n\n\t_ = DB.AutoMigrate(\n\t\t&models.Post{},\n\t)\n\n}\n"}
{"sample": "// Code generated by go-swagger; DO NOT EDIT.\n\npackage resource_controls\n\n// This file was generated by the swagger tool.\n// Editing this file might prove futile when you re-run the swagger generate command\n\nimport (\n\t\"github.com/go-openapi/runtime\"\n\n\tstrfmt \"github.com/go-openapi/strfmt\"\n)\n\n// New creates a new resource controls API client.\nfunc New(transport runtime.ClientTransport, formats strfmt.Registry) *Client {\n\treturn &Client{transport: transport, formats: formats}\n}\n\n/*\nClient for resource controls API\n*/\ntype Client struct {\n\ttransport runtime.ClientTransport\n\tformats   strfmt.Registry\n}\n\n/*\nResourceControlCreate creates a new resource control\n\nCreate a new resource control to restrict access to a Docker resource.\n**Access policy**: restricted\n\n*/\nfunc (a *Client) ResourceControlCreate(params *ResourceControlCreateParams, authInfo runtime.ClientAuthInfoWriter) (*ResourceControlCreateOK, error) {\n\t// TODO: Validate the params before sending\n\tif params == nil {\n\t\tparams = NewResourceControlCreateParams()\n\t}\n\n\tresult, err := a.transport.Submit(&runtime.ClientOperation{\n\t\tID:                 \"ResourceControlCreate\",\n\t\tMethod:             \"POST\",\n\t\tPathPattern:        \"/resource_controls\",\n\t\tProducesMediaTypes: []string{\"application/json\"},\n\t\tConsumesMediaTypes: []string{\"application/json\"},\n\t\tSchemes:            []string{\"http\", \"https\"},\n\t\tParams:             params,\n\t\tReader:             &ResourceControlCreateReader{formats: a.formats},\n\t\tAuthInfo:           authInfo,\n\t\tContext:            params.Context,\n\t\tClient:             params.HTTPClient,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn result.(*ResourceControlCreateOK), nil\n\n}\n\n/*\nResourceControlDelete removes a resource control\n\nRemove a resource control.\n**Access policy**: restricted\n\n*/\nfunc (a *Client) ResourceControlDelete(params *ResourceControlDeleteParams, authInfo runtime.ClientAuthInfoWriter) (*ResourceControlDeleteNoContent, error) {\n\t// TODO: Validate the params before sending\n\tif params == nil {\n\t\tparams = NewResourceControlDeleteParams()\n\t}\n\n\tresult, err := a.transport.Submit(&runtime.ClientOperation{\n\t\tID:                 \"ResourceControlDelete\",\n\t\tMethod:             \"DELETE\",\n\t\tPathPattern:        \"/resource_controls/{id}\",\n\t\tProducesMediaTypes: []string{\"\"},\n\t\tConsumesMediaTypes: []string{\"\"},\n\t\tSchemes:            []string{\"http\", \"https\"},\n\t\tParams:             params,\n\t\tReader:             &ResourceControlDeleteReader{formats: a.formats},\n\t\tAuthInfo:           authInfo,\n\t\tContext:            params.Context,\n\t\tClient:             params.HTTPClient,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn result.(*ResourceControlDeleteNoContent), nil\n\n}\n\n/*\nResourceControlUpdate updates a resource control\n\nUpdate a resource control.\n**Access policy**: restricted\n\n*/\nfunc (a *Client) ResourceControlUpdate(params *ResourceControlUpdateParams, authInfo runtime.ClientAuthInfoWriter) (*ResourceControlUpdateOK, error) {\n\t// TODO: Validate the params before sending\n\tif params == nil {\n\t\tparams = NewResourceControlUpdateParams()\n\t}\n\n\tresult, err := a.transport.Submit(&runtime.ClientOperation{\n\t\tID:                 \"ResourceControlUpdate\",\n\t\tMethod:             \"PUT\",\n\t\tPathPattern:        \"/resource_controls/{id}\",\n\t\tProducesMediaTypes: []string{\"application/json\"},\n\t\tConsumesMediaTypes: []string{\"application/json\"},\n\t\tSchemes:            []string{\"http\", \"https\"},\n\t\tParams:             params,\n\t\tReader:             &ResourceControlUpdateReader{formats: a.formats},\n\t\tAuthInfo:           authInfo,\n\t\tContext:            params.Context,\n\t\tClient:             params.HTTPClient,\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn result.(*ResourceControlUpdateOK), nil\n\n}\n\n// SetTransport changes the transport on the client\nfunc (a *Client) SetTransport(transport runtime.ClientTransport) {\n\ta.transport = transport\n}\n"}
{"sample": "package object\n\nimport (\n\t\"bytes\"\n\t\"crypto/sha256\"\n\t\"errors\"\n\t\"fmt\"\n\n\t\"github.com/mr-tron/base58\"\n\t\"github.com/nspcc-dev/neofs-api-go/v2/refs\"\n)\n\n// ID represents v2-compatible object identifier.\ntype ID refs.ObjectID\n\nvar errInvalidIDString = errors.New(\"incorrect format of the string object ID\")\n\n// NewIDFromV2 wraps v2 ObjectID message to ID.\n//\n// Nil refs.ObjectID converts to nil.\nfunc NewIDFromV2(idV2 *refs.ObjectID) *ID {\n\treturn (*ID)(idV2)\n}\n\n// NewID creates and initializes blank ID.\n//\n// Works similar as NewIDFromV2(new(ObjectID)).\n//\n// Defaults:\n// \t- value: nil.\nfunc NewID() *ID {\n\treturn NewIDFromV2(new(refs.ObjectID))\n}\n\n// SetSHA256 sets object identifier value to SHA256 checksum.\nfunc (id *ID) SetSHA256(v [sha256.Size]byte) {\n\t(*refs.ObjectID)(id).SetValue(v[:])\n}\n\n// Equal returns true if identifiers are identical.\nfunc (id *ID) Equal(id2 *ID) bool {\n\treturn bytes.Equal(\n\t\t(*refs.ObjectID)(id).GetValue(),\n\t\t(*refs.ObjectID)(id2).GetValue(),\n\t)\n}\n\n// ToV2 converts ID to v2 ObjectID message.\n//\n// Nil ID converts to nil.\nfunc (id *ID) ToV2() *refs.ObjectID {\n\treturn (*refs.ObjectID)(id)\n}\n\n// Parse converts base58 string representation into ID.\nfunc (id *ID) Parse(s string) error {\n\tdata, err := base58.Decode(s)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not parse object.ID from string: %w\", err)\n\t} else if len(data) != sha256.Size {\n\t\treturn errInvalidIDString\n\t}\n\n\t(*refs.ObjectID)(id).SetValue(data)\n\n\treturn nil\n}\n\n// String returns base58 string representation of ID.\nfunc (id *ID) String() string {\n\treturn base58.Encode((*refs.ObjectID)(id).GetValue())\n}\n\n// Marshal marshals ID into a protobuf binary form.\n//\n// Buffer is allocated when the argument is empty.\n// Otherwise, the first buffer is used.\nfunc (id *ID) Marshal(b ...[]byte) ([]byte, error) {\n\tvar buf []byte\n\tif len(b) > 0 {\n\t\tbuf = b[0]\n\t}\n\n\treturn (*refs.ObjectID)(id).\n\t\tStableMarshal(buf)\n}\n\n// Unmarshal unmarshals protobuf binary representation of ID.\nfunc (id *ID) Unmarshal(data []byte) error {\n\treturn (*refs.ObjectID)(id).\n\t\tUnmarshal(data)\n}\n\n// MarshalJSON encodes ID to protobuf JSON format.\nfunc (id *ID) MarshalJSON() ([]byte, error) {\n\treturn (*refs.ObjectID)(id).\n\t\tMarshalJSON()\n}\n\n// UnmarshalJSON decodes ID from protobuf JSON format.\nfunc (id *ID) UnmarshalJSON(data []byte) error {\n\treturn (*refs.ObjectID)(id).\n\t\tUnmarshalJSON(data)\n}\n"}
{"sample": "package auth\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go/aws/credentials\"\n\tv4 \"github.com/aws/aws-sdk-go/aws/signer/v4\"\n\t\"github.com/nspcc-dev/neo-go/pkg/crypto/keys\"\n\t\"github.com/nspcc-dev/neofs-api-go/pkg/object\"\n\t\"github.com/nspcc-dev/neofs-s3-gw/creds/accessbox\"\n\t\"github.com/nspcc-dev/neofs-s3-gw/creds/tokens\"\n\t\"github.com/nspcc-dev/neofs-sdk-go/pkg/pool\"\n\t\"go.uber.org/zap\"\n)\n\n// authorizationFieldRegexp -- is regexp for credentials with Base58 encoded cid and oid and '0' (zero) as delimiter.\nvar authorizationFieldRegexp = regexp.MustCompile(`AWS4-HMAC-SHA256 Credential=(?P<access_key_id_cid>[^/]+)0(?P<access_key_id_oid>[^/]+)/(?P<date>[^/]+)/(?P<region>[^/]*)/(?P<service>[^/]+)/aws4_request,\\s*SignedHeaders=(?P<signed_header_fields>.+),\\s*Signature=(?P<v4_signature>.+)`)\n\ntype (\n\t// Center is a user authentication interface.\n\tCenter interface {\n\t\tAuthenticate(request *http.Request) (*accessbox.Box, error)\n\t}\n\n\tcenter struct {\n\t\treg *regexpSubmatcher\n\t\tcli tokens.Credentials\n\t}\n\n\t// Params stores node connection parameters.\n\tParams struct {\n\t\tPool   pool.Pool\n\t\tLogger *zap.Logger\n\t}\n\n\tprs int\n)\n\n// ErrNoAuthorizationHeader is returned for unauthenticated requests.\nvar ErrNoAuthorizationHeader = errors.New(\"no authorization header\")\n\nfunc (p prs) Read(_ []byte) (n int, err error) {\n\tpanic(\"implement me\")\n}\n\nfunc (p prs) Seek(_ int64, _ int) (int64, error) {\n\tpanic(\"implement me\")\n}\n\nvar _ io.ReadSeeker = prs(0)\n\n// New creates an instance of AuthCenter.\nfunc New(conns pool.Pool, key *keys.PrivateKey) Center {\n\treturn &center{\n\t\tcli: tokens.New(conns, key),\n\t\treg: &regexpSubmatcher{re: authorizationFieldRegexp},\n\t}\n}\n\nfunc (c *center) Authenticate(r *http.Request) (*accessbox.Box, error) {\n\tqueryValues := r.URL.Query()\n\tif queryValues.Get(\"X-Amz-Algorithm\") == \"AWS4-HMAC-SHA256\" {\n\t\treturn nil, errors.New(\"pre-signed form of request is not supported\")\n\t}\n\n\tauthHeaderField := r.Header[\"Authorization\"]\n\tif len(authHeaderField) != 1 {\n\t\treturn nil, ErrNoAuthorizationHeader\n\t}\n\n\tsms1 := c.reg.getSubmatches(authHeaderField[0])\n\tif len(sms1) != 7 {\n\t\treturn nil, errors.New(\"bad Authorization header field\")\n\t}\n\n\tsignedHeaderFieldsNames := strings.Split(sms1[\"signed_header_fields\"], \";\")\n\tif len(signedHeaderFieldsNames) == 0 {\n\t\treturn nil, errors.New(\"wrong format of signed headers part\")\n\t}\n\n\tsignatureDateTime, err := time.Parse(\"20060102T150405Z\", r.Header.Get(\"X-Amz-Date\"))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse x-amz-date header field: %w\", err)\n\t}\n\n\taccessKeyID := fmt.Sprintf(\"%s0%s\", sms1[\"access_key_id_cid\"], sms1[\"access_key_id_oid\"])\n\taccessKeyAddress := fmt.Sprintf(\"%s/%s\", sms1[\"access_key_id_cid\"], sms1[\"access_key_id_oid\"])\n\n\taddress := object.NewAddress()\n\tif err = address.Parse(accessKeyAddress); err != nil {\n\t\treturn nil, fmt.Errorf(\"could not parse AccessBox address: %s : %w\", accessKeyID, err)\n\t}\n\n\tbox, err := c.cli.GetBox(r.Context(), address)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\totherRequest := r.Clone(context.TODO())\n\totherRequest.Header = make(http.Header)\n\n\tfor key, val := range r.Header {\n\t\tfor _, name := range signedHeaderFieldsNames {\n\t\t\tif strings.EqualFold(key, name) {\n\t\t\t\totherRequest.Header[key] = val\n\t\t\t}\n\t\t}\n\t}\n\n\tawsCreds := credentials.NewStaticCredentials(accessKeyID, box.Gate.AccessKey, \"\")\n\tsigner := v4.NewSigner(awsCreds)\n\tsigner.DisableURIPathEscaping = true\n\n\t// body not required\n\tif _, err := signer.Sign(otherRequest, nil, sms1[\"service\"], sms1[\"region\"], signatureDateTime); err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to sign temporary HTTP request: %w\", err)\n\t}\n\n\tsms2 := c.reg.getSubmatches(otherRequest.Header.Get(\"Authorization\"))\n\tif sms1[\"v4_signature\"] != sms2[\"v4_signature\"] {\n\t\treturn nil, errors.New(\"failed to pass authentication procedure\")\n\t}\n\n\treturn box, nil\n}\n"}
{"sample": "package logging\n\nimport (\n\t\"context\"\n\tv1 \"github.com/ClessLi/bifrost/api/bifrost/v1\"\n\tsvcv1 \"github.com/ClessLi/bifrost/internal/bifrost/service/v1\"\n\t\"strings\"\n\t\"time\"\n)\n\ntype loggingWebServerConfigService struct {\n\tsvc svcv1.WebServerConfigService\n}\n\nfunc (l loggingWebServerConfigService) GetServerNames(ctx context.Context) (servernames *v1.ServerNames, err error) {\n\tdefer func(begin time.Time) {\n\t\tlogF := newLogFormatter(ctx, l.svc.GetServerNames)\n\t\tlogF.SetBeginTime(begin)\n\t\tdefer logF.Result()\n\t\tif servernames != nil {\n\t\t\tvar result []string\n\t\t\tfor _, serverName := range *servernames {\n\t\t\t\tresult = append(result, serverName.Name)\n\t\t\t}\n\t\t\tlogF.SetResult(\"ServerNames: \" + strings.Join(result, \", \"))\n\t\t}\n\t\tlogF.SetErr(err)\n\t}(time.Now().Local())\n\treturn l.svc.GetServerNames(ctx)\n}\n\nfunc (l loggingWebServerConfigService) Get(ctx context.Context, servername *v1.ServerName) (wsc *v1.WebServerConfig, err error) {\n\tdefer func(begin time.Time) {\n\t\tlogF := newLogFormatter(ctx, l.svc.Get)\n\t\tlogF.SetBeginTime(begin)\n\t\tdefer logF.Result()\n\t\tlogF.AddInfos(\n\t\t\t\"request server name\", servername.Name,\n\t\t)\n\t\tif wsc != nil {\n\t\t\tlogF.SetResult(getLimitResult(wsc.JsonData))\n\t\t}\n\t\tlogF.SetErr(err)\n\t}(time.Now().Local())\n\treturn l.svc.Get(ctx, servername)\n}\n\nfunc (l loggingWebServerConfigService) Update(ctx context.Context, config *v1.WebServerConfig) (err error) {\n\tdefer func(begin time.Time) {\n\t\tlogF := newLogFormatter(ctx, l.svc.Update)\n\t\tlogF.SetBeginTime(begin)\n\t\tdefer logF.Result()\n\t\tlogF.AddInfos(\n\t\t\t\"request server name\", config.ServerName.Name,\n\t\t)\n\t\tif err == nil {\n\t\t\tlogF.SetResult(\"update web server config succeeded\")\n\t\t}\n\t\tlogF.SetErr(err)\n\t}(time.Now().Local())\n\treturn l.svc.Update(ctx, config)\n}\n\nfunc newWebServerConfigMiddleware(svc svcv1.ServiceFactory) svcv1.WebServerConfigService {\n\treturn &loggingWebServerConfigService{svc: svc.WebServerConfig()}\n}\n"}
{"sample": "package command\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\n\t\"github.com/spf13/cobra\"\n)\n\nconst defaultAddress = \"http://localhost:64210/\"\n\nfunc NewHealthCmd() *cobra.Command {\n\treturn &cobra.Command{\n\t\tUse:     \"health\",\n\t\tAliases: []string{},\n\t\tShort:   \"Health check HTTP server\",\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tif len(args) > 1 {\n\t\t\t\treturn fmt.Errorf(\"Too many arguments provided, expected 0 or 1\")\n\t\t\t}\n\t\t\taddress := defaultAddress\n\t\t\tif len(args) == 1 {\n\t\t\t\taddress = args[0]\n\t\t\t}\n\t\t\thealthAddress := address + \"health\"\n\t\t\tresp, err := http.Get(healthAddress)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdefer resp.Body.Close()\n\t\t\tif resp.StatusCode != 204 {\n\t\t\t\treturn fmt.Errorf(\"/health responded with status code %d, expected 204\", resp.StatusCode)\n\t\t\t}\n\t\t\tlog.Printf(\"%s ok\", healthAddress)\n\t\t\treturn nil\n\t\t},\n\t}\n}\n"}
{"sample": "package entity\n\nimport (\n\t\"sync\"\n\n\t\"github.com/LinMAD/Snap/engine/graphics/data\"\n)\n\n// SceneObject interface represents as actor in the scene, can be anything\ntype SceneObject interface {\n\t// OnUpdate event called on each tick to update state\n\t// Make actual data updates for object here\n\tOnUpdate()\n\n\t// TODO Input event\n\n\t// GetDrawableInformation about object\n\tGetDrawableInformation() *DrawableInformation\n\t// GetPosition in the scene\n\tGetPosition() *Position\n}\n\n// DrawableInformation asset data\ntype DrawableInformation struct {\n\t// Width of image\n\tWidth uint32\n\t// Height of image\n\tHeight uint32\n\n\t// IsFlipped image flipped horizontally ?\n\tIsFlipped bool\n\n\t// TextureData about image\n\tTextureData *data.TextureData\n\n\t// FontData about text\n\tFontData *data.FontData\n\n\t// Color modifier\n\tColor *Color\n\n\t// Text name of object, or simple UI text in the screen\n\tText *Text\n}\n\n// Position in screen\ntype Position struct {\n\t// X coordinate on the screen\n\tX int32\n\t// Y coordinate on the screen\n\tY int32\n\n\tsync.Mutex\n}\n\n// Color data\ntype Color struct {\n\tRed   uint8\n\tGreen uint8\n\tBlue  uint8\n\n\tsync.Mutex\n}\n\n// Text in scene screen\ntype Text struct {\n\tTextToPrint string\n\n\tsync.Mutex\n}\n"}
{"sample": "/*\nCopyright 2019 The Tekton Authors\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\npackage resources\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/tektoncd/pipeline/pkg/apis/pipeline/v1alpha1\"\n)\n\n// ApplyParameters applies the params from a PipelineRun.Params to a PipelineSpec.\nfunc ApplyParameters(p *v1alpha1.Pipeline, pr *v1alpha1.PipelineRun) *v1alpha1.Pipeline {\n\t// This assumes that the PipelineRun inputs have been validated against what the Pipeline requests.\n\n\t// stringReplacements is used for standard single-string stringReplacements, while arrayReplacements contains arrays\n\t// that need to be further processed.\n\tstringReplacements := map[string]string{}\n\tarrayReplacements := map[string][]string{}\n\n\t// Set all the default stringReplacements\n\tfor _, p := range p.Spec.Params {\n\t\tif p.Default != nil {\n\t\t\tif p.Default.Type == v1alpha1.ParamTypeString {\n\t\t\t\tstringReplacements[fmt.Sprintf(\"params.%s\", p.Name)] = p.Default.StringVal\n\t\t\t} else {\n\t\t\t\tarrayReplacements[fmt.Sprintf(\"params.%s\", p.Name)] = p.Default.ArrayVal\n\t\t\t}\n\t\t}\n\t}\n\t// Set and overwrite params with the ones from the PipelineRun\n\tfor _, p := range pr.Spec.Params {\n\t\tif p.Value.Type == v1alpha1.ParamTypeString {\n\t\t\tstringReplacements[fmt.Sprintf(\"params.%s\", p.Name)] = p.Value.StringVal\n\t\t} else {\n\t\t\tarrayReplacements[fmt.Sprintf(\"params.%s\", p.Name)] = p.Value.ArrayVal\n\t\t}\n\t}\n\n\treturn ApplyReplacements(p, stringReplacements, arrayReplacements)\n}\n\n// ApplyReplacements replaces placeholders for declared parameters with the specified replacements.\nfunc ApplyReplacements(p *v1alpha1.Pipeline, replacements map[string]string, arrayReplacements map[string][]string) *v1alpha1.Pipeline {\n\tp = p.DeepCopy()\n\n\ttasks := p.Spec.Tasks\n\n\tfor i := range tasks {\n\t\ttasks[i].Params = replaceParamValues(tasks[i].Params, replacements, arrayReplacements)\n\t\tfor j := range tasks[i].Conditions {\n\t\t\tc := tasks[i].Conditions[j]\n\t\t\tc.Params = replaceParamValues(c.Params, replacements, arrayReplacements)\n\t\t}\n\t}\n\n\treturn p\n}\n\nfunc replaceParamValues(params []v1alpha1.Param, stringReplacements map[string]string, arrayReplacements map[string][]string) []v1alpha1.Param {\n\tfor i := range params {\n\t\tparams[i].Value.ApplyReplacements(stringReplacements, arrayReplacements)\n\t}\n\treturn params\n}\n"}
{"sample": "package pools\n\nimport (\n\tstructs \"github.com/akkeris/service-watcher-f5/structs\"\n\tutils \"github.com/akkeris/service-watcher-f5/utils\"\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"github.com/bitly/go-simplejson\"\n\t\"net/http\"\n)\n\nfunc BuildPool(appname string, port string, partition string, monitor string, nodes []string) structs.Poolspec {\n\n\tvar pool structs.Poolspec\n\tpool.Name = appname + \"-pool\"\n\tpool.Partition = partition\n\tpool.Monitor = monitor\n\tvar members []structs.Memberspec\n\n\tfor _, element := range nodes {\n\t\tvar member structs.Memberspec\n\t\tmember.Name = \"/\" + partition + \"/\" + element + \":\" + port\n\t\tmembers = append(members, member)\n\t}\n\tpool.Members = members\n\treturn pool\n\n}\n\nfunc AddPool(pool structs.Poolspec) {\n\n\tstr, err := json.Marshal(pool)\n\tif err != nil {\n\t\tfmt.Println(\"Error preparing request\")\n\t}\n\tjsonStr := []byte(string(str))\n\turlStr := utils.F5url + \"/mgmt/tm/ltm/pool\"\n\treq, _ := http.NewRequest(\"POST\", urlStr, bytes.NewBuffer(jsonStr))\n\treq.Header.Add(\"X-F5-Auth-Token\", utils.F5token)\n\treq.Header.Add(\"Content-Type\", \"application/json\")\n\tresp, err := utils.F5Client.Do(req)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\tdefer resp.Body.Close()\n\tfmt.Printf(\"%v : Add Pool %v\\n\", resp.Status, pool.Name)\n\tif resp.StatusCode > 299 {\n\t\tbodyj, _ := simplejson.NewFromReader(resp.Body)\n\t\tfmt.Println(bodyj)\n\t}\n}\nfunc DeletePool(pool structs.Poolspec) {\n\n\turlStr := utils.F5url + \"/mgmt/tm/ltm/pool/~\" + pool.Partition + \"~\" + pool.Name\n\treq, _ := http.NewRequest(\"DELETE\", urlStr, nil)\n\treq.Header.Add(\"X-F5-Auth-Token\", utils.F5token)\n\treq.Header.Add(\"Content-Type\", \"application/json\")\n\tresp, err := utils.F5Client.Do(req)\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n\tdefer resp.Body.Close()\n\tfmt.Printf(\"%v : Delete Pool %v\\n\", resp.Status, pool.Name)\n\tif resp.StatusCode > 299 {\n\t\tbodyj, _ := simplejson.NewFromReader(resp.Body)\n\t\tfmt.Println(bodyj)\n\t}\n\n}\n"}
{"sample": "package git\n\nimport \"strings\"\n\ntype GitUrl struct {\n\tProtocol string\n\tUser     string\n\tToken    string\n\tRepo     string\n}\n\nfunc (g *GitUrl) SetUser(newUser string) {\n\tif len(newUser) > 0 {\n\t\tg.User = newUser\n\t}\n}\n\nfunc (g *GitUrl) SetToken(newToken string) {\n\tif len(newToken) > 0 {\n\t\tg.Token = newToken\n\t}\n}\n\nfunc (g *GitUrl) ToUrl() string {\n\tif len(g.Token) > 0 && len(g.User) > 0 {\n\t\treturn g.Protocol + \"//\" + g.User + \":\" + g.Token + \"@\" + g.Repo\n\t}\n\tif len(g.User) > 0 {\n\t\treturn g.Protocol + \"//\" + g.User + \"@\" + g.Repo\n\t}\n\treturn g.Protocol + \"//\" + g.Repo\n}\n\nfunc NewGitUrl(url string) *GitUrl {\n\tsplittetAfterProtocol := strings.Split(url, \"//\")\n\tsplittedAfterCredentials := strings.Split(splittetAfterProtocol[1], \"@\")\n\tcredentialsSplitted := strings.Split(splittedAfterCredentials[0], \":\")\n\tif len(credentialsSplitted) == 2 {\n\t\treturn &GitUrl{\n\t\t\tsplittetAfterProtocol[0],\n\t\t\tcredentialsSplitted[0],\n\t\t\tcredentialsSplitted[1],\n\t\t\tsplittedAfterCredentials[1],\n\t\t}\n\t} else {\n\t\tif len(splittedAfterCredentials) == 2 {\n\n\t\t\treturn &GitUrl{\n\t\t\t\tsplittetAfterProtocol[0],\n\t\t\t\tsplittedAfterCredentials[0],\n\t\t\t\t\"\",\n\t\t\t\tsplittedAfterCredentials[1],\n\t\t\t}\n\t\t} else {\n\t\t\treturn &GitUrl{\n\t\t\t\tsplittetAfterProtocol[0],\n\t\t\t\t\"\",\n\t\t\t\t\"\",\n\t\t\t\tsplittedAfterCredentials[0],\n\t\t\t}\n\t\t}\n\t}\n}\n"}
{"sample": "package mutcontext\n\nimport (\n\t\"context\"\n\t\"testing\"\n)\n\nfunc TestCreateNew(t *testing.T) {\n\tparent := context.Background()\n\tctx := CreateNew(parent)\n\tm := ctx.(*mutableContext)\n\tif m.Context != parent {\n\t\tt.Error(\"invalid context\")\n\t}\n\n\t_, ok := m.Deadline()\n\tif ok {\n\t\tt.Error(\"unexpected deadline\")\n\t}\n\n\tif m.Done() != nil {\n\t\tt.Error(\"unexpected done\", m.Done())\n\t}\n\n\tif m.Err() != nil {\n\t\tt.Error(\"unexpected err\", m.Err())\n\t}\n\n\tif v := m.Value(\"unexpected\"); v != nil {\n\t\tt.Error(\"unexpected value\", v)\n\t}\n\tm.Set(\"expected\", \"foobar\")\n\tif v := m.Value(\"expected\"); v != \"foobar\" {\n\t\tt.Error(\"unexpected value\", v)\n\t}\n\tcalled := false\n\tm.SetCleanup(func() {\n\t\tcalled = true\n\t})\n\terr := m.Cancel()\n\tif err != ErrNoCancel {\n\t\tt.Error(\"incorrect error\", err)\n\t}\n\tif !called {\n\t\tt.Error(\"cleanup was not called\")\n\t}\n\tif !m.Completed() {\n\t\tt.Error(\"cancelled flag not set\")\n\t}\n}\n\nfunc TestCreateNewCancel(t *testing.T) {\n\tparent, cancel := context.WithCancel(context.Background())\n\tctx := CreateNewCancel(parent, cancel)\n\tm := ctx.(*mutableContext)\n\tif m.Context != parent {\n\t\tt.Error(\"invalid context\")\n\t}\n\tif m.CancelFunc == nil {\n\t\tt.Error(\"invalid cancel func\")\n\t}\n\terr := m.Cancel()\n\tif err != nil {\n\t\tt.Error(\"unexpected error\", err)\n\t}\n}\n"}
{"sample": "package main\n\nimport (\n\t\"context\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"os\"\n\t\"os/signal\"\n\t\"strings\"\n\t\"syscall\"\n\n\t\"github.com/BurntSushi/toml\"\n\t\"github.com/SonarBeserk/sophie-go/internal/commands\"\n\t\"github.com/SonarBeserk/sophie-go/internal/db\"\n\t\"github.com/SonarBeserk/sophie-go/internal/embed\"\n\t\"github.com/SonarBeserk/sophie-go/internal/emote\"\n\t\"github.com/SonarBeserk/sophie-go/internal/helpers\"\n\t\"github.com/bwmarrin/discordgo\"\n)\n\n// Config represents the configuration for the bot\ntype Config struct {\n\tEmotes []emote.Emote `toml:\"emote\"`\n\tGifs   []emote.Gif   `toml:\"gif\"`\n}\n\n// Variables used for command line parameters\nvar (\n\tToken        string\n\temotesFile   string\n\tdatabaseFile string\n\n\tdatabase *db.Database\n\n\tcmds map[string]commands.Func = map[string]commands.Func{\n\t\t\"emotes\": commands.HandleListEmotes,\n\t}\n\n\tdatabaseCtx embed.ContextKey = \"db\"\n)\n\nfunc init() {\n\tflag.StringVar(&Token, \"t\", \"\", \"Bot Token\")\n\tflag.StringVar(&emotesFile, \"emotes\", \"./emotes.toml\", \"Path to file containing emotes\")\n\tflag.StringVar(&databaseFile, \"db\", \"./data.db\", \"Path to database\")\n\tflag.Parse()\n}\n\nfunc main() {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tfmt.Fprintf(os.Stderr, \"Exception: %v\\n\", err)\n\t\t}\n\t}()\n\n\terr := loadEmoteMaps(emotesFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error loading emotes file %s: %v\\n\", emotesFile, err)\n\t\treturn\n\t}\n\n\tdb, err := db.OpenOrConfigureDatabase(databaseFile)\n\tif err != nil {\n\t\tfmt.Printf(\"Error loading database file %s: %v\\n\", databaseFile, err)\n\t}\n\n\tdatabase = db\n\tdefer database.Close()\n\n\t// Create a new Discord session using the provided bot token.\n\tdg, err := discordgo.New(\"Bot \" + Token)\n\tif err != nil {\n\t\tfmt.Printf(\"Error creating Discord session: %v\\n\", err)\n\t\treturn\n\t}\n\n\t// Register the messageCreate func as a callback for MessageCreate events.\n\tdg.AddHandler(messageCreate)\n\tdg.AddHandler(guildMemberUpdate)\n\n\t// Open a websocket connection to Discord and begin listening.\n\terr = dg.Open()\n\tif err != nil {\n\t\tfmt.Printf(\"Error opening connection: %v\\n\", err)\n\t\treturn\n\t}\n\n\t// Wait here until CTRL-C or other term signal is received.\n\tfmt.Println(\"Bot is now running.  Press CTRL-C to exit.\")\n\tsc := make(chan os.Signal, 1)\n\tsignal.Notify(sc, syscall.SIGINT, syscall.SIGTERM, os.Interrupt, os.Kill)\n\t<-sc\n\n\t// Cleanly close down the Discord session.\n\tdg.Close()\n}\n\nfunc loadEmoteMaps(path string) error {\n\tdata, err := ioutil.ReadFile(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tvar conf Config\n\tif _, err := toml.Decode(string(data), &conf); err != nil {\n\t\treturn err\n\t}\n\n\tfor _, emote := range conf.Emotes {\n\t\tcommands.AddEmote(emote)\n\t\tcmds[emote.Verb] = commands.HandleEmote\n\t}\n\n\tfor _, gif := range conf.Gifs {\n\t\tcommands.AddEmoteImage(gif)\n\t}\n\n\treturn nil\n}\n\n// This function will be called (due to AddHandler above) every time a new\n// message is created on any channel that the authenticated bot has access to.\nfunc messageCreate(s *discordgo.Session, m *discordgo.MessageCreate) {\n\t// Ignore all messages created by the bot itself\n\t// This isn't required in this specific example but it's a good practice.\n\tif m.Author.ID == s.State.User.ID {\n\t\treturn\n\t}\n\n\tisPrivate, err := helpers.IsPrivateChat(s, m.ChannelID)\n\tif err != nil {\n\t\tfmt.Printf(\"Error occurred verifying channel type %s %v\\n\", m.ChannelID, err)\n\t}\n\n\tif isPrivate {\n\t\tfmt.Println(\"Ignoring private chat\")\n\t\treturn\n\t}\n\n\tuserName, err := helpers.GetUserName(s, m.GuildID, s.State.User.ID)\n\tif err != nil {\n\t\tfmt.Printf(\"Error occurred determining guild username %s %v\\n\", m.GuildID, err)\n\t}\n\n\tmsgParts := strings.Split(m.Content, \" \")\n\n\tif len(msgParts) <= 1 {\n\t\treturn\n\t}\n\n\tname := strings.ToLower(msgParts[0])\n\n\tif !strings.HasPrefix(name, strings.ToLower(userName)) && !strings.HasPrefix(name, strings.ToLower(s.State.User.Username)) {\n\t\treturn\n\t}\n\n\tcmd := strings.ToLower(msgParts[1])\n\n\tc := context.Background()\n\tctx := context.WithValue(c, databaseCtx, *database)\n\n\tcmdFunc := cmds[cmd]\n\tif cmdFunc == nil {\n\t\treturn\n\t}\n\n\terr = cmdFunc(ctx, s, msgParts[1:], m.GuildID, m.Author.ID, m.ChannelID)\n\tif err != nil {\n\t\tfmt.Printf(\"Error ocurred running command: %v\", err)\n\t}\n}\n\nfunc guildMemberUpdate(s *discordgo.Session, gmu *discordgo.GuildMemberUpdate) {\n\tif gmu.User.ID == s.State.User.ID {\n\t\thelpers.ClearUsernameCacheByID(gmu.GuildID, s.State.User.ID)\n\t}\n}\n"}
{"sample": "package cointoss\n\nimport (\n\t\"testing\"\n\n\t\"github.com/igor-kupczynski/monte-carlo-exploration/montecarlo\"\n)\n\nfunc Test_cointoss_integration(t *testing.T) {\n\t// Run the cointoss game\n\tcfg := &Args{\n\t\tHistories:      10000,\n\t\tRounds:         100,\n\t\tInitialCapital: 10,\n\t}\n\texperiment := New(cfg)\n\tresults := montecarlo.Run(experiment).(*Results)\n\n\t// Verify basic properties of the results\n\tfor description, property := range map[string]func(r *Results) bool{\n\t\t\"ruin between 28% and 35% times\": func(r *Results) bool {\n\t\t\treturn r.procRuined > 28 && r.procRuined < 35\n\t\t},\n\t\t\"chance of less capital > chance of more capital\": func(r *Results) bool {\n\t\t\treturn r.summary.Below > r.summary.Above\n\t\t},\n\t\t\"lower percentiles at $0\": func(r *Results) bool {\n\t\t\treturn r.summary.Percentiles[1] == 0 &&\n\t\t\t\tr.summary.Percentiles[5] == 0 &&\n\t\t\t\tr.summary.Percentiles[10] == 0 &&\n\t\t\t\tr.summary.Percentiles[25] == 0\n\t\t},\n\t\t\"median at $10\": func(r *Results) bool {\n\t\t\treturn r.summary.Percentiles[50] == 10\n\t\t},\n\t\t\"higher percentiles with more capital\": func(r *Results) bool {\n\t\t\treturn r.summary.Percentiles[75] > 10 &&\n\t\t\t\tr.summary.Percentiles[90] > r.summary.Percentiles[75] &&\n\t\t\t\tr.summary.Percentiles[95] > r.summary.Percentiles[90] &&\n\t\t\t\tr.summary.Percentiles[99] > r.summary.Percentiles[95] &&\n\t\t\t\tr.summary.Percentiles[99] > 30\n\t\t},\n\t} {\n\t\tif !property(results) {\n\t\t\tt.Errorf(\"Property doesn't hold: %s\\nResults:\\n%s\", description, results)\n\t\t}\n\t}\n}\n"}
{"sample": "package rabbit\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/coinexchain/onvakv/store\"\n\t\"github.com/coinexchain/onvakv/store/types\"\n)\n\n// We use a new TrunkStore for transaction\ntype SimpleMultiStore struct {\n\tcache     *SimpleCacheStore\n\ttrunk     *store.TrunkStore\n}\n\n//var WatchedKey = []uint8{0x47, 0x60, 0x3, 0x0, 0x0, 0x0, 0x0, 0x0}\n//var WatchedShortKey = []uint8{0xe3, 0x7e}\n\nfunc (sms *SimpleMultiStore) GetCachedValue(key [KeySize]byte) *CachedValue {\n\tcv, status := sms.cache.GetValue(key)\n\tswitch status {\n\tcase types.JustDeleted:\n\t\treturn nil\n\tcase types.Missed:\n\t\tbz := sms.trunk.Get(key[:])\n\t\tif bz == nil {\n\t\t\treturn nil\n\t\t}\n\t\tcv := BytesToCachedValue(bz)\n\t\tsms.cache.SetValue(key, cv)\n\t\treturn cv\n\tcase types.Hit:\n\t\treturn cv\n\tdefault:\n\t\tpanic(fmt.Sprintf(\"Invalid Status %d\", status))\n\t}\n}\n\nfunc (sms *SimpleMultiStore) MustGetCachedValue(key [KeySize]byte) *CachedValue {\n\tcv, status := sms.cache.GetValue(key)\n\tif status != types.Hit {\n\t\tpanic(\"Failed to get cached value\")\n\t}\n\treturn cv\n}\n\nfunc (sms *SimpleMultiStore) SetCachedValue(key [KeySize]byte, cv *CachedValue) {\n\tcv.isDirty = true\n\tsms.cache.SetValue(key, cv)\n\tif cv.isDeleted {\n\t\tsms.trunk.PrepareForDeletion(key[:])\n\t} else {\n\t\tsms.trunk.PrepareForUpdate(key[:])\n\t}\n}\n\nfunc (sms *SimpleMultiStore) Close(writeBack bool) {\n\tif writeBack {\n\t\tsms.writeBack()\n\t}\n}\n\nfunc (sms *SimpleMultiStore) writeBack() {\n\tsms.trunk.Update(func(cache *store.CacheStore) {\n\t\tsms.cache.ScanAllEntries(func(key, value []byte, isDeleted bool) {\n\t\t\tif isDeleted {\n\t\t\t\tcache.Delete(key)\n\t\t\t} else {\n\t\t\t\tcache.Set(key, value)\n\t\t\t}\n\t\t})\n\t})\n}\n\n"}
{"sample": "package rangedbserver_test\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net\"\n\t\"time\"\n\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/status\"\n\t\"google.golang.org/grpc/test/bufconn\"\n\n\t\"github.com/inklabs/rangedb/pkg/clock/provider/sequentialclock\"\n\t\"github.com/inklabs/rangedb/pkg/grpc/rangedbpb\"\n\t\"github.com/inklabs/rangedb/pkg/grpc/rangedbserver\"\n\t\"github.com/inklabs/rangedb/pkg/jsontools\"\n\t\"github.com/inklabs/rangedb/provider/inmemorystore\"\n\t\"github.com/inklabs/rangedb/rangedbtest\"\n)\n\nfunc ExampleRangeDBServer_Save_failureResponse() {\n\t// Given\n\tinMemoryStore := inmemorystore.New(\n\t\tinmemorystore.WithClock(sequentialclock.New()),\n\t)\n\trangedbtest.BindEvents(inMemoryStore)\n\n\t// Setup gRPC server\n\tbufListener := bufconn.Listen(7)\n\tserver := grpc.NewServer()\n\tdefer server.Stop()\n\trangeDBServer, err := rangedbserver.New(rangedbserver.WithStore(inMemoryStore))\n\tPrintError(err)\n\tdefer rangeDBServer.Stop()\n\trangedbpb.RegisterRangeDBServer(server, rangeDBServer)\n\tgo func() {\n\t\tPrintError(server.Serve(bufListener))\n\t}()\n\n\t// Setup gRPC connection\n\tdialer := grpc.WithContextDialer(func(context.Context, string) (net.Conn, error) {\n\t\treturn bufListener.Dial()\n\t})\n\tconnCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer cancel()\n\tconn, err := grpc.DialContext(connCtx, \"bufnet\", dialer, grpc.WithInsecure(), grpc.WithBlock())\n\tPrintError(err)\n\tdefer Close(conn)\n\n\t// Setup gRPC client\n\trangeDBClient := rangedbpb.NewRangeDBClient(conn)\n\tctx, done := context.WithTimeout(context.Background(), 5*time.Second)\n\tdefer done()\n\trequest := &rangedbpb.SaveRequest{\n\t\tStreamName: \"thing-141b39d2b9854f8093ef79dc47dae6af\",\n\t\tEvents: []*rangedbpb.Event{\n\t\t\t{\n\t\t\t\tAggregateType: \"thing\",\n\t\t\t\tAggregateID:   \"141b39d2b9854f8093ef79dc47dae6af\",\n\t\t\t\tEventType:     \"ThingWasDone\",\n\t\t\t\tData:          `{\"id\":\"141b39d2b9854f8093ef79dc47dae6af\",\"number\":100}`,\n\t\t\t\tMetadata:      \"\",\n\t\t\t},\n\t\t\t{\n\t\t\t\tAggregateType: \"thing\",\n\t\t\t\tAggregateID:   \"141b39d2b9854f8093ef79dc47dae6af\",\n\t\t\t\tEventType:     \"ThingWasDone\",\n\t\t\t\tData:          `{invalid-json`,\n\t\t\t\tMetadata:      \"\",\n\t\t\t},\n\t\t},\n\t}\n\n\t// When\n\t_, err = rangeDBClient.Save(ctx, request)\n\tfmt.Println(err)\n\n\tfor _, detail := range status.Convert(err).Details() {\n\t\tfailureResponse := detail.(*rangedbpb.SaveFailureResponse)\n\n\t\tbody, err := json.Marshal(failureResponse)\n\t\tPrintError(err)\n\n\t\tfmt.Println(jsontools.PrettyJSON(body))\n\t}\n\n\t// Output:\n\t// rpc error: code = InvalidArgument desc = unable to read event data: invalid character 'i' looking for beginning of object key string\n\t// {\n\t//   \"Message\": \"unable to read event data: invalid character 'i' looking for beginning of object key string\"\n\t// }\n}\n"}
{"sample": "//  Copyright 2019 Google Inc. All Rights Reserved.\n//\n//  Licensed under the Apache License, Version 2.0 (the \"License\");\n//  you may not use this file except in compliance with the License.\n//  You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n//  Unless required by applicable law or agreed to in writing, software\n//  distributed under the License is distributed on an \"AS IS\" BASIS,\n//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n//  See the License for the specific language governing permissions and\n//  limitations under the License.\n\npackage param\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"strings\"\n\n\t\"google.golang.org/api/option\"\n\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/common/domain\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/common/utils/paramhelper\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/common/utils/storage\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/cli_tools/common/utils/validation\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/daisy\"\n\t\"github.com/GoogleCloudPlatform/compute-image-tools/daisy/compute\"\n)\n\n// GetProjectID gets project id from flag if exists; otherwise, try to retrieve from GCE metadata.\nfunc GetProjectID(mgce domain.MetadataGCEInterface, projectFlag string) (string, error) {\n\tif projectFlag == \"\" {\n\t\tif !mgce.OnGCE() {\n\t\t\treturn \"\", daisy.Errf(\"project cannot be determined because build is not running on GCE\")\n\t\t}\n\t\taProject, err := mgce.ProjectID()\n\t\tif err != nil || aProject == \"\" {\n\t\t\treturn \"\", daisy.Errf(\"project cannot be determined %v\", err)\n\t\t}\n\t\treturn aProject, nil\n\t}\n\treturn projectFlag, nil\n}\n\n// populateScratchBucketGcsPath validates the scratch bucket, creating a new one if not\n// provided, and returns the region of the scratch bucket. If the scratch bucket is\n// already populated, and the owning project doesn't match `project`, then an error is returned.\n// In that case, if `file` resides in the non-owned scratch bucket and `removeFileWhenScratchNotOwned`\n// is specified, then `file` is deleted from GCS.\nfunc populateScratchBucketGcsPath(scratchBucketGcsPath *string, zone string, mgce domain.MetadataGCEInterface,\n\tscratchBucketCreator domain.ScratchBucketCreatorInterface, file string, project *string,\n\tstorageClient domain.StorageClientInterface, removeFileWhenScratchNotOwned bool) (string, error) {\n\n\tscratchBucketRegion := \"\"\n\tif *scratchBucketGcsPath == \"\" {\n\t\tfallbackZone := zone\n\t\tif fallbackZone == \"\" && mgce.OnGCE() {\n\t\t\tvar err error\n\t\t\tif fallbackZone, err = mgce.Zone(); err != nil {\n\t\t\t\t// reset fallback zone if failed to get zone from running GCE\n\t\t\t\tfallbackZone = \"\"\n\t\t\t}\n\t\t}\n\n\t\tscratchBucketName, sbr, err := scratchBucketCreator.CreateScratchBucket(file, *project, fallbackZone)\n\t\tscratchBucketRegion = sbr\n\t\tif err != nil {\n\t\t\treturn \"\", daisy.Errf(\"failed to create scratch bucket: %v\", err)\n\t\t}\n\n\t\t*scratchBucketGcsPath = fmt.Sprintf(\"gs://%v/\", scratchBucketName)\n\t} else {\n\t\tscratchBucketName, err := storage.GetBucketNameFromGCSPath(*scratchBucketGcsPath)\n\t\tif err != nil {\n\t\t\treturn \"\", daisy.Errf(\"invalid scratch bucket GCS path %v\", scratchBucketGcsPath)\n\t\t}\n\n\t\tif !scratchBucketCreator.IsBucketInProject(*project, scratchBucketName) {\n\t\t\tanonymizedErrorMessage := \"Scratch bucket %q is not in project %q\"\n\n\t\t\tsubstitutions := []interface{}{scratchBucketName, *project}\n\n\t\t\tif removeFileWhenScratchNotOwned && strings.HasPrefix(file, fmt.Sprintf(\"gs://%s/\", scratchBucketName)) {\n\t\t\t\terr := storageClient.DeleteObject(file)\n\t\t\t\tif err == nil {\n\t\t\t\t\tanonymizedErrorMessage += \". Deleted %q\"\n\t\t\t\t\tsubstitutions = append(substitutions, file)\n\t\t\t\t} else {\n\t\t\t\t\tanonymizedErrorMessage += \". Failed to delete %q: %v. \" +\n\t\t\t\t\t\t\"Check with the owner of gs://%q for more information\"\n\t\t\t\t\tsubstitutions = append(substitutions, file, err, scratchBucketName)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn \"\", daisy.Errf(anonymizedErrorMessage, substitutions...)\n\t\t}\n\n\t\tscratchBucketAttrs, err := storageClient.GetBucketAttrs(scratchBucketName)\n\t\tif err == nil {\n\t\t\tscratchBucketRegion = scratchBucketAttrs.Location\n\t\t}\n\t}\n\treturn scratchBucketRegion, nil\n}\n\n// PopulateProjectIfMissing populates project id for cli tools\nfunc PopulateProjectIfMissing(mgce domain.MetadataGCEInterface, projectFlag *string) error {\n\tvar err error\n\t*projectFlag, err = GetProjectID(mgce, *projectFlag)\n\treturn err\n}\n\n// PopulateRegion populates region based on the value extracted from zone param\nfunc PopulateRegion(region *string, zone string) error {\n\taRegion, err := paramhelper.GetRegion(zone)\n\tif err != nil {\n\t\treturn err\n\t}\n\t*region = aRegion\n\treturn nil\n}\n\n// CreateComputeClient creates a new compute client\nfunc CreateComputeClient(ctx *context.Context, oauth string, ce string) (compute.Client, error) {\n\tcomputeOptions := []option.ClientOption{option.WithCredentialsFile(oauth)}\n\tif ce != \"\" {\n\t\tcomputeOptions = append(computeOptions, option.WithEndpoint(ce))\n\t}\n\n\tcomputeClient, err := compute.NewClient(*ctx, computeOptions...)\n\tif err != nil {\n\t\treturn nil, daisy.Errf(\"failed to create compute client: %v\", err)\n\t}\n\treturn computeClient, nil\n}\n\nvar fullResourceURLPrefix = \"https://www.googleapis.com/compute/[^/]*/\"\nvar fullResourceURLRegex = regexp.MustCompile(fmt.Sprintf(\"^(%s)\", fullResourceURLPrefix))\n\nfunc getResourcePath(scope string, resourceType string, resourceName string) string {\n\t// handle full URL: transform to relative URL\n\tif prefix := fullResourceURLRegex.FindString(resourceName); prefix != \"\" {\n\t\treturn strings.TrimPrefix(resourceName, prefix)\n\t}\n\n\t// handle relative (partial) URL: use it as-is\n\tif strings.Contains(resourceName, \"/\") {\n\t\treturn resourceName\n\t}\n\n\t// handle pure name: treat it as current project\n\treturn fmt.Sprintf(\"%v/%v/%v\", scope, resourceType, resourceName)\n}\n\n// GetImageResourcePath gets the resource path for an image. It will panic if either\n// projectID or imageName is invalid. To avoid panic, pre-validate using the\n// functions in the `validation` package.\nfunc GetImageResourcePath(projectID, imageName string) string {\n\tif err := validation.ValidateImageName(imageName); err != nil {\n\t\tpanic(fmt.Sprintf(\"Invalid image name %q: %v\", imageName, err))\n\t}\n\tif err := validation.ValidateProjectID(projectID); err != nil {\n\t\tpanic(fmt.Sprintf(\"Invalid projectID %q: %v\", projectID, err))\n\t}\n\treturn fmt.Sprintf(\"projects/%s/global/images/%s\", projectID, imageName)\n}\n\n// GetGlobalResourcePath gets global resource path based on either a local resource name or a path\nfunc GetGlobalResourcePath(resourceType string, resourceName string) string {\n\treturn getResourcePath(\"global\", resourceType, resourceName)\n}\n\n// GetRegionalResourcePath gets regional resource path based on either a local resource name or a path\nfunc GetRegionalResourcePath(region string, resourceType string, resourceName string) string {\n\treturn getResourcePath(fmt.Sprintf(\"regions/%v\", region), resourceType, resourceName)\n}\n\n// GetZonalResourcePath gets zonal resource path based on either a local resource name or a path\nfunc GetZonalResourcePath(zone string, resourceType string, resourceName string) string {\n\treturn getResourcePath(fmt.Sprintf(\"zones/%v\", zone), resourceType, resourceName)\n}\n"}
{"sample": "package cache_test\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"strings\"\n\n\t. \"github.com/onsi/ginkgo\"\n\t. \"github.com/onsi/gomega\"\n\n\t\"code.cloudfoundry.org/loggregator-agent/pkg/binding\"\n\t\"code.cloudfoundry.org/loggregator-agent/pkg/cache\"\n)\n\nvar _ = Describe(\"Client\", func() {\n\tvar (\n\t\tspyHTTPClient *spyHTTPClient\n\t\taddr          string\n\t\tclient        *cache.CacheClient\n\t)\n\n\tBeforeEach(func() {\n\t\tspyHTTPClient = newSpyHTTPClient()\n\t\taddr = \"https://cache.address.com\"\n\t\tclient = cache.NewClient(addr, spyHTTPClient)\n\t})\n\n\tIt(\"returns bindings from the cache\", func() {\n\t\tbindings := []binding.Binding{\n\t\t\t{\n\t\t\t\tAppID:    \"app-id-1\",\n\t\t\t\tDrains:   []string{\"drain-1\"},\n\t\t\t\tHostname: \"host-1\",\n\t\t\t},\n\t\t}\n\n\t\tj, err := json.Marshal(bindings)\n\t\tExpect(err).ToNot(HaveOccurred())\n\t\tspyHTTPClient.response = &http.Response{\n\t\t\tStatusCode: http.StatusOK,\n\t\t\tBody:       ioutil.NopCloser(bytes.NewReader(j)),\n\t\t}\n\n\t\tExpect(client.Get()).To(Equal(bindings))\n\t\tExpect(spyHTTPClient.requestURL).To(Equal(\"https://cache.address.com/bindings\"))\n\t})\n\n\tIt(\"returns empty bindings if an HTTP error occurs\", func() {\n\t\tspyHTTPClient.err = errors.New(\"http error\")\n\n\t\t_, err := client.Get()\n\n\t\tExpect(err).To(MatchError(\"http error\"))\n\t})\n\n\tIt(\"returns empty bindings if cache returns a non-OK status code\", func() {\n\t\tspyHTTPClient.response = &http.Response{\n\t\t\tStatusCode: http.StatusInternalServerError,\n\t\t\tBody:       ioutil.NopCloser(strings.NewReader(\"\")),\n\t\t}\n\n\t\t_, err := client.Get()\n\n\t\tExpect(err).To(MatchError(\"unexpected http response from binding cache: 500\"))\n\t})\n})\n\ntype spyHTTPClient struct {\n\tresponse   *http.Response\n\trequestURL string\n\terr        error\n}\n\nfunc newSpyHTTPClient() *spyHTTPClient {\n\treturn &spyHTTPClient{}\n}\n\nfunc (s *spyHTTPClient) Get(url string) (*http.Response, error) {\n\ts.requestURL = url\n\treturn s.response, s.err\n}\n"}
{"sample": "package value\n\nimport (\n\t\"strconv\"\n\t\"strings\"\n)\n\ntype compareIntFunc func(a, b int64) bool\n\n// IntSlice holds a slice of int64 values\ntype IntSlice struct {\n\tvalsPtr *[]int64\n}\n\n// NewIntSlice makes a new IntSlice with the given int64 values.\nfunc NewIntSlice(vals ...int64) *IntSlice {\n\tslice := make([]int64, len(vals))\n\n\tcopy(slice, vals)\n\n\treturn &IntSlice{valsPtr: &slice}\n}\n\n// NewIntSliceFromPtr makes a new IntSlice with the given pointer to int64 values.\nfunc NewIntSliceFromPtr(valsPtr *[]int64) *IntSlice {\n\treturn &IntSlice{valsPtr: valsPtr}\n}\n\n// Set changes the int64 values.\nfunc (v *IntSlice) Set(vals []int64) { *v.valsPtr = vals }\n\n// Type return TypeInt.\nfunc (v *IntSlice) Type() Type { return TypeInt }\n\n// IsSlice returns true.\nfunc (v *IntSlice) IsSlice() bool { return true }\n\n// Clone produce a clone that is identical except for the backing pointer.\nfunc (v *IntSlice) Clone() Value { return NewIntSlice(*v.valsPtr...) }\n\n// Parse sets the values from the given string.\nfunc (v *IntSlice) Parse(str string) error {\n\tsubstrings := strings.Split(str, \",\")\n\tvals := make([]int64, len(substrings))\n\n\tfor i := 0; i < len(substrings); i++ {\n\t\tsubstr := strings.TrimSpace(substrings[i])\n\n\t\tval, err := strconv.ParseInt(substr, 10, 64)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tvals[i] = val\n\t}\n\n\t*v.valsPtr = vals\n\n\treturn nil\n}\n\n// SlicePointer returns the pointer for storage of slice values.\nfunc (v *IntSlice) SlicePointer() interface{} { return v.valsPtr }\n\n// Slice returns the int64 slice values.\nfunc (v *IntSlice) Slice() interface{} { return *v.valsPtr }\n\n// Len returns the number of slice elements.\nfunc (v *IntSlice) Len() int { return len(*v.valsPtr) }\n\n// Equal checks if length and values of given slice equal the current.\n// Returns a non-nil error if types do not match.\nfunc (v *IntSlice) Equal(v2 Slice) (bool, error) {\n\tif err := CheckType(TypeInt, v2.Type()); err != nil {\n\t\treturn false, err\n\t}\n\n\tvals1 := *v.valsPtr\n\tvals2 := v2.Slice().([]int64)\n\n\tif len(vals1) != len(vals2) {\n\t\treturn false, nil\n\t}\n\n\tfor i, val1 := range vals1 {\n\t\tif val1 != vals2[i] {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\n\treturn true, nil\n}\n\n// Greater checks if all values of the current slice are greater than that of\n// the given single.\n// Returns a non-nil error if types do not match.\nfunc (v *IntSlice) Greater(v2 Single) (bool, error) {\n\treturn compareInts(*v.valsPtr, v2, intGreater)\n}\n\n// GreaterEqual checks if all values of the current slice are greater or equal\n// to the given single.\n// Returns a non-nil error if types do not match.\nfunc (v *IntSlice) GreaterEqual(v2 Single) (bool, error) {\n\treturn compareInts(*v.valsPtr, v2, intGreaterEqual)\n}\n\n// Less checks if all values of the current slice are less than that of\n// the given single.\n// Returns a non-nil error if types do not match.\nfunc (v *IntSlice) Less(v2 Single) (bool, error) {\n\treturn compareInts(*v.valsPtr, v2, intLess)\n}\n\n// LessEqual checks if all values of the current slice are less or equal\n// to the given single.\n// Returns a non-nil error if types do not match.\nfunc (v *IntSlice) LessEqual(v2 Single) (bool, error) {\n\treturn compareInts(*v.valsPtr, v2, intLessEqual)\n}\n\n// Contains checks if the given single value is equal to one of the\n// current slice values.\n// Returns a non-nil error if types do not match.\nfunc (v *IntSlice) Contains(v2 Single) (bool, error) {\n\tif err := CheckType(TypeInt, v2.Type()); err != nil {\n\t\treturn false, err\n\t}\n\n\tvals := *v.valsPtr\n\tval2 := v2.Value().(int64)\n\n\tfor _, val1 := range vals {\n\t\tif val1 == val2 {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\nfunc compareInts(vals []int64, v2 Single, f compareIntFunc) (bool, error) {\n\tif err := CheckType(TypeInt, v2.Type()); err != nil {\n\t\treturn false, err\n\t}\n\n\tif len(vals) == 0 {\n\t\treturn false, nil\n\t}\n\n\tval2 := v2.Value().(int64)\n\n\tfor _, val1 := range vals {\n\t\tif !f(val1, val2) {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}\n\nfunc intGreater(a, b int64) bool {\n\treturn a > b\n}\n\nfunc intGreaterEqual(a, b int64) bool {\n\treturn a >= b\n}\n\nfunc intLess(a, b int64) bool {\n\treturn a < b\n}\n\nfunc intLessEqual(a, b int64) bool {\n\treturn a <= b\n}\n"}
{"sample": "package test\n\nimport (\n\t\"fmt\"\n\t\"github.com/lmendes86/Kalbi/sip/message\"\n\t\"github.com/lmendes86/Kalbi/authentication\"\n\t\"testing\"\n)\n\nfunc TestSIPParser(t *testing.T) {\n\tbyteMsg := []byte(msg)\n\tx := message.Parse(byteMsg)\n\n\tfmt.Println(authentication.MD5Challange(\"02922401513\", \"thevoicefactory.co.uk\", \"Chuckie93@\", \"sip:thevoicefactory.co.uk\", \"BroadWorksXiv8la38lT5rbw3uBW\", \"slmssmsf\", \"00000001\", \"auth\", \"REGISTER\"))\n\t\n\tif string(x.Req.Method) != \"INVITE\" {\n\t\tt.Error(\"Method line not parsed\")\n\t}\n}\n"}
{"sample": "package main\n\nimport (\n\t\"io\"\n\t\"log\"\n\t\"net\"\n\t\"os\"\n)\n\nfunc main() {\n\tif len(os.Args) != 3 {\n\t\tlog.Fatal(\"expected two arguments; the listen and destination addresses\")\n\t}\n\n\tlistenAddr := os.Args[1]\n\tpeerAddr := os.Args[2]\n\n\tln, err := net.Listen(\"tcp\", listenAddr)\n\tif err != nil {\n\t\tlog.Fatal(err)\n\t}\n\n\tfor {\n\t\tc, err := ln.Accept()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"Error accepting connection: %s\", err)\n\t\t\tcontinue\n\t\t}\n\n\t\tgo proxy(c, peerAddr)\n\t}\n}\n\nfunc proxy(c net.Conn, peerAddr string) {\n\tlog.Printf(\"Incomming connection from %s\", c.RemoteAddr())\n\tlog.Printf(\"Connecting to %s\", peerAddr)\n\n\tr, err := net.Dial(\"tcp\", peerAddr)\n\tif err != nil {\n\t\tlog.Printf(\"Error connecting to peer: %s\", err)\n\t\tc.Close()\n\t\treturn\n\t}\n\n\tlog.Printf(\"Proxying connection...\")\n\tgo func() {\n\t\tio.Copy(c, r)\n\t\tc.Close()\n\t}()\n\n\tgo func() {\n\t\tio.Copy(r, c)\n\t\tr.Close()\n\t}()\n}\n"}
{"sample": "package frapi\n\nimport (\n\t\"fmt\"\n\t\"sort\"\n\n\t\"github.com/bjorge/friendlyreservations/frdate\"\n)\n\nconst membershipStatusConstraintsGQL = `\n\nenum MembershipState {\n\t# membership has not been purchased or set to opt out\n\tOPEN\n\t# membership has been purchased\n\tPURCHASED\n\t# user has opted out\n\tOPTOUT\n}\n\ntype MembershipStatusConstraintsRecord {\n\tstatus: MembershipState!\n\tinfo: RestrictionRecord!\n\treservationCount: Int!\n\t# cannot opt out if reservations exist\n\toptOutAllowed: Boolean!\n\t# cannot purchase if over minimum balance\n\tpurchaseAllowed: Boolean!\n}\n\ntype MembershipStatusConstraints {\n\tuser: User!\n\tmemberships: [MembershipStatusConstraintsRecord]!\n}\n\n`\n\ntype membershipStatusConstraintsArgs struct {\n\tUserID     *string\n\tMaxVersion *int32\n}\n\n// MembershipStatusConstraints is called by the GQL framewor, see contentGQL\nfunc (r *PropertyResolver) MembershipStatusConstraints(args *membershipStatusConstraintsArgs) ([]*MembershipStatusConstraintsResolver, error) {\n\n\t// validate input\n\tif args.UserID != nil {\n\t\tusers := r.Users(&usersArgs{UserID: args.UserID})\n\t\tif len(users) != 1 {\n\t\t\treturn nil, fmt.Errorf(\"user for id %+v not found\", *args.UserID)\n\t\t}\n\t}\n\n\tif args.MaxVersion != nil {\n\t\tif *args.MaxVersion < 0 {\n\t\t\treturn nil, fmt.Errorf(\"maxVersion cannot be less than 0\")\n\t\t}\n\t}\n\n\t// rollup\n\tr.rollupMembershipStatus()\n\n\t// resolve\n\treturn r.resolveMembershipStatus(args)\n}\n\n// UserMembershipRecord contains the information for resolving a user membership\ntype UserMembershipRecord struct {\n\trestrictionID    string\n\tuserID           string\n\tstatus           MembershipState\n\tinDate           *frdate.Date\n\toutDate          *frdate.Date\n\tprePayStartDate  *frdate.Date\n\tpurchaseAllowed  *bool\n\toptOutAllowed    *bool\n\treservationCount int\n}\n\n// MembershipRecordResolver resolves one of the memberships for a user\ntype MembershipRecordResolver struct {\n\tmembership *UserMembershipRecord\n\tproperty   *PropertyResolver\n\tuserID     string\n}\n\n// MembershipStatusConstraintsResolver resolves the memberships for a user\ntype MembershipStatusConstraintsResolver struct {\n\tuserID         string\n\tallMemberShips []*UserMembershipRecord\n\tproperty       *PropertyResolver\n}\n\n// Memberships is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipStatusConstraintsResolver) Memberships() []*MembershipRecordResolver {\n\n\tresolvers := []*MembershipRecordResolver{}\n\tfor _, membership := range r.allMemberShips {\n\t\tresolver := &MembershipRecordResolver{}\n\t\tresolver.membership = membership\n\t\tresolver.property = r.property\n\t\tresolver.userID = r.userID\n\t\tresolvers = append(resolvers, resolver)\n\t}\n\n\t// descending order so that newest on the top of the list\n\tsort.Slice(resolvers, func(i, j int) bool {\n\t\treturn resolvers[i].membership.inDate.After(resolvers[j].membership.inDate)\n\t})\n\treturn resolvers\n}\n\n// User is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipStatusConstraintsResolver) User() *UserResolver {\n\tusers := r.property.Users(&usersArgs{UserID: &r.userID})\n\treturn users[0]\n}\n\n// Info is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipRecordResolver) Info() *RestrictionRecordResolver {\n\trestrictions, _ := r.property.Restrictions(&restrictionsArgs{RestrictionID: &r.membership.restrictionID})\n\treturn restrictions[0]\n}\n\n// Status is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipRecordResolver) Status() MembershipState {\n\treturn r.membership.status\n}\n\n// ReservationCount is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipRecordResolver) ReservationCount() int32 {\n\treturn int32(r.membership.reservationCount)\n}\n\nvar bFalse = false\nvar bTrue = true\n\n// OptOutAllowed is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipRecordResolver) OptOutAllowed() bool {\n\treturn *r.membership.optOutAllowed\n}\nfunc setOptOutAllowed(allMemberShips []*UserMembershipRecord) {\n\n\tfoundOpen := false\n\tfor _, resolver := range allMemberShips {\n\t\tif foundOpen {\n\t\t\t// don't allow updates after first OPEN record\n\t\t\tresolver.optOutAllowed = &bFalse\n\t\t} else {\n\t\t\tswitch resolver.status {\n\t\t\tcase OPEN:\n\t\t\t\tif !foundOpen {\n\t\t\t\t\tfoundOpen = true\n\t\t\t\t\tresolver.optOutAllowed = &bTrue\n\t\t\t\t}\n\t\t\tcase OPTOUT:\n\t\t\t\tresolver.optOutAllowed = &bFalse\n\t\t\tcase PURCHASED:\n\t\t\t\tresolver.optOutAllowed = &bTrue\n\t\t\tdefault:\n\t\t\t\tresolver.optOutAllowed = &bFalse\n\t\t\t}\n\t\t}\n\t\tif resolver.reservationCount > 0 {\n\t\t\tresolver.optOutAllowed = &bFalse\n\t\t}\n\t}\n}\n\n// PurchaseAllowed is called by the GQL framework, see membershipStatusGQL\nfunc setPurchaseAllowed(lowBalance bool, allMemberShips []*UserMembershipRecord, today *frdate.Date) {\n\n\tfoundOpen := false\n\tfor _, resolver := range allMemberShips {\n\t\tif foundOpen {\n\t\t\t// don't allow updates after first OPEN record\n\t\t\tresolver.purchaseAllowed = &bFalse\n\t\t} else {\n\t\t\tswitch resolver.status {\n\t\t\tcase OPEN:\n\t\t\t\tresolver.purchaseAllowed = &bTrue\n\t\t\t\tif !foundOpen {\n\t\t\t\t\tfoundOpen = true\n\t\t\t\t}\n\t\t\tcase OPTOUT:\n\t\t\t\tresolver.purchaseAllowed = &bTrue\n\t\t\tcase PURCHASED:\n\t\t\t\tresolver.purchaseAllowed = &bFalse\n\t\t\t}\n\t\t}\n\t\t// if before prepay start, then not allowed\n\t\tif today.Before(resolver.prePayStartDate) || lowBalance {\n\t\t\tresolver.purchaseAllowed = &bFalse\n\t\t}\n\t}\n\n}\n\n// PurchaseAllowed is called by the GQL framework, see membershipStatusGQL\nfunc (r *MembershipRecordResolver) PurchaseAllowed() bool {\n\treturn *r.membership.purchaseAllowed\n}\n\nfunc (r *PropertyResolver) resolveMembershipStatus(args *membershipStatusConstraintsArgs) ([]*MembershipStatusConstraintsResolver, error) {\n\n\t// get all the rollups\n\tversionedRollups := r.getRollups(&rollupArgs{maxVersion: args.MaxVersion}, membershipStatusRollupType)\n\n\t// get a datebuilder from the property timezone\n\tsettings, err := r.Settings(&settingsArgs{})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdateBuilder := frdate.MustNewDateBuilder(settings.Timezone())\n\n\t// calculate the number of reservations per membership period per user\n\treservations, err := r.Reservations(&reservationsArgs{Order: ASCENDING, MaxVersion: args.MaxVersion})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// userID -> membershipID -> count\n\treservationCountMap := make(map[string]map[string]int)\n\tfor _, reservation := range reservations {\n\t\tif reservation.Canceled() {\n\t\t\tcontinue\n\t\t}\n\t\trInDate := dateBuilder.MustNewDate(reservation.StartDate())\n\t\trOutDate := dateBuilder.MustNewDate(reservation.EndDate())\n\t\tfor _, versionedRollup := range versionedRollups {\n\t\t\trollup := versionedRollup.(*MembershipRollupRecord)\n\t\t\tmInDate := dateBuilder.MustNewDate(rollup.InDate)\n\t\t\tmOutDate := dateBuilder.MustNewDate(rollup.OutDate)\n\t\t\tif frdate.DateOverlap(rInDate, rOutDate, mInDate, mOutDate) {\n\t\t\t\tuID := reservation.ReservedFor().UserID()\n\t\t\t\tif _, ok := reservationCountMap[uID]; !ok {\n\t\t\t\t\treservationCountMap[uID] = make(map[string]int)\n\t\t\t\t}\n\t\t\t\tmID := rollup.RestrictionID\n\t\t\t\tif _, ok := reservationCountMap[uID][mID]; !ok {\n\t\t\t\t\treservationCountMap[uID][mID] = 0\n\t\t\t\t}\n\t\t\t\treservationCountMap[uID][mID]++\n\t\t\t}\n\t\t}\n\t}\n\n\t// get all the users\n\tusers := r.Users(&usersArgs{})\n\n\tresolvers := []*MembershipStatusConstraintsResolver{}\n\n\t// for each user...\n\tfor _, user := range users {\n\t\t// return only a single user\n\t\tif args.UserID != nil {\n\t\t\tif user.UserID() != *args.UserID {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tresolver := &MembershipStatusConstraintsResolver{}\n\t\tresolver.userID = user.UserID()\n\t\tresolver.property = r\n\n\t\tfor _, versionedRollup := range versionedRollups {\n\t\t\trollup := versionedRollup.(*MembershipRollupRecord)\n\n\t\t\trecord := &UserMembershipRecord{}\n\t\t\trecord.userID = resolver.userID\n\t\t\trecord.restrictionID = rollup.RestrictionID\n\t\t\trecord.inDate = dateBuilder.MustNewDate(rollup.InDate)\n\t\t\trecord.outDate = dateBuilder.MustNewDate(rollup.OutDate)\n\t\t\trecord.prePayStartDate = dateBuilder.MustNewDate(rollup.PrePayStartDate)\n\n\t\t\tif status, ok := rollup.Users[user.UserID()]; ok {\n\t\t\t\trecord.status = status\n\t\t\t} else {\n\t\t\t\trecord.status = OPEN\n\t\t\t}\n\n\t\t\t// set the reservation count in the record\n\t\t\tif count, ok := reservationCountMap[resolver.userID][record.restrictionID]; ok {\n\t\t\t\trecord.reservationCount = count\n\t\t\t} else {\n\t\t\t\trecord.reservationCount = 0\n\t\t\t}\n\n\t\t\tresolver.allMemberShips = append(resolver.allMemberShips, record)\n\t\t}\n\n\t\tif len(resolver.allMemberShips) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\tsort.Slice(resolver.allMemberShips, func(i, j int) bool {\n\t\t\treturn resolver.allMemberShips[i].inDate.Before(resolver.allMemberShips[j].inDate)\n\t\t})\n\n\t\tsetOptOutAllowed(resolver.allMemberShips)\n\n\t\tledgers, err := r.Ledgers(&ledgersArgs{Reverse: &bTrue, UserID: &resolver.userID})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tbalance := ledgers[0].Records()[0].balanceInternal().Raw()\n\t\tminBalance := settings.minBalanceInternal().Raw()\n\n\t\tsetPurchaseAllowed(balance < minBalance, resolver.allMemberShips, dateBuilder.Today())\n\n\t\tresolvers = append(resolvers, resolver)\n\n\t}\n\n\treturn resolvers, nil\n}\n"}
{"sample": "package mapper_test\n\nimport (\n\t\"testing\"\n\n\t\"github.com/microsoft/abstrakt/internal/platform/mapper\"\n\t\"github.com/stretchr/testify/assert\"\n)\n\nfunc TestFindByName(t *testing.T) {\n\tmapper := new(mapper.Config)\n\n\terr := mapper.LoadFile(\"testdata/mapper.yaml\")\n\tassert.NoError(t, err)\n\n\tinfo := mapper.FindByName(\"event_hub_sample_event_generator\")\n\n\tassert.NotNil(t, info)\n\tassert.Equal(t, \"event_hub_sample_event_generator\", info.ChartName)\n\tassert.Equal(t, \"EventGenerator\", info.Type)\n\tassert.Equal(t, \"../../helm/basictest\", info.Location)\n\tassert.Equal(t, \"1.0.0\", info.Version)\n\n\tinfo = mapper.FindByName(\"event_hub_sample_event_logger\")\n\n\tassert.NotNil(t, info)\n\tassert.Equal(t, \"event_hub_sample_event_logger\", info.ChartName)\n\tassert.Equal(t, \"EventLogger\", info.Type)\n\tassert.Equal(t, \"../../helm/basictest2\", info.Location)\n\tassert.Equal(t, \"1.0.0\", info.Version)\n\n\tinfo = mapper.FindByName(\"event_hub_sample_event_hub\")\n\n\tassert.NotNil(t, info)\n\tassert.Equal(t, \"event_hub_sample_event_hub\", info.ChartName)\n\tassert.Equal(t, \"EventHub\", info.Type)\n\tassert.Equal(t, \"../../helm/basictest3\", info.Location)\n\tassert.Equal(t, \"1.0.0\", info.Version)\n}\n\nfunc TestFindByType(t *testing.T) {\n\tmapper := new(mapper.Config)\n\n\terr := mapper.LoadFile(\"testdata/mapper.yaml\")\n\tassert.NoError(t, err)\n\n\tinfo := mapper.FindByType(\"EventGenerator\")\n\n\tassert.NotNil(t, info)\n\tassert.Equal(t, \"event_hub_sample_event_generator\", info.ChartName)\n\tassert.Equal(t, \"EventGenerator\", info.Type)\n\tassert.Equal(t, \"../../helm/basictest\", info.Location)\n\tassert.Equal(t, \"1.0.0\", info.Version)\n\n\tinfo = mapper.FindByType(\"EventLogger\")\n\n\tassert.NotNil(t, info)\n\tassert.Equal(t, \"event_hub_sample_event_logger\", info.ChartName)\n\tassert.Equal(t, \"EventLogger\", info.Type)\n\tassert.Equal(t, \"../../helm/basictest2\", info.Location)\n\tassert.Equal(t, \"1.0.0\", info.Version)\n\n\tinfo = mapper.FindByType(\"EventHub\")\n\n\tassert.NotNil(t, info)\n\tassert.Equal(t, \"event_hub_sample_event_hub\", info.ChartName)\n\tassert.Equal(t, \"EventHub\", info.Type)\n\tassert.Equal(t, \"../../helm/basictest3\", info.Location)\n\tassert.Equal(t, \"1.0.0\", info.Version)\n}\n\nfunc TestDuplicateChartNamePass(t *testing.T) {\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/mapper.yaml\")\n\tassert.NoError(t, err)\n\n\tduplicate := testData.FindDuplicateChartName()\n\tassert.Nil(t, duplicate)\n}\n\nfunc TestDuplicateTypesPass(t *testing.T) {\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/mapper.yaml\")\n\tassert.NoError(t, err)\n\n\tduplicate := testData.FindDuplicateType()\n\tassert.Nil(t, duplicate)\n}\n\nfunc TestDuplicateLocationsPass(t *testing.T) {\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/mapper.yaml\")\n\tassert.NoError(t, err)\n\n\tduplicate := testData.FindDuplicateLocation()\n\tassert.Nil(t, duplicate)\n}\n\nfunc TestSchemaFailMissingChartNameValue(t *testing.T) {\n\texpected := \"Validation error in field \\\"ChartName\\\" of type \\\"string\\\" using validator \\\"empty=false\\\"\"\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/missing/chartNameValue.yaml\")\n\tassert.NoError(t, err)\n\n\terr = testData.ValidateModel()\n\tassert.Error(t, err, \"Model validation should return error\")\n\tassert.EqualError(t, err, expected, \"Model validation should return error\")\n}\n\nfunc TestSchemaFailMissingVersionProperty(t *testing.T) {\n\texpected := \"Validation error in field \\\"Version\\\" of type \\\"string\\\" using validator \\\"empty=false\\\"\"\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/missing/versionProperty.yaml\")\n\tassert.NoError(t, err)\n\n\terr = testData.ValidateModel()\n\tassert.Error(t, err, \"Model validation should return error\")\n\tassert.EqualError(t, err, expected, \"Model validation should return error\")\n}\n\nfunc TestSchemaFailMissingMap(t *testing.T) {\n\texpected := \"Validation error in field \\\"Maps\\\" of type \\\"[]mapper.Info\\\" using validator \\\"empty=false\\\"\"\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/missing/map.yaml\")\n\tassert.NoError(t, err)\n\n\terr = testData.ValidateModel()\n\tassert.Error(t, err, \"Model validation should return error\")\n\tassert.EqualError(t, err, expected, \"Model validation should return error\")\n}\n\nfunc TestDuplicateChartName(t *testing.T) {\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/duplicate/chartNames.yaml\")\n\tassert.NoError(t, err)\n\n\terr = testData.ValidateModel()\n\tassert.NoError(t, err, \"Model validation should not return error\")\n\n\tduplicate := testData.FindDuplicateChartName()\n\tassert.NotNil(t, duplicate)\n\tassert.Equal(t, 2, len(duplicate))\n\tassert.Equal(t, \"event_hub_sample_event_generator\", duplicate[0])\n}\n\nfunc TestDuplicateTypes(t *testing.T) {\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/duplicate/types.yaml\")\n\tassert.NoError(t, err)\n\n\terr = testData.ValidateModel()\n\tassert.NoError(t, err, \"Model validation should not return error\")\n\n\tduplicate := testData.FindDuplicateType()\n\tassert.NotNil(t, duplicate)\n\tassert.Equal(t, 2, len(duplicate))\n\tassert.Equal(t, \"EventHub\", duplicate[0])\n}\n\nfunc TestDuplicateLocation(t *testing.T) {\n\ttestData := new(mapper.Config)\n\n\terr := testData.LoadFile(\"testdata/duplicate/locations.yaml\")\n\tassert.NoError(t, err)\n\n\terr = testData.ValidateModel()\n\tassert.NoError(t, err, \"Model validation should not return error\")\n\n\tduplicate := testData.FindDuplicateLocation()\n\tassert.NotNil(t, duplicate)\n\tassert.Equal(t, 2, len(duplicate))\n\tassert.Equal(t, \"../../helm/basictest\", duplicate[0])\n}\n"}
{"sample": "package main\n\nimport (\n\t\"bufio\"\n\t\"fmt\"\n\t\"math\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n)\n\nfunc sum(arr []int) int {\n\tsum := 0\n\n\tfor _, a := range arr {\n\t\tsum += a\n\t}\n\n\treturn sum\n}\n\nfunc findSumSign(op string) int {\n\tfor i, t := range op {\n\t\tif t == '+' {\n\t\t\treturn i\n\t\t}\n\t}\n\n\treturn -1\n}\n\nfunc getLastNumber(op string) (int, int) {\n\tterms := strings.Split(op, \" \")\n\tnumber, _ := strconv.Atoi(terms[len(terms)-1])\n\n\treturn number, int(math.Log10(float64(number))) + 1\n}\n\nfunc getFirstNumber(op string) (int, int) {\n\tterms := strings.Split(op, \" \")\n\tnumber, _ := strconv.Atoi(terms[0])\n\n\treturn number, int(math.Log10(float64(number))) + 1\n}\n\nfunc evaluateSums(op string) string {\n\tfor strings.Count(op, \"+\") != 0 {\n\t\tsum := findSumSign(op)\n\n\t\tnum1, digits1 := getLastNumber(op[:sum-1])\n\t\tnum2, digits2 := getFirstNumber(op[sum+2:])\n\n\t\tpartial := num1 + num2\n\n\t\top = op[:sum-1-digits1] + strconv.Itoa(partial) + op[sum+2+digits2:]\n\t}\n\n\treturn op\n}\n\nfunc evaluateArithmetic(op string, level int) int {\n\tif level == 1 {\n\t\tterms := strings.Split(op, \" \")\n\t\tresult, _ := strconv.Atoi(terms[0])\n\n\t\tfor i := 1; i < len(terms); i += 2 {\n\t\t\tif terms[i] == \"+\" {\n\t\t\t\tnum, _ := strconv.Atoi(terms[i+1])\n\t\t\t\tresult += num\n\t\t\t}\n\n\t\t\tif terms[i] == \"*\" {\n\t\t\t\tnum, _ := strconv.Atoi(terms[i+1])\n\t\t\t\tresult *= num\n\t\t\t}\n\t\t}\n\n\t\treturn result\n\t}\n\n\top = evaluateSums(op)\n\n\tterms := strings.Split(op, \" \")\n\tresult, _ := strconv.Atoi(terms[0])\n\n\tfor i := 1; i < len(terms); i += 2 {\n\t\tif terms[i] == \"*\" {\n\t\t\tnum, _ := strconv.Atoi(terms[i+1])\n\t\t\tresult *= num\n\t\t}\n\t}\n\n\treturn result\n}\n\nfunc findMostInnerParentheses(op string) (int, int) {\n\topening, closing := -1, -1\n\n\tfor i, t := range op {\n\t\tif t == '(' {\n\t\t\topening = i\n\t\t}\n\n\t\tif t == ')' {\n\t\t\tclosing = i\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn opening, closing\n}\n\nfunc evaluate(op string, level int) int {\n\tfor strings.Count(op, \"(\") > 0 {\n\t\topening, closing := findMostInnerParentheses(op)\n\n\t\tpartial := evaluateArithmetic(op[opening+1:closing], level)\n\n\t\top = op[:opening] + strconv.Itoa(partial) + op[closing+1:]\n\t}\n\n\treturn evaluateArithmetic(op, level)\n}\n\nfunc main() {\n\tfile, _ := os.Open(\"input.txt\")\n\n\tdefer file.Close()\n\n\tscanner := bufio.NewScanner(file)\n\tvar operations []string\n\n\tfor scanner.Scan() {\n\t\toperations = append(operations, scanner.Text())\n\t}\n\n\tvar results1 []int\n\n\tfor _, op := range operations {\n\t\tresults1 = append(results1, evaluate(op, 1))\n\t}\n\n\tfmt.Printf(\"Sum of all operations (1): %d\\n\", sum(results1))\n\n\tvar results2 []int\n\n\tfor _, op := range operations {\n\t\tresults2 = append(results2, evaluate(op, 2))\n\t}\n\n\tfmt.Printf(\"Sum of all operations (2): %d\\n\", sum(results2))\n}\n"}
{"sample": "package nodes\n\nimport (\n\t\"fmt\"\n\t\"text/scanner\"\n)\n\ntype Scope struct {\n\tAt     scanner.Position\n\tParent *Scope\n\n\tVariables []*Variable\n\n\tChildren []*Scope\n}\n\nfunc (self *Scope) Position() scanner.Position {\n\treturn self.At\n}\n\nfunc (self *Scope) Clone(at scanner.Position) *Scope {\n\tscope := &Scope{\n\t\tAt:     at,\n\t\tParent: self,\n\n\t\tVariables: append([]*Variable(nil), self.Variables...),\n\t}\n\tself.Children = append(self.Children, scope)\n\treturn scope\n}\n\nfunc (self *Scope) AddVariable(variable *Variable) *Scope {\n\tcloned := self.Clone(variable.At)\n\tcloned.Variables = append([]*Variable{variable}, cloned.Variables...)\n\treturn cloned\n}\n\nfunc (self *Scope) FindVariable(name string) *Variable {\n\tfor _, node := range self.Variables {\n\t\tif node.Name.String() == name {\n\t\t\treturn node\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (self *Scope) Find(name string) Node {\n\tvar node Node\n\n\tnode = self.FindVariable(name)\n\tif node != nil {\n\t\treturn node\n\t}\n\n\treturn nil\n}\n\nfunc (self *Scope) DumpTree() {\n\tscope := self\n\tfor scope != nil {\n\t\tfmt.Printf(\"-- %p %s\\n\", scope, scope.At)\n\t\tscope = scope.Parent\n\t}\n}\n"}
{"sample": "/* messages.go\r\n   (c) Scott M Baker, http://www.smbaker.com/\r\n\r\n   JSON message structures, sent from Plugin to Streamdeck\r\n*/\r\n\r\npackage streamdeck\r\n\r\nconst (\r\n\tTARGET_BOTH     = 0\r\n\tTARGET_HARDWARE = 1\r\n\tTARGET_SOFTWARE = 2\r\n\r\n\tTYPE_JPG = \"image/jpg\"\r\n\tTYPE_PNG = \"image/png\"\r\n\tTYPE_BMP = \"image/bmp\"\r\n)\r\n\r\ntype RegisterMessage struct {\r\n\tEvent string `json:\"event\"`\r\n\tUuid  string `json:\"uuid\"`\r\n}\r\n\r\ntype ProfilePayload struct {\r\n\tProfile string `json:\"profile\"`\r\n}\r\n\r\ntype SwitchProfileMessage struct {\r\n\tEvent   string         `json:\"event\"`\r\n\tContext string         `json:\"context\"`\r\n\tDevice  string         `json:\"device\"`\r\n\tPayload ProfilePayload `json:\"payload\"`\r\n}\r\n\r\ntype SetImagePayload struct {\r\n\tImage  string `json:\"image\"`\r\n\tTarget int    `json:\"target\"`\r\n}\r\n\r\ntype SetImageMessage struct {\r\n\tEvent   string          `json:\"event\"`\r\n\tContext string          `json:\"context\"`\r\n\tPayload SetImagePayload `json:\"payload\"`\r\n}\r\n\r\ntype SetTitlePayload struct {\r\n\tTitle  string `json:\"title\"`\r\n\tTarget int    `json:\"target\"`\r\n}\r\n\r\ntype SetTitleMessage struct {\r\n\tEvent   string          `json:\"event\"`\r\n\tContext string          `json:\"context\"`\r\n\tPayload SetTitlePayload `json:\"payload\"`\r\n}\r\n\r\ntype ShowAlertMessage struct {\r\n\tEvent   string `json:\"event\"`\r\n\tContext string `json:\"context\"`\r\n}\r\n\r\ntype ShowOkMessage struct {\r\n\tEvent   string `json:\"event\"`\r\n\tContext string `json:\"context\"`\r\n}\r\n\r\ntype GetSettingsMessage struct {\r\n\tEvent   string `json:\"event\"`\r\n\tContext string `json:\"context\"`\r\n}\r\n"}
{"sample": "// Copyright (c) 2019, NVIDIA CORPORATION. All rights reserved.\n\npackage main\n\nimport (\n\t\"fmt\"\n\t\"github.com/NVIDIA/gpu-monitoring-tools/bindings/go/nvml\"\n)\n\n// NvmlMock : Implementation of Nvml using mocked calls\ntype NvmlMock struct {\n\tdevices       []NvmlMockDevice\n\tdriverVersion string\n\tcudaMajor     uint\n\tcudaMinor     uint\n\terrorOnInit   bool\n}\n\n// NvmlMockDevice : Implementation of NvmlDevice using mocked calls\ntype NvmlMockDevice struct {\n\tinstance   *nvml.Device\n\tattributes *nvml.DeviceAttributes\n\tmigEnabled bool\n\tmigDevices []NvmlMockDevice\n}\n\n// Init : Init the mock\nfunc (nvmlMock NvmlMock) Init() error {\n\tif nvmlMock.errorOnInit {\n\t\treturn fmt.Errorf(\"NvmlMock error on init\")\n\t}\n\treturn nil\n}\n\n// Shutdown : Shutdown the mock\nfunc (nvmlMock NvmlMock) Shutdown() error {\n\treturn nil\n}\n\n// GetDeviceCount : Return a fake number of devices\nfunc (nvmlMock NvmlMock) GetDeviceCount() (uint, error) {\n\treturn uint(len(nvmlMock.devices)), nil\n}\n\n// NewDevice : Get information about a fake GPU\nfunc (nvmlMock NvmlMock) NewDevice(id uint) (NvmlDevice, error) {\n\tif int(id) <= len(nvmlMock.devices) {\n\t\treturn nvmlMock.devices[id], nil\n\t}\n\treturn nil, fmt.Errorf(\"Invalid index: %d\", id)\n}\n\n// GetDriverVersion : Return a fake driver version\nfunc (nvmlMock NvmlMock) GetDriverVersion() (string, error) {\n\treturn nvmlMock.driverVersion, nil\n}\n\n// GetCudaDriverVersion : Return a fake cuda version\nfunc (nvmlMock NvmlMock) GetCudaDriverVersion() (*uint, *uint, error) {\n\treturn &nvmlMock.cudaMajor, &nvmlMock.cudaMinor, nil\n}\n\n// Instance : Return the underlying NVML device instance\nfunc (d NvmlMockDevice) Instance() *nvml.Device {\n\treturn d.instance\n}\n\n// IsMigEnabled : Returns whether MIG is enabled on the device or not\nfunc (d NvmlMockDevice) IsMigEnabled() (bool, error) {\n\treturn d.migEnabled, nil\n}\n\n// GetMigDevices : Returns the list of MIG devices configured on this device\nfunc (d NvmlMockDevice) GetMigDevices() ([]NvmlDevice, error) {\n\tvar devices []NvmlDevice\n\tfor _, m := range d.migDevices {\n\t\tdevices = append(devices, m)\n\t}\n\treturn devices, nil\n}\n\n// GetAttributes : Returns the set of of Devices attributes\nfunc (d NvmlMockDevice) GetAttributes() (nvml.DeviceAttributes, error) {\n\treturn *d.attributes, nil\n}\n"}
{"sample": "/*\n * Adyen for Platforms: Notifications\n *\n * The Notification API sends notifications to the endpoints specified in a given subscription. Subscriptions are managed through the Notification Configuration API. The API specifications listed here detail the format of each notification.  For more information, refer to our [documentation](https://docs.adyen.com/platforms/notifications).\n *\n * API version: 6\n * Contact: support@adyen.com\n */\n\n// Code generated by OpenAPI Generator (https://openapi-generator.tech); DO NOT EDIT.\n\npackage platformsnotificationevents\n\nimport (\n\t\"encoding/json\"\n)\n\n// PayoutMethod struct for PayoutMethod\ntype PayoutMethod struct {\n\tMerchantAccount string `json:\"merchantAccount\"`\n\tPayoutMethodCode *string `json:\"payoutMethodCode,omitempty\"`\n\tPayoutMethodType *string `json:\"payoutMethodType,omitempty\"`\n\tRecurringDetailReference string `json:\"recurringDetailReference\"`\n\tShopperReference string `json:\"shopperReference\"`\n}\n\n// NewPayoutMethod instantiates a new PayoutMethod object\n// This constructor will assign default values to properties that have it defined,\n// and makes sure properties required by API are set, but the set of arguments\n// will change when the set of required properties is changed\nfunc NewPayoutMethod(merchantAccount string, recurringDetailReference string, shopperReference string, ) *PayoutMethod {\n\tthis := PayoutMethod{}\n\tthis.MerchantAccount = merchantAccount\n\tthis.RecurringDetailReference = recurringDetailReference\n\tthis.ShopperReference = shopperReference\n\treturn &this\n}\n\n// NewPayoutMethodWithDefaults instantiates a new PayoutMethod object\n// This constructor will only assign default values to properties that have it defined,\n// but it doesn't guarantee that properties required by API are set\nfunc NewPayoutMethodWithDefaults() *PayoutMethod {\n\tthis := PayoutMethod{}\n\treturn &this\n}\n\n// GetMerchantAccount returns the MerchantAccount field value\nfunc (o *PayoutMethod) GetMerchantAccount() string {\n\tif o == nil  {\n\t\tvar ret string\n\t\treturn ret\n\t}\n\n\treturn o.MerchantAccount\n}\n\n// GetMerchantAccountOk returns a tuple with the MerchantAccount field value\n// and a boolean to check if the value has been set.\nfunc (o *PayoutMethod) GetMerchantAccountOk() (*string, bool) {\n\tif o == nil  {\n\t\treturn nil, false\n\t}\n\treturn &o.MerchantAccount, true\n}\n\n// SetMerchantAccount sets field value\nfunc (o *PayoutMethod) SetMerchantAccount(v string) {\n\to.MerchantAccount = v\n}\n\n// GetPayoutMethodCode returns the PayoutMethodCode field value if set, zero value otherwise.\nfunc (o *PayoutMethod) GetPayoutMethodCode() string {\n\tif o == nil || o.PayoutMethodCode == nil {\n\t\tvar ret string\n\t\treturn ret\n\t}\n\treturn *o.PayoutMethodCode\n}\n\n// GetPayoutMethodCodeOk returns a tuple with the PayoutMethodCode field value if set, nil otherwise\n// and a boolean to check if the value has been set.\nfunc (o *PayoutMethod) GetPayoutMethodCodeOk() (*string, bool) {\n\tif o == nil || o.PayoutMethodCode == nil {\n\t\treturn nil, false\n\t}\n\treturn o.PayoutMethodCode, true\n}\n\n// HasPayoutMethodCode returns a boolean if a field has been set.\nfunc (o *PayoutMethod) HasPayoutMethodCode() bool {\n\tif o != nil && o.PayoutMethodCode != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// SetPayoutMethodCode gets a reference to the given string and assigns it to the PayoutMethodCode field.\nfunc (o *PayoutMethod) SetPayoutMethodCode(v string) {\n\to.PayoutMethodCode = &v\n}\n\n// GetPayoutMethodType returns the PayoutMethodType field value if set, zero value otherwise.\nfunc (o *PayoutMethod) GetPayoutMethodType() string {\n\tif o == nil || o.PayoutMethodType == nil {\n\t\tvar ret string\n\t\treturn ret\n\t}\n\treturn *o.PayoutMethodType\n}\n\n// GetPayoutMethodTypeOk returns a tuple with the PayoutMethodType field value if set, nil otherwise\n// and a boolean to check if the value has been set.\nfunc (o *PayoutMethod) GetPayoutMethodTypeOk() (*string, bool) {\n\tif o == nil || o.PayoutMethodType == nil {\n\t\treturn nil, false\n\t}\n\treturn o.PayoutMethodType, true\n}\n\n// HasPayoutMethodType returns a boolean if a field has been set.\nfunc (o *PayoutMethod) HasPayoutMethodType() bool {\n\tif o != nil && o.PayoutMethodType != nil {\n\t\treturn true\n\t}\n\n\treturn false\n}\n\n// SetPayoutMethodType gets a reference to the given string and assigns it to the PayoutMethodType field.\nfunc (o *PayoutMethod) SetPayoutMethodType(v string) {\n\to.PayoutMethodType = &v\n}\n\n// GetRecurringDetailReference returns the RecurringDetailReference field value\nfunc (o *PayoutMethod) GetRecurringDetailReference() string {\n\tif o == nil  {\n\t\tvar ret string\n\t\treturn ret\n\t}\n\n\treturn o.RecurringDetailReference\n}\n\n// GetRecurringDetailReferenceOk returns a tuple with the RecurringDetailReference field value\n// and a boolean to check if the value has been set.\nfunc (o *PayoutMethod) GetRecurringDetailReferenceOk() (*string, bool) {\n\tif o == nil  {\n\t\treturn nil, false\n\t}\n\treturn &o.RecurringDetailReference, true\n}\n\n// SetRecurringDetailReference sets field value\nfunc (o *PayoutMethod) SetRecurringDetailReference(v string) {\n\to.RecurringDetailReference = v\n}\n\n// GetShopperReference returns the ShopperReference field value\nfunc (o *PayoutMethod) GetShopperReference() string {\n\tif o == nil  {\n\t\tvar ret string\n\t\treturn ret\n\t}\n\n\treturn o.ShopperReference\n}\n\n// GetShopperReferenceOk returns a tuple with the ShopperReference field value\n// and a boolean to check if the value has been set.\nfunc (o *PayoutMethod) GetShopperReferenceOk() (*string, bool) {\n\tif o == nil  {\n\t\treturn nil, false\n\t}\n\treturn &o.ShopperReference, true\n}\n\n// SetShopperReference sets field value\nfunc (o *PayoutMethod) SetShopperReference(v string) {\n\to.ShopperReference = v\n}\n\nfunc (o PayoutMethod) MarshalJSON() ([]byte, error) {\n\ttoSerialize := map[string]interface{}{}\n\tif true {\n\t\ttoSerialize[\"merchantAccount\"] = o.MerchantAccount\n\t}\n\tif o.PayoutMethodCode != nil {\n\t\ttoSerialize[\"payoutMethodCode\"] = o.PayoutMethodCode\n\t}\n\tif o.PayoutMethodType != nil {\n\t\ttoSerialize[\"payoutMethodType\"] = o.PayoutMethodType\n\t}\n\tif true {\n\t\ttoSerialize[\"recurringDetailReference\"] = o.RecurringDetailReference\n\t}\n\tif true {\n\t\ttoSerialize[\"shopperReference\"] = o.ShopperReference\n\t}\n\treturn json.Marshal(toSerialize)\n}\n\ntype NullablePayoutMethod struct {\n\tvalue *PayoutMethod\n\tisSet bool\n}\n\nfunc (v NullablePayoutMethod) Get() *PayoutMethod {\n\treturn v.value\n}\n\nfunc (v *NullablePayoutMethod) Set(val *PayoutMethod) {\n\tv.value = val\n\tv.isSet = true\n}\n\nfunc (v NullablePayoutMethod) IsSet() bool {\n\treturn v.isSet\n}\n\nfunc (v *NullablePayoutMethod) Unset() {\n\tv.value = nil\n\tv.isSet = false\n}\n\nfunc NewNullablePayoutMethod(val *PayoutMethod) *NullablePayoutMethod {\n\treturn &NullablePayoutMethod{value: val, isSet: true}\n}\n\nfunc (v NullablePayoutMethod) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(v.value)\n}\n\nfunc (v *NullablePayoutMethod) UnmarshalJSON(src []byte) error {\n\tv.isSet = true\n\treturn json.Unmarshal(src, &v.value)\n}\n\n\n"}
